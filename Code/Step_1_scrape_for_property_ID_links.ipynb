{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "52778020",
      "metadata": {},
      "outputs": [],
      "source": [
        "# libraries \n",
        "import pandas as pd \n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "from csv import reader\n",
        "import time\n",
        "\n",
        "# plots:\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "\n",
        "# scraping\n",
        "from bs4 import BeautifulSoup\n",
        "from lxml import etree #for using XPATH with beautifulsoup\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "#JSON\n",
        "import json\n",
        "\n",
        "# GeoJSON\n",
        "# import geopandas as gpd\n",
        "\n",
        "# regular expression\n",
        "import re \n",
        "\n",
        "# concurrent futures - boosts the process of scraping utilicing the CPU better\n",
        "# two main classes- \n",
        "#       1) executor class: manages all the threads and workload\n",
        "#       2) futures class: creates a little instance and manages data coming back\n",
        "import concurrent.futures\n",
        "\n",
        "# libraries: \n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed51e503",
      "metadata": {},
      "source": [
        " \n",
        "     \n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1121346c",
      "metadata": {},
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dab181c",
      "metadata": {},
      "source": [
        "# The plan :\n",
        "\n",
        "\n",
        "* filter for properties that mach the following \n",
        "    * **housing type:** Villa (detached house) , Rækkehus (raðhús) , Ejerlejlighed (condo)\n",
        "    * **Time:** 2012-2023\n",
        "    * **Sale type:** normal or according to boliga.dk Almindeligt frit salg\n",
        "    * ***according to Boliga.dk the result is 1.028.612 properties*** \n",
        "    \n",
        "* First I scrape the API that gives me search result \n",
        "    * they dont seem to filter i.e. the properties amounts to 1.028.612 and have 50 properties per page which means **25.573** pages which they allow to search in. \n",
        "    \n",
        "    * parameters that it takes are : \n",
        "        * searchTab: 1\n",
        "        * propertyType: 1,2,3\n",
        "        * saleType: 1\n",
        "        * salesDateMin: 2012\n",
        "        * salesDateMax: 2023\n",
        "        * sort: date-d\n",
        "        * page: 2\n",
        "        \n",
        "    * Property types are numbers such that \n",
        "        * property type = 1 is **Villa**\n",
        "        * property type = 2 is **Rækkehus**\n",
        "        * property type = 3 is **Ejerlejlighed**\n",
        "        * property type = 6 is **Landejendom** (farm house) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a810ea75",
      "metadata": {},
      "source": [
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "208ee2dd",
      "metadata": {},
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d2f5932",
      "metadata": {},
      "source": [
        "# Setting up User agent and header "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3dffc1a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# change user agent for each request randomly\n",
        "def get_user_agent():\n",
        "    user_agent_list = [\n",
        "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.50',\n",
        "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36',\n",
        "        'Mozilla/5.0 (iPhone; CPU iPhone OS 14_4_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Mobile/15E148 Safari/604.1',\n",
        "        'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n",
        "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36 Edg/87.0.664.75',\n",
        "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.18363',\n",
        "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36 Edg/113.0.1774.57'\n",
        "    ]\n",
        "    user_agent = user_agent_list[random.randint(0,len(user_agent_list)-1)]\n",
        "   \n",
        "    return user_agent\n",
        "\n",
        "def get_header():\n",
        "    \n",
        "    # get user-agent\n",
        "    user_agent = get_user_agent()\n",
        "\n",
        "     # set up header     \n",
        "    header = {\n",
        "        'authority': 'api.boligsiden.dk',\n",
        "        'accept': 'application/json, text/plain, */*',\n",
        "        'accept-language': 'en-GB,en;q=0.9,en-US;q=0.8',\n",
        "        'origin': 'https://www.boligsiden.dk',\n",
        "        'referer': 'https://www.boliga.dk/',\n",
        "        'sec-ch-ua': '\"Microsoft Edge\";v=\"113\", \"Chromium\";v=\"113\", \"Not-A.Brand\";v=\"24\"',\n",
        "        'sec-ch-ua-mobile': '?0',\n",
        "        'sec-ch-ua-platform': '\"Windows\"',\n",
        "        'sec-fetch-dest': 'empty',\n",
        "        'sec-fetch-mode': 'cors',\n",
        "        'sec-fetch-site': 'same-site',\n",
        "        'user-agent': user_agent\n",
        "#         'x-api-key': 'GWD0fljZzkc8GOLV',\n",
        "    }\n",
        "    return header "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b4677a7",
      "metadata": {},
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "132bedc0",
      "metadata": {},
      "source": [
        "# scrape page "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe3018e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def scrape_page(page):\n",
        "#     global dataframes_list\n",
        "    \n",
        "#     print('-------------------------------------')\n",
        "#     print(f'---- page number {page} of (510.670 boliger solgt')\n",
        "#     print('-------------------------------------')\n",
        "\n",
        "#     # Set up the header\n",
        "#     ########################\n",
        "#     main_header = get_header()\n",
        "\n",
        "#     # Set up the url of the API\n",
        "#     ###########################\n",
        "#     main_url = f'https://api.boliga.dk/api/v2/sold/search/results?searchTab=1&propertyType=1,2,3,6&saleType=1&salesDateMin=2012&salesDateMax=2023&sort=date-d&page={page}'\n",
        "\n",
        "#     # Make the HTTPS Request \n",
        "#     ########################\n",
        "#     response = session.get(main_url, headers=main_header)\n",
        "\n",
        "#     if response.status_code == 200:\n",
        "        \n",
        "#         print('--------------------- scraping !')\n",
        "\n",
        "#         # Convert to JSON \n",
        "#         #################\n",
        "#         page_result = response.json()['results']\n",
        "\n",
        "#         # loop over each object and construct the dataframe\n",
        "#         ####################################################\n",
        "#         dataframes = [pd.DataFrame([prop]) for prop in page_result]\n",
        "\n",
        "#         # append to the dataframes_list \n",
        "#         ###############################\n",
        "#         dataframes_list.extend(dataframes)\n",
        "#     else:\n",
        "#         print()\n",
        "#         print('############################################################')\n",
        "#         print('------------------- BAD REQUEST, NOT 200 ------------------')\n",
        "#         print('############################################################')\n",
        "#         print()\n",
        "\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7e957fa6",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def scrape_page(page):\n",
        "    global dataframes_list\n",
        "    global session\n",
        "    \n",
        "    print('-------------------------------------')\n",
        "    print(f'---- page number {page} of 25.573 pages')\n",
        "    print('-------------------------------------')\n",
        "\n",
        "    # Set up the header\n",
        "    ########################\n",
        "    main_header = get_header()\n",
        "\n",
        "    # Set up the url of the API\n",
        "    ###########################\n",
        "    main_url = f'https://api.boliga.dk/api/v2/sold/search/results?searchTab=1&propertyType=1,2,3,6&saleType=1&salesDateMin=2006&salesDateMax=2011&sort=date-d&page={page}'\n",
        "\n",
        "    # Make the HTTPS Request \n",
        "    ########################\n",
        "    response = session.get(main_url, headers=main_header)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        \n",
        "        print('--------------------- scraping !')\n",
        "\n",
        "        # Convert to JSON \n",
        "        #################\n",
        "        page_result = response.json()['results']\n",
        "\n",
        "        # loop over each object and construct the dataframe\n",
        "        ####################################################\n",
        "        dataframes = [pd.DataFrame([prop]) for prop in page_result]\n",
        "\n",
        "        # append to the dataframes_list \n",
        "        ###############################\n",
        "        dataframes_list.extend(dataframes)\n",
        "    else:\n",
        "        print()\n",
        "        print('############################################################')\n",
        "        print('------------------- BAD REQUEST, NOT 200 ------------------')\n",
        "        print('############################################################')\n",
        "        print()\n",
        "\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "72a6aec6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10213.4"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c71c8b29",
      "metadata": {},
      "source": [
        " \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce843d6e",
      "metadata": {},
      "source": [
        "# Main function \n",
        "\n",
        "The total number of pages is 25.573."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b7a008",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "798cdae5",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "###############################################\n",
        "# for loop: \n",
        "# --------- go over each of the  25.573 pages\n",
        "###############################################\n",
        "\n",
        "dataframes_list = []\n",
        "\n",
        "session = requests.Session()\n",
        "\n",
        "page_numbers = list(range(1,25572+1))\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor: \n",
        "    retry = Retry(connect=3, backoff_factor=0.5) # max 3 retries to the same link with a 0.5 sec delay\n",
        "    adapter = HTTPAdapter(max_retries=retry)\n",
        "    session.mount('http://', adapter)\n",
        "    session.mount('https://', adapter)\n",
        "\n",
        "    # run script\n",
        "    executor.map(scrape_page,page_numbers)\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef0a2079",
      "metadata": {},
      "outputs": [],
      "source": [
        "len(dataframes_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e91c325a",
      "metadata": {},
      "source": [
        "# ---- Save data as multiple chunks "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b17810c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming you have a list of DataFrames called \"db_list\"\n",
        "\n",
        "# Specify the chunk size (adjust based on your system's available memory)\n",
        "chunk_size = 10000  # Process 10000 DataFrames at a time\n",
        "\n",
        "# Initialize a counter to keep track of the chunks\n",
        "counter = 81\n",
        "\n",
        "for i in range(0, len(dataframes_list), chunk_size):\n",
        "    print(f\" -------- chunk {counter} out of 80\")\n",
        "    \n",
        "    chunk = dataframes_list[i:i + chunk_size]\n",
        "    combined_df = pd.concat(chunk, ignore_index=True)\n",
        "    \n",
        "    # Save each chunk to a CSV file with a unique name\n",
        "    csv_filename = f'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Step_1_Scrape_Property_ID_Links\\data\\combined_data_chunk_{counter}.csv'\n",
        "    combined_df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
        "    \n",
        "    counter += 1\n",
        "    \n",
        "    "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
