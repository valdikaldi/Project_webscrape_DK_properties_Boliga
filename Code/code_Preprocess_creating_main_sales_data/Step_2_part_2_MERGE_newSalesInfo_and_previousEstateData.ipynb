{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New plan (old plan below)\n",
    "\n",
    "## --- Create NEW Estate csv file only with main id column and the strings of the dictionaries containing the sales \n",
    "## --- Then merge by main ID \n",
    "## --- Then convert dictionary column to dictionary object \n",
    "## --- next create the new columns \n",
    "## --- Finally run a loop over rows with estate object and add values to new columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "# 1) read in the NEW SALES data (Sales+evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2623340 entries, 0 to 2623339\n",
      "Data columns (total 20 columns):\n",
      " #   Column                            Non-Null Count    Dtype  \n",
      "---  ------                            --------------    -----  \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID   2623340 non-null  object \n",
      " 1   salesInfo_isSalesValid            2623340 non-null  bool   \n",
      " 2   salesInfo_handoverCode            2623340 non-null  float64\n",
      " 3   salesInfo_handoverName            2623340 non-null  object \n",
      " 4   salesInfo_deedIssueDate           2623340 non-null  object \n",
      " 5   salesInfo_price                   2623340 non-null  float64\n",
      " 6   salesInfo_recalculationDate       2623340 non-null  object \n",
      " 7   salesInfo_rebuildYear             2623340 non-null  float64\n",
      " 8   unique_sales_ID                   2623340 non-null  int64  \n",
      " 9   salesInfo_year_of_sale            2623340 non-null  int64  \n",
      " 10  EvaluationInfo_evaluationYear     1364441 non-null  float64\n",
      " 11  EvaluationInfo_lastChange         1364441 non-null  object \n",
      " 12  EvaluationInfo_propertyValue      1364441 non-null  float64\n",
      " 13  EvaluationInfo_landValue          1364441 non-null  float64\n",
      " 14  EvaluationInfo_deductionSum       1364441 non-null  float64\n",
      " 15  EvaluationInfo_usage              1364441 non-null  object \n",
      " 16  EvaluationInfo_residentialUnits   1364441 non-null  float64\n",
      " 17  EvaluationInfo_propertyValueArea  1364441 non-null  float64\n",
      " 18  EvaluationInfo_rebuildYear        1364441 non-null  float64\n",
      " 19  EvaluationInfo_areaSize           1364441 non-null  float64\n",
      "dtypes: bool(1), float64(11), int64(2), object(6)\n",
      "memory usage: 382.8+ MB\n"
     ]
    }
   ],
   "source": [
    "path_sales = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_merge\\step_1_mergin_Sales_transactions_with_evaluation_data\\Boliga_salesData_SalesTransactions_with_evaluation_2623340rows_20columns.csv'\n",
    "data_salesdata = pd.read_csv(path_sales, encoding = 'utf-8', low_memory=False) #,nrows=1000)\n",
    "data_salesdata.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Read IN THE plan B version of previousEstates data\n",
    "that file contains only MAIN id AND ESTATE DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1031507 entries, 0 to 1031506\n",
      "Data columns (total 2 columns):\n",
      " #   Column                           Non-Null Count    Dtype \n",
      "---  ------                           --------------    ----- \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID  1031507 non-null  object\n",
      " 1   RAW_dictionary_previousEstates   1031507 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.7+ MB\n"
     ]
    }
   ],
   "source": [
    "path_ESTATE = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_split\\14_PreviousEstate\\Ready\\PLAN_B_Boliga_propertySales_previousEstate_READY.csv'\n",
    "data_ESTATE = pd.read_csv(path_ESTATE, encoding = 'utf-8', low_memory=False) #,nrows=1000)\n",
    "data_ESTATE.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Merge dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2623340 entries, 0 to 2623339\n",
      "Data columns (total 21 columns):\n",
      " #   Column                            Dtype  \n",
      "---  ------                            -----  \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID   object \n",
      " 1   salesInfo_isSalesValid            bool   \n",
      " 2   salesInfo_handoverCode            float64\n",
      " 3   salesInfo_handoverName            object \n",
      " 4   salesInfo_deedIssueDate           object \n",
      " 5   salesInfo_price                   float64\n",
      " 6   salesInfo_recalculationDate       object \n",
      " 7   salesInfo_rebuildYear             float64\n",
      " 8   unique_sales_ID                   int64  \n",
      " 9   salesInfo_year_of_sale            int64  \n",
      " 10  EvaluationInfo_evaluationYear     float64\n",
      " 11  EvaluationInfo_lastChange         object \n",
      " 12  EvaluationInfo_propertyValue      float64\n",
      " 13  EvaluationInfo_landValue          float64\n",
      " 14  EvaluationInfo_deductionSum       float64\n",
      " 15  EvaluationInfo_usage              object \n",
      " 16  EvaluationInfo_residentialUnits   float64\n",
      " 17  EvaluationInfo_propertyValueArea  float64\n",
      " 18  EvaluationInfo_rebuildYear        float64\n",
      " 19  EvaluationInfo_areaSize           float64\n",
      " 20  RAW_dictionary_previousEstates    object \n",
      "dtypes: bool(1), float64(11), int64(2), object(7)\n",
      "memory usage: 402.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_salesdata = pd.merge(data_salesdata, data_ESTATE, on='RowID_MAIN_boliga_ROW_ID_unitID', how='left')\n",
    "data_salesdata.info()\n",
    "\n",
    "del data_ESTATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2623340 entries, 0 to 2623339\n",
      "Data columns (total 21 columns):\n",
      " #   Column                            Non-Null Count    Dtype  \n",
      "---  ------                            --------------    -----  \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID   2623340 non-null  object \n",
      " 1   salesInfo_isSalesValid            2623340 non-null  bool   \n",
      " 2   salesInfo_handoverCode            2623340 non-null  float64\n",
      " 3   salesInfo_handoverName            2623340 non-null  object \n",
      " 4   salesInfo_deedIssueDate           2623340 non-null  object \n",
      " 5   salesInfo_price                   2623340 non-null  float64\n",
      " 6   salesInfo_recalculationDate       2623340 non-null  object \n",
      " 7   salesInfo_rebuildYear             2623340 non-null  float64\n",
      " 8   unique_sales_ID                   2623340 non-null  int64  \n",
      " 9   salesInfo_year_of_sale            2623340 non-null  int64  \n",
      " 10  EvaluationInfo_evaluationYear     1364441 non-null  float64\n",
      " 11  EvaluationInfo_lastChange         1364441 non-null  object \n",
      " 12  EvaluationInfo_propertyValue      1364441 non-null  float64\n",
      " 13  EvaluationInfo_landValue          1364441 non-null  float64\n",
      " 14  EvaluationInfo_deductionSum       1364441 non-null  float64\n",
      " 15  EvaluationInfo_usage              1364441 non-null  object \n",
      " 16  EvaluationInfo_residentialUnits   1364441 non-null  float64\n",
      " 17  EvaluationInfo_propertyValueArea  1364441 non-null  float64\n",
      " 18  EvaluationInfo_rebuildYear        1364441 non-null  float64\n",
      " 19  EvaluationInfo_areaSize           1364441 non-null  float64\n",
      " 20  RAW_dictionary_previousEstates    2623340 non-null  object \n",
      "dtypes: bool(1), float64(11), int64(2), object(7)\n",
      "memory usage: 402.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_salesdata.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_salesdata[data_salesdata['RAW_dictionary_previousEstates']!='[]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) convert column RAW_dictionary_previousEstates to dictionary object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['RAW_dictionary_previousEstates'] = data_salesdata['RAW_dictionary_previousEstates'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) and x!='[]' and x!='' and x is not None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estateId': 1931979,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 52,\n",
       "  'salesPrice': 3248000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1931/1931979.jpg',\n",
       "  'lastSeen': '8. nov. 2022',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1857402,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 242,\n",
       "  'salesPrice': 3348000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1857/1857402.jpg',\n",
       "  'lastSeen': '14. sep. 2022',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1352628,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 26,\n",
       "  'salesPrice': 2975000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1352/1352628.jpg',\n",
       "  'lastSeen': '31. aug. 2017',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['RAW_dictionary_previousEstates'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) convert  salesInfo_deedIssueDate to date object ----------------------- wait with this after the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salesInfo_deedIssueDate\n",
       "1899    700815\n",
       "2021    126417\n",
       "2006    119706\n",
       "2007    115858\n",
       "2020    107467\n",
       "2017    106966\n",
       "2018    106140\n",
       "2019    102195\n",
       "2010     96812\n",
       "2015     95374\n",
       "2016     94765\n",
       "2022     93602\n",
       "2008     86676\n",
       "2005     83941\n",
       "2011     78689\n",
       "2014     77941\n",
       "2013     70983\n",
       "2012     70848\n",
       "2023     66320\n",
       "2004     66171\n",
       "2003     61625\n",
       "2009     54393\n",
       "1753     19862\n",
       "2002     15987\n",
       "1996       711\n",
       "2001       708\n",
       "2000       644\n",
       "1997       583\n",
       "1998       572\n",
       "1999       567\n",
       "1900         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(data_salesdata['salesInfo_deedIssueDate'], format=\"%Y-%m-%d\").dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7          0d3618c0-35a1-49bc-b2cb-9228ef5065f9\n",
       "8          0d3618c0-35a1-49bc-b2cb-9228ef5065f9\n",
       "14         e824b5cd-d1ae-4599-9b1d-7bff5cc52255\n",
       "15         e824b5cd-d1ae-4599-9b1d-7bff5cc52255\n",
       "20         d6d3cb16-c5db-4e10-af5d-ee0cc4b59f9c\n",
       "                           ...                 \n",
       "2623330    ce1f5b0b-053a-4661-9cb2-632d1a182d5f\n",
       "2623331    ce1f5b0b-053a-4661-9cb2-632d1a182d5f\n",
       "2623334    845ce2df-d0ca-45cf-b6ca-df6ca620a685\n",
       "2623336    81ce9112-1089-4179-a38e-e89dd148faac\n",
       "2623339    ac22bf6a-bb13-4092-be79-ad8951e0b5c3\n",
       "Name: RowID_MAIN_boliga_ROW_ID_unitID, Length: 700815, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[pd.to_datetime(data_salesdata['salesInfo_deedIssueDate'], format=\"%Y-%m-%d\").dt.year == 1899]['RowID_MAIN_boliga_ROW_ID_unitID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salesInfo_recalculationDate</th>\n",
       "      <th>salesInfo_deedIssueDate</th>\n",
       "      <th>salesInfo_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>1950000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1997-08-31</td>\n",
       "      <td>1899-12-30</td>\n",
       "      <td>620000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1996-02-13</td>\n",
       "      <td>1899-12-30</td>\n",
       "      <td>430000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1993-11-29</td>\n",
       "      <td>1899-12-30</td>\n",
       "      <td>440000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2003-08-11</td>\n",
       "      <td>2003-09-23</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2009-11-24</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>1300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>1998000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   salesInfo_recalculationDate salesInfo_deedIssueDate  salesInfo_price\n",
       "19                  2021-05-18              2021-07-19        1950000.0\n",
       "20                  1997-08-31              1899-12-30         620000.0\n",
       "21                  1996-02-13              1899-12-30         430000.0\n",
       "22                  1993-11-29              1899-12-30         440000.0\n",
       "23                  2003-08-11              2003-09-23        1000000.0\n",
       "24                  2009-11-24              2010-01-12        1300000.0\n",
       "25                  2023-11-07              2023-11-07        1998000.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='d6d3cb16-c5db-4e10-af5d-ee0cc4b59f9c'][['salesInfo_recalculationDate','salesInfo_deedIssueDate','salesInfo_price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!! NOTE : AT FIRST i USED salesInfo_deedIssueDate BUT AS YOU CAN SEE ITS FUCKED 700815 OBS WIHT YEAR 1899 ALSO salesInfo_recalculationDate CAN CONTAIN DATES THAT ARE OLDER THEN AN AD THAT BELONGS TO IT.... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAN: \n",
    "\n",
    "#### Create column salesInfo_MAIN_date_of_Sale : which compares the dates in salesInfo_deedIssueDate and salesInfo_recalculationDate then takes the newer date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string columns to datetime objects\n",
    "data_salesdata['salesInfo_recalculationDate'] = pd.to_datetime(data_salesdata['salesInfo_recalculationDate'])\n",
    "data_salesdata['salesInfo_deedIssueDate'] = pd.to_datetime(data_salesdata['salesInfo_deedIssueDate'])\n",
    "\n",
    "# Create a new column with the newer date for each row\n",
    "data_salesdata['salesInfo_MAIN_date_of_Sale'] = data_salesdata[['salesInfo_recalculationDate','salesInfo_deedIssueDate']].max(axis=1)\n",
    "\n",
    "# convert salesInfo_MAIN_date_of_Sale back to string object \n",
    "data_salesdata['salesInfo_MAIN_date_of_Sale'] = data_salesdata['salesInfo_MAIN_date_of_Sale'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salesInfo_recalculationDate</th>\n",
       "      <th>salesInfo_deedIssueDate</th>\n",
       "      <th>salesInfo_MAIN_date_of_Sale</th>\n",
       "      <th>salesInfo_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>1950000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1997-08-31</td>\n",
       "      <td>1899-12-30</td>\n",
       "      <td>1997-08-31</td>\n",
       "      <td>620000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1996-02-13</td>\n",
       "      <td>1899-12-30</td>\n",
       "      <td>1996-02-13</td>\n",
       "      <td>430000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1993-11-29</td>\n",
       "      <td>1899-12-30</td>\n",
       "      <td>1993-11-29</td>\n",
       "      <td>440000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2003-08-11</td>\n",
       "      <td>2003-09-23</td>\n",
       "      <td>2003-09-23</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2009-11-24</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>1300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>1998000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   salesInfo_recalculationDate salesInfo_deedIssueDate  \\\n",
       "19                  2021-05-18              2021-07-19   \n",
       "20                  1997-08-31              1899-12-30   \n",
       "21                  1996-02-13              1899-12-30   \n",
       "22                  1993-11-29              1899-12-30   \n",
       "23                  2003-08-11              2003-09-23   \n",
       "24                  2009-11-24              2010-01-12   \n",
       "25                  2023-11-07              2023-11-07   \n",
       "\n",
       "   salesInfo_MAIN_date_of_Sale  salesInfo_price  \n",
       "19                  2021-07-19        1950000.0  \n",
       "20                  1997-08-31         620000.0  \n",
       "21                  1996-02-13         430000.0  \n",
       "22                  1993-11-29         440000.0  \n",
       "23                  2003-09-23        1000000.0  \n",
       "24                  2010-01-12        1300000.0  \n",
       "25                  2023-11-07        1998000.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='d6d3cb16-c5db-4e10-af5d-ee0cc4b59f9c'][['salesInfo_recalculationDate','salesInfo_deedIssueDate','salesInfo_MAIN_date_of_Sale','salesInfo_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_salesdata['salesInfo_deedIssueDate'] = pd.to_datetime(data_salesdata['salesInfo_deedIssueDate'], format=\"%Y-%m-%d\")#.dt.date\n",
    "# type(data_salesdata['salesInfo_deedIssueDate'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) change key \"lastSeen\" values In Estate dictionaries such that I replace \"maj\" to \"may\" and \"okt\" to \"oct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_salesdata['RAW_dictionary_previousEstates'] = data_salesdata['RAW_dictionary_previousEstates'].apply(\n",
    "    lambda x: [{**entry, 'lastSeen': entry['lastSeen'].replace('okt', 'oct').replace('maj', 'may')} for entry in x] if isinstance(x, list) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "1          [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "2          [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "3          [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "4          [{'estateId': 1988849, 'estateAddress': 'Ibsgå...\n",
       "                                 ...                        \n",
       "2623335                                                   []\n",
       "2623336                                                   []\n",
       "2623337                                                   []\n",
       "2623338                                                   []\n",
       "2623339                                                   []\n",
       "Name: RAW_dictionary_previousEstates, Length: 2623340, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['RAW_dictionary_previousEstates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2623340 entries, 0 to 2623339\n",
      "Data columns (total 22 columns):\n",
      " #   Column                            Dtype         \n",
      "---  ------                            -----         \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID   object        \n",
      " 1   salesInfo_isSalesValid            bool          \n",
      " 2   salesInfo_handoverCode            float64       \n",
      " 3   salesInfo_handoverName            object        \n",
      " 4   salesInfo_deedIssueDate           datetime64[ns]\n",
      " 5   salesInfo_price                   float64       \n",
      " 6   salesInfo_recalculationDate       datetime64[ns]\n",
      " 7   salesInfo_rebuildYear             float64       \n",
      " 8   unique_sales_ID                   int64         \n",
      " 9   salesInfo_year_of_sale            int64         \n",
      " 10  EvaluationInfo_evaluationYear     float64       \n",
      " 11  EvaluationInfo_lastChange         object        \n",
      " 12  EvaluationInfo_propertyValue      float64       \n",
      " 13  EvaluationInfo_landValue          float64       \n",
      " 14  EvaluationInfo_deductionSum       float64       \n",
      " 15  EvaluationInfo_usage              object        \n",
      " 16  EvaluationInfo_residentialUnits   float64       \n",
      " 17  EvaluationInfo_propertyValueArea  float64       \n",
      " 18  EvaluationInfo_rebuildYear        float64       \n",
      " 19  EvaluationInfo_areaSize           float64       \n",
      " 20  RAW_dictionary_previousEstates    object        \n",
      " 21  salesInfo_MAIN_date_of_Sale       object        \n",
      "dtypes: bool(1), datetime64[ns](2), float64(11), int64(2), object(6)\n",
      "memory usage: 422.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_salesdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Create New column called \"Property_Older_transactions_dates\" which will contain a list of dates of other transaction of the same property which occured in the past "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ----- first create a new dataframe with the unique RowID_MAIN_boliga_ROW_ID_unitID    and a list of all dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'ID' and aggregate dates into a list\n",
    "grouped_Dates_by_ID = data_salesdata.groupby('RowID_MAIN_boliga_ROW_ID_unitID')['salesInfo_MAIN_date_of_Sale'].agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name of the column \n",
    "grouped_Dates_by_ID = grouped_Dates_by_ID.rename(columns={'salesInfo_deedIssueDate': 'salesInfo_ALL_sales_dates_by_main_ID'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ----- NEXT merge data_salesdata and grouped_Dates_by_ID together (on = left - keep all rows in sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2623340 entries, 0 to 2623339\n",
      "Data columns (total 23 columns):\n",
      " #   Column                            Non-Null Count    Dtype         \n",
      "---  ------                            --------------    -----         \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID   2623340 non-null  object        \n",
      " 1   salesInfo_isSalesValid            2623340 non-null  bool          \n",
      " 2   salesInfo_handoverCode            2623340 non-null  float64       \n",
      " 3   salesInfo_handoverName            2623340 non-null  object        \n",
      " 4   salesInfo_deedIssueDate           2623340 non-null  datetime64[ns]\n",
      " 5   salesInfo_price                   2623340 non-null  float64       \n",
      " 6   salesInfo_recalculationDate       2623340 non-null  datetime64[ns]\n",
      " 7   salesInfo_rebuildYear             2623340 non-null  float64       \n",
      " 8   unique_sales_ID                   2623340 non-null  int64         \n",
      " 9   salesInfo_year_of_sale            2623340 non-null  int64         \n",
      " 10  EvaluationInfo_evaluationYear     1364441 non-null  float64       \n",
      " 11  EvaluationInfo_lastChange         1364441 non-null  object        \n",
      " 12  EvaluationInfo_propertyValue      1364441 non-null  float64       \n",
      " 13  EvaluationInfo_landValue          1364441 non-null  float64       \n",
      " 14  EvaluationInfo_deductionSum       1364441 non-null  float64       \n",
      " 15  EvaluationInfo_usage              1364441 non-null  object        \n",
      " 16  EvaluationInfo_residentialUnits   1364441 non-null  float64       \n",
      " 17  EvaluationInfo_propertyValueArea  1364441 non-null  float64       \n",
      " 18  EvaluationInfo_rebuildYear        1364441 non-null  float64       \n",
      " 19  EvaluationInfo_areaSize           1364441 non-null  float64       \n",
      " 20  RAW_dictionary_previousEstates    2623340 non-null  object        \n",
      " 21  salesInfo_MAIN_date_of_Sale_x     2623340 non-null  object        \n",
      " 22  salesInfo_MAIN_date_of_Sale_y     2623340 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](2), float64(11), int64(2), object(7)\n",
      "memory usage: 442.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_salesdata = pd.merge(data_salesdata, grouped_Dates_by_ID, on='RowID_MAIN_boliga_ROW_ID_unitID', how='left')\n",
    "data_salesdata.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [2007-09-12, 2023-11-08, 2017-12-11, 2007-09-27]\n",
       "1          [2007-09-12, 2023-11-08, 2017-12-11, 2007-09-27]\n",
       "2          [2007-09-12, 2023-11-08, 2017-12-11, 2007-09-27]\n",
       "3          [2007-09-12, 2023-11-08, 2017-12-11, 2007-09-27]\n",
       "4                                              [2023-11-07]\n",
       "                                 ...                       \n",
       "2623335                            [2006-01-02, 2009-04-20]\n",
       "2623336                            [2001-06-20, 2006-01-02]\n",
       "2623337                            [2001-06-20, 2006-01-02]\n",
       "2623338                            [2006-05-24, 2001-06-07]\n",
       "2623339                            [2006-05-24, 2001-06-07]\n",
       "Name: salesInfo_MAIN_date_of_Sale_y, Length: 2623340, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['salesInfo_MAIN_date_of_Sale_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata = data_salesdata.rename(columns={'salesInfo_MAIN_date_of_Sale_y': 'salesInfo_ALL_sales_dates_by_main_ID', 'salesInfo_MAIN_date_of_Sale_x':'salesInfo_MAIN_date_of_Sale'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "del grouped_Dates_by_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2623340 entries, 0 to 2623339\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                Non-Null Count    Dtype         \n",
      "---  ------                                --------------    -----         \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID       2623340 non-null  object        \n",
      " 1   salesInfo_isSalesValid                2623340 non-null  bool          \n",
      " 2   salesInfo_handoverCode                2623340 non-null  float64       \n",
      " 3   salesInfo_handoverName                2623340 non-null  object        \n",
      " 4   salesInfo_deedIssueDate               2623340 non-null  datetime64[ns]\n",
      " 5   salesInfo_price                       2623340 non-null  float64       \n",
      " 6   salesInfo_recalculationDate           2623340 non-null  datetime64[ns]\n",
      " 7   salesInfo_rebuildYear                 2623340 non-null  float64       \n",
      " 8   unique_sales_ID                       2623340 non-null  int64         \n",
      " 9   salesInfo_year_of_sale                2623340 non-null  int64         \n",
      " 10  EvaluationInfo_evaluationYear         1364441 non-null  float64       \n",
      " 11  EvaluationInfo_lastChange             1364441 non-null  object        \n",
      " 12  EvaluationInfo_propertyValue          1364441 non-null  float64       \n",
      " 13  EvaluationInfo_landValue              1364441 non-null  float64       \n",
      " 14  EvaluationInfo_deductionSum           1364441 non-null  float64       \n",
      " 15  EvaluationInfo_usage                  1364441 non-null  object        \n",
      " 16  EvaluationInfo_residentialUnits       1364441 non-null  float64       \n",
      " 17  EvaluationInfo_propertyValueArea      1364441 non-null  float64       \n",
      " 18  EvaluationInfo_rebuildYear            1364441 non-null  float64       \n",
      " 19  EvaluationInfo_areaSize               1364441 non-null  float64       \n",
      " 20  RAW_dictionary_previousEstates        2623340 non-null  object        \n",
      " 21  salesInfo_MAIN_date_of_Sale           2623340 non-null  object        \n",
      " 22  salesInfo_ALL_sales_dates_by_main_ID  2623340 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](2), float64(11), int64(2), object(7)\n",
      "memory usage: 442.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_salesdata.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 8) Create column salesInfo_OTHER_sales_dates_by_main_ID  ------ where I have REMOVEd current row date from the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['salesInfo_OTHER_sales_dates_by_main_ID'] = data_salesdata.apply(\n",
    "    lambda row: row['salesInfo_ALL_sales_dates_by_main_ID'][:] if row['salesInfo_MAIN_date_of_Sale'] not in row['salesInfo_ALL_sales_dates_by_main_ID'] or not isinstance(row['salesInfo_ALL_sales_dates_by_main_ID'], list) or row['salesInfo_ALL_sales_dates_by_main_ID'] == []\n",
    "                else [date for date in row['salesInfo_ALL_sales_dates_by_main_ID'] if date != row['salesInfo_MAIN_date_of_Sale']],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- check result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          9133416f-191b-496e-88bb-62b3a46a370a\n",
       "1          9133416f-191b-496e-88bb-62b3a46a370a\n",
       "2          9133416f-191b-496e-88bb-62b3a46a370a\n",
       "3          9133416f-191b-496e-88bb-62b3a46a370a\n",
       "4          b1a52c68-cc3c-4ee0-b794-d9e638cc26e4\n",
       "                           ...                 \n",
       "2623335    845ce2df-d0ca-45cf-b6ca-df6ca620a685\n",
       "2623336    81ce9112-1089-4179-a38e-e89dd148faac\n",
       "2623337    81ce9112-1089-4179-a38e-e89dd148faac\n",
       "2623338    ac22bf6a-bb13-4092-be79-ad8951e0b5c3\n",
       "2623339    ac22bf6a-bb13-4092-be79-ad8951e0b5c3\n",
       "Name: RowID_MAIN_boliga_ROW_ID_unitID, Length: 2623340, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2007-09-12\n",
       "1   2023-01-18\n",
       "2   2017-12-11\n",
       "3   2007-09-27\n",
       "Name: salesInfo_deedIssueDate, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_deedIssueDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2007-09-12\n",
       "1    2023-11-08\n",
       "2    2017-12-11\n",
       "3    2007-09-27\n",
       "Name: salesInfo_MAIN_date_of_Sale, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_MAIN_date_of_Sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_ALL_sales_dates_by_main_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_OTHER_sales_dates_by_main_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['RAW_dictionary_previousEstates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Create column  salesInfo_OLDER_sales_dates_by_main_ID --- which is a list of dates of other transactions which are only older than the current date \n",
    "\n",
    "\n",
    "NOTE: CHANGE THIS USING salesInfo_MAIN_date_of_Sale NOT SALES DEED ISSUED ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2022-01-15'\n",
    "deed_issue_date = '2022-02-03'\n",
    "\n",
    "if date <= deed_issue_date:\n",
    "    \n",
    "    print('bingo')\n",
    "else:\n",
    "    print(f\"{date} is greater than {deed_issue_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['salesInfo_deedIssueDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'2007-09-12'<'2010-09-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['salesInfo_OLDER_sales_dates_by_main_ID'] = data_salesdata.apply(\n",
    "    lambda row: row['salesInfo_ALL_sales_dates_by_main_ID'][:] if row['salesInfo_MAIN_date_of_Sale'] not in row['salesInfo_ALL_sales_dates_by_main_ID'] or not isinstance(row['salesInfo_ALL_sales_dates_by_main_ID'], list) or row['salesInfo_ALL_sales_dates_by_main_ID'] == []\n",
    "                else [date for date in row['salesInfo_ALL_sales_dates_by_main_ID'] if date != row['salesInfo_MAIN_date_of_Sale'] and date <= row['salesInfo_MAIN_date_of_Sale']],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- CHECK RESULT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2007-09-12\n",
       "1   2023-01-18\n",
       "2   2017-12-11\n",
       "3   2007-09-27\n",
       "Name: salesInfo_deedIssueDate, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_deedIssueDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2007-09-12\n",
       "1    2023-11-08\n",
       "2    2017-12-11\n",
       "3    2007-09-27\n",
       "Name: salesInfo_MAIN_date_of_Sale, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_MAIN_date_of_Sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [2007-09-12, 2023-11-08, 2017-12-11, 2007-09-27]\n",
       "1    [2007-09-12, 2023-11-08, 2017-12-11, 2007-09-27]\n",
       "2    [2007-09-12, 2023-11-08, 2017-12-11, 2007-09-27]\n",
       "3    [2007-09-12, 2023-11-08, 2017-12-11, 2007-09-27]\n",
       "Name: salesInfo_ALL_sales_dates_by_main_ID, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_ALL_sales_dates_by_main_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [2023-11-08, 2017-12-11, 2007-09-27]\n",
       "1    [2007-09-12, 2017-12-11, 2007-09-27]\n",
       "2    [2007-09-12, 2023-11-08, 2007-09-27]\n",
       "3    [2007-09-12, 2023-11-08, 2017-12-11]\n",
       "Name: salesInfo_OTHER_sales_dates_by_main_ID, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_OTHER_sales_dates_by_main_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      []\n",
       "1    [2007-09-12, 2017-12-11, 2007-09-27]\n",
       "2                [2007-09-12, 2007-09-27]\n",
       "3                            [2007-09-12]\n",
       "Name: salesInfo_OLDER_sales_dates_by_main_ID, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_OLDER_sales_dates_by_main_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2623340 entries, 0 to 2623339\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                  Non-Null Count    Dtype         \n",
      "---  ------                                  --------------    -----         \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID         2623340 non-null  object        \n",
      " 1   salesInfo_isSalesValid                  2623340 non-null  bool          \n",
      " 2   salesInfo_handoverCode                  2623340 non-null  float64       \n",
      " 3   salesInfo_handoverName                  2623340 non-null  object        \n",
      " 4   salesInfo_deedIssueDate                 2623340 non-null  datetime64[ns]\n",
      " 5   salesInfo_price                         2623340 non-null  float64       \n",
      " 6   salesInfo_recalculationDate             2623340 non-null  datetime64[ns]\n",
      " 7   salesInfo_rebuildYear                   2623340 non-null  float64       \n",
      " 8   unique_sales_ID                         2623340 non-null  int64         \n",
      " 9   salesInfo_year_of_sale                  2623340 non-null  int64         \n",
      " 10  EvaluationInfo_evaluationYear           1364441 non-null  float64       \n",
      " 11  EvaluationInfo_lastChange               1364441 non-null  object        \n",
      " 12  EvaluationInfo_propertyValue            1364441 non-null  float64       \n",
      " 13  EvaluationInfo_landValue                1364441 non-null  float64       \n",
      " 14  EvaluationInfo_deductionSum             1364441 non-null  float64       \n",
      " 15  EvaluationInfo_usage                    1364441 non-null  object        \n",
      " 16  EvaluationInfo_residentialUnits         1364441 non-null  float64       \n",
      " 17  EvaluationInfo_propertyValueArea        1364441 non-null  float64       \n",
      " 18  EvaluationInfo_rebuildYear              1364441 non-null  float64       \n",
      " 19  EvaluationInfo_areaSize                 1364441 non-null  float64       \n",
      " 20  RAW_dictionary_previousEstates          2623340 non-null  object        \n",
      " 21  salesInfo_MAIN_date_of_Sale             2623340 non-null  object        \n",
      " 22  salesInfo_ALL_sales_dates_by_main_ID    2623340 non-null  object        \n",
      " 23  salesInfo_OTHER_sales_dates_by_main_ID  2623340 non-null  object        \n",
      " 24  salesInfo_OLDER_sales_dates_by_main_ID  2623340 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](2), float64(11), int64(2), object(9)\n",
      "memory usage: 482.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_salesdata.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- save THE RESULT AS IS : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_merge\\step_2_mrgin_newSales_with_Estate_ads\\setup\\setup_data_salesdata_step1_with_salesInfo_MAIN_date_of_Sale.csv'\n",
    "data_salesdata.to_csv(save_path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 10) : create column \"Relevant_Estates_ads_for_transaction\"\n",
    "\n",
    "* where I filter the RAW_dictionary_previousEstates for only dictionaries where\n",
    "    * \"lastSeen\" date is older than 'salesInfo_MAIN_date_of_Sale' \n",
    "    * and \"lastSeen\" is newer than all the dates in the list salesInfo_OLDER_sales_dates_by_main_ID             \n",
    "\n",
    "\n",
    "# pLAN : RUN THE CODE ON CHUNKS AND FOR EACH CHUNK WRITE TO CSV FILE CALLED setup_Relevant_Estates_ads_for_transaction_step_2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import ast\n",
    "import numpy as np\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_relevant_estates(row):\n",
    "    deed_issue_date = row['salesInfo_MAIN_date_of_Sale'] ######################################## <--------------salesInfo_MAIN_date_of_Sale NOT deed issued date\n",
    "    older_sales_dates = row['salesInfo_OLDER_sales_dates_by_main_ID']\n",
    "    estates_list = row['RAW_dictionary_previousEstates']\n",
    "\n",
    "    relevant_estates = []\n",
    "\n",
    "    # Check if 'RAW_dictionary_previousEstates' is a list\n",
    "    if isinstance(estates_list, list):\n",
    "        # Iterate over each dictionary in the list\n",
    "        for estate_dict in estates_list:\n",
    "            # Extract 'lastSeen' date from the dictionary\n",
    "            last_seen_date = pd.to_datetime(estate_dict.get('lastSeen', ''))\n",
    "            \n",
    "            # Check conditions for relevant estate\n",
    "            if last_seen_date < deed_issue_date:\n",
    "                if older_sales_dates != '[]' and older_sales_dates != '' and isinstance(older_sales_dates, list):\n",
    "                    if np.all(np.array([last_seen_date > pd.to_datetime(date) for date in older_sales_dates if pd.to_datetime(date, errors='coerce') is not pd.NaT])):\n",
    "                        relevant_estates.append(estate_dict)\n",
    "                else:\n",
    "                    relevant_estates.append(estate_dict)\n",
    "\n",
    "    return relevant_estates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================> chunk number:1 out of 27\n",
      "------>setting RAW_dictionary_previousEstate to dictionary object\n",
      "------>setting salesInfo_OLDER_sales_dates_by_main_ID to list\n",
      "------>setting salesInfo_deedIssueDate to datetime object\n",
      "------>setting [] to None in RAW_dictionary_previousEstates\n",
      "------>setting \"lastSeen\" to datetime object in dictionary\n",
      "------> Creating column : Relevant_Estates_ads_for_transaction!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'Timestamp' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 50\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#===========================================================\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Create the variable: Relevant_Estates_ads_for_transaction\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#===========================================================\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Apply the function using apply and axis=1\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------> Creating column : Relevant_Estates_ads_for_transaction!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m chunk_data_salesdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelevant_Estates_ads_for_transaction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m chunk_data_salesdata\u001b[38;5;241m.\u001b[39mapply(filter_relevant_estates, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Record the end time\u001b[39;00m\n\u001b[0;32m     53\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(v)\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m, in \u001b[0;36mfilter_relevant_estates\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     13\u001b[0m last_seen_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(estate_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlastSeen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Check conditions for relevant estate\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_seen_date \u001b[38;5;241m<\u001b[39m deed_issue_date:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m older_sales_dates \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m older_sales_dates \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(older_sales_dates, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39marray([last_seen_date \u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(date) \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m older_sales_dates \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mto_datetime(date, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mNaT])):\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'Timestamp' and 'str'"
     ]
    }
   ],
   "source": [
    "# Set the file paths\n",
    "input_file_path =  r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_merge\\step_2_mrgin_newSales_with_Estate_ads\\setup\\setup_data_salesdata_step1_with_salesInfo_MAIN_date_of_Sale.csv'\n",
    "output_file_path = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_merge\\step_2_mrgin_newSales_with_Estate_ads\\setup\\setup_Relevant_Estates_Variable_Ready_by_MAIN_date_of_Sale_Column.csv'\n",
    "\n",
    "\n",
    "# Set the chunk size based on your requirements\n",
    "chunk_size = 100000  # 100.000 rows (2623340/100000 = 26,23 = 27 chunks)\n",
    "\n",
    "# Read the file in chunks\n",
    "chunks = pd.read_csv(input_file_path, chunksize=chunk_size)\n",
    "\n",
    "# set bool var for header- only write header once\n",
    "missingHeader = True\n",
    "\n",
    "# count chunks \n",
    "chunk_counter = 0\n",
    "# Perform operations on each chunk\n",
    "for chunk_data_salesdata in chunks:\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    chunk_counter+=1 \n",
    "    print(f'============================> chunk number:{chunk_counter} out of 27')\n",
    "\n",
    "    # convert RAW_dictionary_previousEstate again to a dictionary object\n",
    "    print('------>setting RAW_dictionary_previousEstate to dictionary object')\n",
    "    chunk_data_salesdata['RAW_dictionary_previousEstates'] = chunk_data_salesdata['RAW_dictionary_previousEstates'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) and x!='[]' and x!='' and x is not None else x)\n",
    "\n",
    "    #convert salesInfo_OLDER_sales_dates_by_main_ID  to a list  (now its a string)\n",
    "    print('------>setting salesInfo_OLDER_sales_dates_by_main_ID to list')\n",
    "    chunk_data_salesdata['salesInfo_OLDER_sales_dates_by_main_ID'] = chunk_data_salesdata['salesInfo_OLDER_sales_dates_by_main_ID'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) and x!='' and x is not None else x) #and x!='[]'\n",
    "\n",
    "    # convert  salesInfo_deedIssueDate to a datetime object\n",
    "    print('------>setting salesInfo_deedIssueDate to datetime object')\n",
    "    chunk_data_salesdata['salesInfo_deedIssueDate'] = pd.to_datetime(chunk_data_salesdata['salesInfo_deedIssueDate'])#, format=\"%Y-%m-%d\")#.dt.date\n",
    "\n",
    "    # replace '[]' with None in RAW_dictionary_previousEstates\n",
    "    print('------>setting [] to None in RAW_dictionary_previousEstates')\n",
    "    chunk_data_salesdata['RAW_dictionary_previousEstates'] = chunk_data_salesdata['RAW_dictionary_previousEstates'].replace('[]',None)\n",
    "\n",
    "    # Change \"lastSeen\" key in dictionary \"RAW_dictionary_previousEstates\" to a datetime object\n",
    "    print('------>setting \"lastSeen\" to datetime object in dictionary')\n",
    "    chunk_data_salesdata['RAW_dictionary_previousEstates'] = chunk_data_salesdata['RAW_dictionary_previousEstates'].apply(lambda x: None if x is None or x == '[]' or x =='' else [{k: pd.to_datetime(v) if k == 'lastSeen' else v for k, v in d.items()} for d in x])\n",
    "\n",
    "    #===========================================================\n",
    "    # Create the variable: Relevant_Estates_ads_for_transaction\n",
    "    #===========================================================\n",
    "    # Apply the function using apply and axis=1\n",
    "    print('------> Creating column : Relevant_Estates_ads_for_transaction!')\n",
    "    chunk_data_salesdata['Relevant_Estates_ads_for_transaction'] = chunk_data_salesdata.apply(filter_relevant_estates, axis=1)\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate the runtime\n",
    "    runtime = end_time - start_time\n",
    "    print('********************************************************')\n",
    "    print(f'************** Time it took to run code: {runtime} seconds')\n",
    "    print('********************************************************')\n",
    "\n",
    "    \n",
    "    #===========================================================\n",
    "    # Save chunk dataframe to csv file (WRITE TO FILE)\n",
    "    #===========================================================\n",
    "    print('------> WRITING RESULT TO CSV FILE')\n",
    "    # Set header=False if you don't want to rewrite the header in each chunk\n",
    "    chunk_data_salesdata.to_csv(output_file_path, mode='a', index=False, header=missingHeader)\n",
    "    # dont write header again\n",
    "    missingHeader = False\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "    # Calculate the runtime\n",
    "    runtime = end_time - start_time\n",
    "    print('********************************************************')\n",
    "    print(f'************** TOTAL RUNTIME of chunk (with writing to csv): {runtime} seconds')\n",
    "    print('********************************************************')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------- read in file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2623340 entries, 0 to 2623339\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                  Non-Null Count    Dtype  \n",
      "---  ------                                  --------------    -----  \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID         2623340 non-null  object \n",
      " 1   salesInfo_isSalesValid                  2623340 non-null  bool   \n",
      " 2   salesInfo_handoverCode                  2623340 non-null  float64\n",
      " 3   salesInfo_handoverName                  2623340 non-null  object \n",
      " 4   salesInfo_deedIssueDate                 2623340 non-null  object \n",
      " 5   salesInfo_price                         2623340 non-null  float64\n",
      " 6   salesInfo_recalculationDate             2623340 non-null  object \n",
      " 7   salesInfo_rebuildYear                   2623340 non-null  float64\n",
      " 8   unique_sales_ID                         2623340 non-null  int64  \n",
      " 9   salesInfo_year_of_sale                  2623340 non-null  int64  \n",
      " 10  EvaluationInfo_evaluationYear           1364441 non-null  float64\n",
      " 11  EvaluationInfo_lastChange               1364441 non-null  object \n",
      " 12  EvaluationInfo_propertyValue            1364441 non-null  float64\n",
      " 13  EvaluationInfo_landValue                1364441 non-null  float64\n",
      " 14  EvaluationInfo_deductionSum             1364441 non-null  float64\n",
      " 15  EvaluationInfo_usage                    1364441 non-null  object \n",
      " 16  EvaluationInfo_residentialUnits         1364441 non-null  float64\n",
      " 17  EvaluationInfo_propertyValueArea        1364441 non-null  float64\n",
      " 18  EvaluationInfo_rebuildYear              1364441 non-null  float64\n",
      " 19  EvaluationInfo_areaSize                 1364441 non-null  float64\n",
      " 20  RAW_dictionary_previousEstates          1790826 non-null  object \n",
      " 21  salesInfo_ALL_sales_dates_by_main_ID    2623340 non-null  object \n",
      " 22  salesInfo_OTHER_sales_dates_by_main_ID  2623340 non-null  object \n",
      " 23  salesInfo_OLDER_sales_dates_by_main_ID  2623340 non-null  object \n",
      " 24  Relevant_Estates_ads_for_transaction    2623340 non-null  object \n",
      "dtypes: bool(1), float64(11), int64(2), object(11)\n",
      "memory usage: 482.8+ MB\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_merge\\step_2_mrgin_newSales_with_Estate_ads\\setup\\setup_Relevant_Estates_Variable_Ready.csv'\n",
    "data_salesdata = pd.read_csv(path, encoding='utf-8', low_memory=False)\n",
    "data_salesdata.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- clean up column Relevant_Estates_ads_for_transaction     from the string \"Timestamp()\" other wise eval_literal wont work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform the replacement\n",
    "def replace_timestamp(value):\n",
    "    return re.sub(pattern, r\"\\1\", value)\n",
    "\n",
    "\n",
    "# Define a regular expression pattern to match Timestamp('...')\n",
    "pattern = re.compile(r\"Timestamp\\(('[^']+?')\\)\")\n",
    "\n",
    "# Use map to apply the replacement to each string in the list\n",
    "data_salesdata['Relevant_Estates_ads_for_transaction'] = data_salesdata['Relevant_Estates_ads_for_transaction'].apply(lambda x: replace_timestamp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert each tring from single quoted to double qouted\n",
    "# data_salesdata['Relevant_Estates_ads_for_transaction'] = data_salesdata['Relevant_Estates_ads_for_transaction'].apply(lambda x: x.replace(\"'\", \"\\\"\") if x !='' and x !='[]' else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----- Convert column \"Relevant_Estates_ads_for_transaction\" to a list object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['Relevant_Estates_ads_for_transaction'] = data_salesdata['Relevant_Estates_ads_for_transaction'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) and x!='[]' and x!='' and x is not None else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estateId': 1931979,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 52,\n",
       "  'salesPrice': 3248000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1931/1931979.jpg',\n",
       "  'lastSeen': '2022-11-08 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1857402,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 242,\n",
       "  'salesPrice': 3348000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1857/1857402.jpg',\n",
       "  'lastSeen': '2022-09-14 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['Relevant_Estates_ads_for_transaction'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowID_MAIN_boliga_ROW_ID_unitID</th>\n",
       "      <th>salesInfo_isSalesValid</th>\n",
       "      <th>salesInfo_handoverCode</th>\n",
       "      <th>salesInfo_handoverName</th>\n",
       "      <th>salesInfo_deedIssueDate</th>\n",
       "      <th>salesInfo_price</th>\n",
       "      <th>salesInfo_recalculationDate</th>\n",
       "      <th>salesInfo_rebuildYear</th>\n",
       "      <th>unique_sales_ID</th>\n",
       "      <th>salesInfo_year_of_sale</th>\n",
       "      <th>...</th>\n",
       "      <th>EvaluationInfo_usage</th>\n",
       "      <th>EvaluationInfo_residentialUnits</th>\n",
       "      <th>EvaluationInfo_propertyValueArea</th>\n",
       "      <th>EvaluationInfo_rebuildYear</th>\n",
       "      <th>EvaluationInfo_areaSize</th>\n",
       "      <th>RAW_dictionary_previousEstates</th>\n",
       "      <th>salesInfo_ALL_sales_dates_by_main_ID</th>\n",
       "      <th>salesInfo_OTHER_sales_dates_by_main_ID</th>\n",
       "      <th>salesInfo_OLDER_sales_dates_by_main_ID</th>\n",
       "      <th>Relevant_Estates_ads_for_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9133416f-191b-496e-88bb-62b3a46a370a</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alm. frit salg</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>3050000.0</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>Beboelsesejendom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2250000.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>[{'estateId': 1931979, 'estateAddress': 'Rønne...</td>\n",
       "      <td>['2007-09-12', '2023-01-18', '2017-12-11', '20...</td>\n",
       "      <td>['2007-09-12', '2017-12-11', '2007-09-27']</td>\n",
       "      <td>['2007-09-12', '2017-12-11', '2007-09-27']</td>\n",
       "      <td>[{'estateId': 1931979, 'estateAddress': 'Rønne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9133416f-191b-496e-88bb-62b3a46a370a</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alm. frit salg</td>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>2910000.0</td>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>Beboelsesejendom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2250000.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>[{'estateId': 1931979, 'estateAddress': 'Rønne...</td>\n",
       "      <td>['2007-09-12', '2023-01-18', '2017-12-11', '20...</td>\n",
       "      <td>['2007-09-12', '2023-01-18', '2007-09-27']</td>\n",
       "      <td>['2007-09-12', '2007-09-27']</td>\n",
       "      <td>[{'estateId': 1352628, 'estateAddress': 'Rønne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1a52c68-cc3c-4ee0-b794-d9e638cc26e4</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alm. frit salg</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>3900000.0</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>Beboelsesejendom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>[{'estateId': 1988849, 'estateAddress': 'Ibsgå...</td>\n",
       "      <td>['2023-11-07']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'estateId': 1988849, 'estateAddress': 'Ibsgå...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f45b8fc3-af55-4907-b05e-bbc3f98c5935</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alm. frit salg</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>1160000.0</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>Beboelsesejendom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>530000.0</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>[{'estateId': 2023363, 'estateAddress': 'Gaabe...</td>\n",
       "      <td>['2023-11-07', '2016-08-26']</td>\n",
       "      <td>['2016-08-26']</td>\n",
       "      <td>['2016-08-26']</td>\n",
       "      <td>[{'estateId': 2023363, 'estateAddress': 'Gaabe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f45b8fc3-af55-4907-b05e-bbc3f98c5935</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alm. frit salg</td>\n",
       "      <td>2016-08-26</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>2016-08-03</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>Beboelsesejendom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>530000.0</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>[{'estateId': 2023363, 'estateAddress': 'Gaabe...</td>\n",
       "      <td>['2023-11-07', '2016-08-26']</td>\n",
       "      <td>['2023-11-07']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'estateId': 1223229, 'estateAddress': 'Gaabe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623113</th>\n",
       "      <td>fcd80f19-79c3-4847-a632-65eb64be9b3f</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alm. frit salg</td>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>1160000.0</td>\n",
       "      <td>2014-12-12</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>2623574</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>Ejerlejlighed, beboelse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>770000.0</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'estateId': 1370414, 'estateAddress': 'Bisid...</td>\n",
       "      <td>['1899-12-30', '2018-03-06', '1899-12-30', '20...</td>\n",
       "      <td>['1899-12-30', '2018-03-06', '1899-12-30', '20...</td>\n",
       "      <td>['1899-12-30', '1899-12-30', '1899-12-30', '20...</td>\n",
       "      <td>[{'estateId': 1022233, 'estateAddress': 'Bisid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623156</th>\n",
       "      <td>0a4e4a38-9d75-49d8-86cd-6d875dfe4c73</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Auktion</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>345000.0</td>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>2623617</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>Ejerlejlighed med beboelse i en-, to-, trefami...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560000.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'estateId': 1140517, 'estateAddress': 'Nyvej...</td>\n",
       "      <td>['2016-04-01', '2006-01-02', '2004-02-26']</td>\n",
       "      <td>['2006-01-02', '2004-02-26']</td>\n",
       "      <td>['2006-01-02', '2004-02-26']</td>\n",
       "      <td>[{'estateId': 1140517, 'estateAddress': 'Nyvej...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623237</th>\n",
       "      <td>24716e85-a89f-484e-bb9d-e2dea980f01c</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alm. frit salg</td>\n",
       "      <td>2012-03-16</td>\n",
       "      <td>1400000.0</td>\n",
       "      <td>2012-01-10</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>2623698</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>Beboelsesejendom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1350000.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>[{'estateId': 564069, 'estateAddress': 'Jystru...</td>\n",
       "      <td>['2012-03-16', '2012-03-16', '2004-08-14', '20...</td>\n",
       "      <td>['2004-08-14', '2006-02-02', '2017-03-17']</td>\n",
       "      <td>['2004-08-14', '2006-02-02']</td>\n",
       "      <td>[{'estateId': 564069, 'estateAddress': 'Jystru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623238</th>\n",
       "      <td>24716e85-a89f-484e-bb9d-e2dea980f01c</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alm. frit salg</td>\n",
       "      <td>2012-03-16</td>\n",
       "      <td>1400000.0</td>\n",
       "      <td>2012-01-10</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>2623699</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>Beboelsesejendom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1350000.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>[{'estateId': 564069, 'estateAddress': 'Jystru...</td>\n",
       "      <td>['2012-03-16', '2012-03-16', '2004-08-14', '20...</td>\n",
       "      <td>['2004-08-14', '2006-02-02', '2017-03-17']</td>\n",
       "      <td>['2004-08-14', '2006-02-02']</td>\n",
       "      <td>[{'estateId': 564069, 'estateAddress': 'Jystru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623286</th>\n",
       "      <td>cc09cd46-73fc-4258-ad84-2efcb907b661</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Auktion</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>995000.0</td>\n",
       "      <td>2010-08-24</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>2623747</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>Beboelsesejendom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>[{'estateId': 543780, 'estateAddress': 'Rugvan...</td>\n",
       "      <td>['2006-01-02', '2011-07-06']</td>\n",
       "      <td>['2006-01-02']</td>\n",
       "      <td>['2006-01-02']</td>\n",
       "      <td>[{'estateId': 543780, 'estateAddress': 'Rugvan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>847237 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              RowID_MAIN_boliga_ROW_ID_unitID  salesInfo_isSalesValid  \\\n",
       "1        9133416f-191b-496e-88bb-62b3a46a370a                    True   \n",
       "2        9133416f-191b-496e-88bb-62b3a46a370a                    True   \n",
       "4        b1a52c68-cc3c-4ee0-b794-d9e638cc26e4                    True   \n",
       "5        f45b8fc3-af55-4907-b05e-bbc3f98c5935                    True   \n",
       "6        f45b8fc3-af55-4907-b05e-bbc3f98c5935                    True   \n",
       "...                                       ...                     ...   \n",
       "2623113  fcd80f19-79c3-4847-a632-65eb64be9b3f                    True   \n",
       "2623156  0a4e4a38-9d75-49d8-86cd-6d875dfe4c73                    True   \n",
       "2623237  24716e85-a89f-484e-bb9d-e2dea980f01c                    True   \n",
       "2623238  24716e85-a89f-484e-bb9d-e2dea980f01c                    True   \n",
       "2623286  cc09cd46-73fc-4258-ad84-2efcb907b661                    True   \n",
       "\n",
       "         salesInfo_handoverCode salesInfo_handoverName  \\\n",
       "1                           1.0         Alm. frit salg   \n",
       "2                           1.0         Alm. frit salg   \n",
       "4                           1.0         Alm. frit salg   \n",
       "5                           1.0         Alm. frit salg   \n",
       "6                           1.0         Alm. frit salg   \n",
       "...                         ...                    ...   \n",
       "2623113                     1.0         Alm. frit salg   \n",
       "2623156                     3.0                Auktion   \n",
       "2623237                     1.0         Alm. frit salg   \n",
       "2623238                     1.0         Alm. frit salg   \n",
       "2623286                     3.0                Auktion   \n",
       "\n",
       "        salesInfo_deedIssueDate  salesInfo_price salesInfo_recalculationDate  \\\n",
       "1                    2023-01-18        3050000.0                  2023-11-08   \n",
       "2                    2017-12-11        2910000.0                  2017-08-30   \n",
       "4                    2023-11-07        3900000.0                  2023-11-07   \n",
       "5                    2023-11-07        1160000.0                  2023-11-07   \n",
       "6                    2016-08-26         275000.0                  2016-08-03   \n",
       "...                         ...              ...                         ...   \n",
       "2623113              2015-02-11        1160000.0                  2014-12-12   \n",
       "2623156              2016-04-01         345000.0                  2015-02-03   \n",
       "2623237              2012-03-16        1400000.0                  2012-01-10   \n",
       "2623238              2012-03-16        1400000.0                  2012-01-10   \n",
       "2623286              2011-07-06         995000.0                  2010-08-24   \n",
       "\n",
       "         salesInfo_rebuildYear  unique_sales_ID  salesInfo_year_of_sale  ...  \\\n",
       "1                       2008.0                2                    2023  ...   \n",
       "2                       2008.0                3                    2017  ...   \n",
       "4                       1976.0                5                    2023  ...   \n",
       "5                       1898.0                6                    2023  ...   \n",
       "6                       1898.0                7                    2016  ...   \n",
       "...                        ...              ...                     ...  ...   \n",
       "2623113                 1935.0          2623574                    2014  ...   \n",
       "2623156                 1890.0          2623617                    2015  ...   \n",
       "2623237                 1972.0          2623698                    2012  ...   \n",
       "2623238                 1972.0          2623699                    2012  ...   \n",
       "2623286                 1972.0          2623747                    2010  ...   \n",
       "\n",
       "                                      EvaluationInfo_usage  \\\n",
       "1                                         Beboelsesejendom   \n",
       "2                                         Beboelsesejendom   \n",
       "4                                         Beboelsesejendom   \n",
       "5                                         Beboelsesejendom   \n",
       "6                                         Beboelsesejendom   \n",
       "...                                                    ...   \n",
       "2623113                            Ejerlejlighed, beboelse   \n",
       "2623156  Ejerlejlighed med beboelse i en-, to-, trefami...   \n",
       "2623237                                   Beboelsesejendom   \n",
       "2623238                                   Beboelsesejendom   \n",
       "2623286                                   Beboelsesejendom   \n",
       "\n",
       "        EvaluationInfo_residentialUnits  EvaluationInfo_propertyValueArea  \\\n",
       "1                                   1.0                         2250000.0   \n",
       "2                                   1.0                         2250000.0   \n",
       "4                                   1.0                         2500000.0   \n",
       "5                                   1.0                          530000.0   \n",
       "6                                   1.0                          530000.0   \n",
       "...                                 ...                               ...   \n",
       "2623113                             1.0                          770000.0   \n",
       "2623156                             1.0                          560000.0   \n",
       "2623237                             1.0                         1350000.0   \n",
       "2623238                             1.0                         1350000.0   \n",
       "2623286                             1.0                         1650000.0   \n",
       "\n",
       "         EvaluationInfo_rebuildYear  EvaluationInfo_areaSize  \\\n",
       "1                            2008.0                    562.0   \n",
       "2                            2008.0                    562.0   \n",
       "4                            1976.0                    217.0   \n",
       "5                            1898.0                    343.0   \n",
       "6                            1898.0                    343.0   \n",
       "...                             ...                      ...   \n",
       "2623113                      1935.0                      0.0   \n",
       "2623156                      1890.0                      0.0   \n",
       "2623237                      1972.0                    683.0   \n",
       "2623238                      1972.0                    683.0   \n",
       "2623286                      1972.0                    841.0   \n",
       "\n",
       "                            RAW_dictionary_previousEstates  \\\n",
       "1        [{'estateId': 1931979, 'estateAddress': 'Rønne...   \n",
       "2        [{'estateId': 1931979, 'estateAddress': 'Rønne...   \n",
       "4        [{'estateId': 1988849, 'estateAddress': 'Ibsgå...   \n",
       "5        [{'estateId': 2023363, 'estateAddress': 'Gaabe...   \n",
       "6        [{'estateId': 2023363, 'estateAddress': 'Gaabe...   \n",
       "...                                                    ...   \n",
       "2623113  [{'estateId': 1370414, 'estateAddress': 'Bisid...   \n",
       "2623156  [{'estateId': 1140517, 'estateAddress': 'Nyvej...   \n",
       "2623237  [{'estateId': 564069, 'estateAddress': 'Jystru...   \n",
       "2623238  [{'estateId': 564069, 'estateAddress': 'Jystru...   \n",
       "2623286  [{'estateId': 543780, 'estateAddress': 'Rugvan...   \n",
       "\n",
       "                      salesInfo_ALL_sales_dates_by_main_ID  \\\n",
       "1        ['2007-09-12', '2023-01-18', '2017-12-11', '20...   \n",
       "2        ['2007-09-12', '2023-01-18', '2017-12-11', '20...   \n",
       "4                                           ['2023-11-07']   \n",
       "5                             ['2023-11-07', '2016-08-26']   \n",
       "6                             ['2023-11-07', '2016-08-26']   \n",
       "...                                                    ...   \n",
       "2623113  ['1899-12-30', '2018-03-06', '1899-12-30', '20...   \n",
       "2623156         ['2016-04-01', '2006-01-02', '2004-02-26']   \n",
       "2623237  ['2012-03-16', '2012-03-16', '2004-08-14', '20...   \n",
       "2623238  ['2012-03-16', '2012-03-16', '2004-08-14', '20...   \n",
       "2623286                       ['2006-01-02', '2011-07-06']   \n",
       "\n",
       "                    salesInfo_OTHER_sales_dates_by_main_ID  \\\n",
       "1               ['2007-09-12', '2017-12-11', '2007-09-27']   \n",
       "2               ['2007-09-12', '2023-01-18', '2007-09-27']   \n",
       "4                                                       []   \n",
       "5                                           ['2016-08-26']   \n",
       "6                                           ['2023-11-07']   \n",
       "...                                                    ...   \n",
       "2623113  ['1899-12-30', '2018-03-06', '1899-12-30', '20...   \n",
       "2623156                       ['2006-01-02', '2004-02-26']   \n",
       "2623237         ['2004-08-14', '2006-02-02', '2017-03-17']   \n",
       "2623238         ['2004-08-14', '2006-02-02', '2017-03-17']   \n",
       "2623286                                     ['2006-01-02']   \n",
       "\n",
       "                    salesInfo_OLDER_sales_dates_by_main_ID  \\\n",
       "1               ['2007-09-12', '2017-12-11', '2007-09-27']   \n",
       "2                             ['2007-09-12', '2007-09-27']   \n",
       "4                                                       []   \n",
       "5                                           ['2016-08-26']   \n",
       "6                                                       []   \n",
       "...                                                    ...   \n",
       "2623113  ['1899-12-30', '1899-12-30', '1899-12-30', '20...   \n",
       "2623156                       ['2006-01-02', '2004-02-26']   \n",
       "2623237                       ['2004-08-14', '2006-02-02']   \n",
       "2623238                       ['2004-08-14', '2006-02-02']   \n",
       "2623286                                     ['2006-01-02']   \n",
       "\n",
       "                      Relevant_Estates_ads_for_transaction  \n",
       "1        [{'estateId': 1931979, 'estateAddress': 'Rønne...  \n",
       "2        [{'estateId': 1352628, 'estateAddress': 'Rønne...  \n",
       "4        [{'estateId': 1988849, 'estateAddress': 'Ibsgå...  \n",
       "5        [{'estateId': 2023363, 'estateAddress': 'Gaabe...  \n",
       "6        [{'estateId': 1223229, 'estateAddress': 'Gaabe...  \n",
       "...                                                    ...  \n",
       "2623113  [{'estateId': 1022233, 'estateAddress': 'Bisid...  \n",
       "2623156  [{'estateId': 1140517, 'estateAddress': 'Nyvej...  \n",
       "2623237  [{'estateId': 564069, 'estateAddress': 'Jystru...  \n",
       "2623238  [{'estateId': 564069, 'estateAddress': 'Jystru...  \n",
       "2623286  [{'estateId': 543780, 'estateAddress': 'Rugvan...  \n",
       "\n",
       "[847237 rows x 25 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[~data_salesdata['Relevant_Estates_ads_for_transaction'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estateId': 1931979,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 52,\n",
       "  'salesPrice': 3248000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1931/1931979.jpg',\n",
       "  'lastSeen': '2022-11-08 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1857402,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 242,\n",
       "  'salesPrice': 3348000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1857/1857402.jpg',\n",
       "  'lastSeen': '2022-09-14 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID'] == '9133416f-191b-496e-88bb-62b3a46a370a']['Relevant_Estates_ads_for_transaction'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationInfo_usage\n",
       "Beboelsesejendom                                                        550181\n",
       "Ejerlejlighed, beboelse                                                 172796\n",
       "Landbrug, bebygget, mindst 0,55 Ha.                                      13352\n",
       "Ejerlejlighed med beboelse i en-, to-, trefamiliehus ell. dobbelthus     10401\n",
       "Ejerlejlighed med beboelse i rækkehusbebyggelse.                          7207\n",
       "Ubebygget areal (Ikke landbrugsareal), forskelsværdi max. 10 %            5281\n",
       "Beboelses- og forretningsejendom                                          4711\n",
       "Sommerhus.                                                                 897\n",
       "Ejerlejlighed, øvrige på fremmed grund.                                    808\n",
       "Ejerlejlighed, ren forretning                                              499\n",
       "Ejerlejlighed, iøvrigt.                                                    451\n",
       "Frugtplantage, gartneri og planteskole.                                    317\n",
       "Ren forretning.                                                            226\n",
       "Kommunal beboelses- og forretningsejendom.                                 213\n",
       "Privat institutions- og serviceejendom.                                    184\n",
       "Anden kommunal ejendom (Skole, rådhus m.v.).                               137\n",
       "Erhvervsejendom af speciel karakter                                        126\n",
       "Særskilt vurderet skov og plantage.                                        116\n",
       "Andre vurderinger.                                                         110\n",
       "Ejerlejlighed, beboelse og forretning                                      101\n",
       "Areal med bygning på fremmed grund.                                         44\n",
       "Beboelse på fremmed grund.                                                  34\n",
       "Fabrik og lager.                                                            17\n",
       "Ejerlejlighed, fabrik og lager.                                             15\n",
       "Ubebyggede landbrugslodder.                                                 13\n",
       "Statsejendom (Bebygget).                                                     4\n",
       "Opkrævningsejendom (Areal vurderet i anden kommune).                         2\n",
       "Anden bygning på fremmed grund.                                              2\n",
       "Sommerhus på fremmed grund.                                                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[~data_salesdata['Relevant_Estates_ads_for_transaction'].isna()]['EvaluationInfo_usage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================================================\n",
    "\n",
    "# NOW CREATE THE VARIABLES FROM THE ADS/ESTATES ! \n",
    "\n",
    "# ======================================================\n",
    "\n",
    "\n",
    "* Number_of_estates_ads\n",
    "* Number_of_days_between_ads\n",
    "* Total_daysForSale\n",
    "* NEWESTAd_askingPrice_lastAd\n",
    "* OLDESTAd_askingPrice_firstAd\n",
    "* NEWESTAd_daysForSale\n",
    "* OLDESTAd_daysForSale\n",
    "* NEWESTAd_lastSeen_Date\n",
    "* OLDESTAd_lastSeen_Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =======================> creating : Number_of_estates_ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                       None\n",
       "1          [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "2          [{'estateId': 1352628, 'estateAddress': 'Rønne...\n",
       "3                                                       None\n",
       "4          [{'estateId': 1988849, 'estateAddress': 'Ibsgå...\n",
       "                                 ...                        \n",
       "2623335                                                 None\n",
       "2623336                                                 None\n",
       "2623337                                                 None\n",
       "2623338                                                 None\n",
       "2623339                                                 None\n",
       "Name: Relevant_Estates_ads_for_transaction, Length: 2623340, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['Relevant_Estates_ads_for_transaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estateId': 1931979,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 52,\n",
       "  'salesPrice': 3248000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1931/1931979.jpg',\n",
       "  'lastSeen': '2022-11-08 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1857402,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 242,\n",
       "  'salesPrice': 3348000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1857/1857402.jpg',\n",
       "  'lastSeen': '2022-09-14 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['Relevant_Estates_ads_for_transaction'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['Estate_info_Number_of_estates_Ads'] = data_salesdata['Relevant_Estates_ads_for_transaction'].apply(lambda x: len(x) if isinstance(x,list) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Estate_info_Number_of_estates_Ads\n",
       "0     1776103\n",
       "1      658845\n",
       "2      135860\n",
       "3       35846\n",
       "4       11031\n",
       "5        3586\n",
       "6        1291\n",
       "7         443\n",
       "8         176\n",
       "9          77\n",
       "10         24\n",
       "15         15\n",
       "11         10\n",
       "13         10\n",
       "12          9\n",
       "18          8\n",
       "14          3\n",
       "21          1\n",
       "19          1\n",
       "23          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['Estate_info_Number_of_estates_Ads'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =======================> creating : Total_daysForSale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['Estate_info_Number_of_dayes_between_ads'] = data_salesdata['Relevant_Estates_ads_for_transaction'].apply(\n",
    "    lambda ads_list: sum(ad.get('daysForSale', 0) for ad in (ads_list if ads_list is not None else [])) ### use [] because sum() function need an iterable, cant set to 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estateId': 1931979,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 52,\n",
       "  'salesPrice': 3248000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1931/1931979.jpg',\n",
       "  'lastSeen': '2022-11-08 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1857402,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 242,\n",
       "  'salesPrice': 3348000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1857/1857402.jpg',\n",
       "  'lastSeen': '2022-09-14 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['Relevant_Estates_ads_for_transaction'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['Estate_info_Number_of_dayes_between_ads'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estateId': 1931979,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 52,\n",
       "  'salesPrice': 3248000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1931/1931979.jpg',\n",
       "  'lastSeen': '2022-11-08 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1857402,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 242,\n",
       "  'salesPrice': 3348000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1857/1857402.jpg',\n",
       "  'lastSeen': '2022-09-14 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['Relevant_Estates_ads_for_transaction'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estateId': 1857402,\n",
       " 'estateAddress': 'Rønnevangen 1',\n",
       " 'daysForSale': 242,\n",
       " 'salesPrice': 3348000,\n",
       " 'imageUrl': 'https://i.boliga.org/dk/550x/1857/1857402.jpg',\n",
       " 'lastSeen': '2022-09-14 00:00:00',\n",
       " 'zipCode': 8471,\n",
       " 'city': 'Sabro'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newest_dict = min(data_salesdata['Relevant_Estates_ads_for_transaction'][1], key=lambda x: x['lastSeen'])\n",
    "newest_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### =======================> creating : NEWESTAd_askingPrice_lastAd\n",
    "##### =======================> creating : OLDESTAd_askingPrice_firstAd\n",
    "##### =======================> creating : NEWESTAd_daysForSale\n",
    "##### =======================> creating : OLDESTAd_daysForSale\n",
    "##### =======================> creating : NEWESTAd_lastSeen_Date\n",
    "##### =======================> creating : OLDESTAd_lastSeen_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Create variables in dataframe \n",
    "\n",
    "data_salesdata['Estate_Info_NEWESTAd_askingPrice_lastAd'] = None\n",
    "data_salesdata['Estate_Info_NEWESTAd_daysForSale'] = None\n",
    "data_salesdata['Estate_Info_NEWESTAd_lastSeen_Date'] = None\n",
    "data_salesdata['Estate_Info_OLDESTAd_askingPrice_firstAd'] = None\n",
    "data_salesdata['Estate_Info_OLDESTAd_daysForSale'] = None\n",
    "data_salesdata['Estate_Info_OLDESTAd_lastSeen_Date'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "847237"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_salesdata[~data_salesdata['Relevant_Estates_ads_for_transaction'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows gone over: 1000 out of 847.237\n",
      "Number of rows gone over: 2000 out of 847.237\n",
      "Number of rows gone over: 3000 out of 847.237\n",
      "Number of rows gone over: 4000 out of 847.237\n",
      "Number of rows gone over: 5000 out of 847.237\n",
      "Number of rows gone over: 6000 out of 847.237\n",
      "Number of rows gone over: 7000 out of 847.237\n",
      "Number of rows gone over: 8000 out of 847.237\n",
      "Number of rows gone over: 9000 out of 847.237\n",
      "Number of rows gone over: 10000 out of 847.237\n",
      "Number of rows gone over: 11000 out of 847.237\n",
      "Number of rows gone over: 12000 out of 847.237\n",
      "Number of rows gone over: 13000 out of 847.237\n",
      "Number of rows gone over: 14000 out of 847.237\n",
      "Number of rows gone over: 15000 out of 847.237\n",
      "Number of rows gone over: 16000 out of 847.237\n",
      "Number of rows gone over: 17000 out of 847.237\n",
      "Number of rows gone over: 18000 out of 847.237\n",
      "Number of rows gone over: 19000 out of 847.237\n",
      "Number of rows gone over: 20000 out of 847.237\n",
      "Number of rows gone over: 21000 out of 847.237\n",
      "Number of rows gone over: 22000 out of 847.237\n",
      "Number of rows gone over: 23000 out of 847.237\n",
      "Number of rows gone over: 24000 out of 847.237\n",
      "Number of rows gone over: 25000 out of 847.237\n",
      "Number of rows gone over: 26000 out of 847.237\n",
      "Number of rows gone over: 27000 out of 847.237\n",
      "Number of rows gone over: 28000 out of 847.237\n",
      "Number of rows gone over: 29000 out of 847.237\n",
      "Number of rows gone over: 30000 out of 847.237\n",
      "Number of rows gone over: 31000 out of 847.237\n",
      "Number of rows gone over: 32000 out of 847.237\n",
      "Number of rows gone over: 33000 out of 847.237\n",
      "Number of rows gone over: 34000 out of 847.237\n",
      "Number of rows gone over: 35000 out of 847.237\n",
      "Number of rows gone over: 36000 out of 847.237\n",
      "Number of rows gone over: 37000 out of 847.237\n",
      "Number of rows gone over: 38000 out of 847.237\n",
      "Number of rows gone over: 39000 out of 847.237\n",
      "Number of rows gone over: 40000 out of 847.237\n",
      "Number of rows gone over: 41000 out of 847.237\n",
      "Number of rows gone over: 42000 out of 847.237\n",
      "Number of rows gone over: 43000 out of 847.237\n",
      "Number of rows gone over: 44000 out of 847.237\n",
      "Number of rows gone over: 45000 out of 847.237\n",
      "Number of rows gone over: 46000 out of 847.237\n",
      "Number of rows gone over: 47000 out of 847.237\n",
      "Number of rows gone over: 48000 out of 847.237\n",
      "Number of rows gone over: 49000 out of 847.237\n",
      "Number of rows gone over: 50000 out of 847.237\n",
      "Number of rows gone over: 51000 out of 847.237\n",
      "Number of rows gone over: 52000 out of 847.237\n",
      "Number of rows gone over: 53000 out of 847.237\n",
      "Number of rows gone over: 54000 out of 847.237\n",
      "Number of rows gone over: 55000 out of 847.237\n",
      "Number of rows gone over: 56000 out of 847.237\n",
      "Number of rows gone over: 57000 out of 847.237\n",
      "Number of rows gone over: 58000 out of 847.237\n",
      "Number of rows gone over: 59000 out of 847.237\n",
      "Number of rows gone over: 60000 out of 847.237\n",
      "Number of rows gone over: 61000 out of 847.237\n",
      "Number of rows gone over: 62000 out of 847.237\n",
      "Number of rows gone over: 63000 out of 847.237\n",
      "Number of rows gone over: 64000 out of 847.237\n",
      "Number of rows gone over: 65000 out of 847.237\n",
      "Number of rows gone over: 66000 out of 847.237\n",
      "Number of rows gone over: 67000 out of 847.237\n",
      "Number of rows gone over: 68000 out of 847.237\n",
      "Number of rows gone over: 69000 out of 847.237\n",
      "Number of rows gone over: 70000 out of 847.237\n",
      "Number of rows gone over: 71000 out of 847.237\n",
      "Number of rows gone over: 72000 out of 847.237\n",
      "Number of rows gone over: 73000 out of 847.237\n",
      "Number of rows gone over: 74000 out of 847.237\n",
      "Number of rows gone over: 75000 out of 847.237\n",
      "Number of rows gone over: 76000 out of 847.237\n",
      "Number of rows gone over: 77000 out of 847.237\n",
      "Number of rows gone over: 78000 out of 847.237\n",
      "Number of rows gone over: 79000 out of 847.237\n",
      "Number of rows gone over: 80000 out of 847.237\n",
      "Number of rows gone over: 81000 out of 847.237\n",
      "Number of rows gone over: 82000 out of 847.237\n",
      "Number of rows gone over: 83000 out of 847.237\n",
      "Number of rows gone over: 84000 out of 847.237\n",
      "Number of rows gone over: 85000 out of 847.237\n",
      "Number of rows gone over: 86000 out of 847.237\n",
      "Number of rows gone over: 87000 out of 847.237\n",
      "Number of rows gone over: 88000 out of 847.237\n",
      "Number of rows gone over: 89000 out of 847.237\n",
      "Number of rows gone over: 90000 out of 847.237\n",
      "Number of rows gone over: 91000 out of 847.237\n",
      "Number of rows gone over: 92000 out of 847.237\n",
      "Number of rows gone over: 93000 out of 847.237\n",
      "Number of rows gone over: 94000 out of 847.237\n",
      "Number of rows gone over: 95000 out of 847.237\n",
      "Number of rows gone over: 96000 out of 847.237\n",
      "Number of rows gone over: 97000 out of 847.237\n",
      "Number of rows gone over: 98000 out of 847.237\n",
      "Number of rows gone over: 99000 out of 847.237\n",
      "Number of rows gone over: 100000 out of 847.237\n",
      "Number of rows gone over: 101000 out of 847.237\n",
      "Number of rows gone over: 102000 out of 847.237\n",
      "Number of rows gone over: 103000 out of 847.237\n",
      "Number of rows gone over: 104000 out of 847.237\n",
      "Number of rows gone over: 105000 out of 847.237\n",
      "Number of rows gone over: 106000 out of 847.237\n",
      "Number of rows gone over: 107000 out of 847.237\n",
      "Number of rows gone over: 108000 out of 847.237\n",
      "Number of rows gone over: 109000 out of 847.237\n",
      "Number of rows gone over: 110000 out of 847.237\n",
      "Number of rows gone over: 111000 out of 847.237\n",
      "Number of rows gone over: 112000 out of 847.237\n",
      "Number of rows gone over: 113000 out of 847.237\n",
      "Number of rows gone over: 114000 out of 847.237\n",
      "Number of rows gone over: 115000 out of 847.237\n",
      "Number of rows gone over: 116000 out of 847.237\n",
      "Number of rows gone over: 117000 out of 847.237\n",
      "Number of rows gone over: 118000 out of 847.237\n",
      "Number of rows gone over: 119000 out of 847.237\n",
      "Number of rows gone over: 120000 out of 847.237\n",
      "Number of rows gone over: 121000 out of 847.237\n",
      "Number of rows gone over: 122000 out of 847.237\n",
      "Number of rows gone over: 123000 out of 847.237\n",
      "Number of rows gone over: 124000 out of 847.237\n",
      "Number of rows gone over: 125000 out of 847.237\n",
      "Number of rows gone over: 126000 out of 847.237\n",
      "Number of rows gone over: 127000 out of 847.237\n",
      "Number of rows gone over: 128000 out of 847.237\n",
      "Number of rows gone over: 129000 out of 847.237\n",
      "Number of rows gone over: 130000 out of 847.237\n",
      "Number of rows gone over: 131000 out of 847.237\n",
      "Number of rows gone over: 132000 out of 847.237\n",
      "Number of rows gone over: 133000 out of 847.237\n",
      "Number of rows gone over: 134000 out of 847.237\n",
      "Number of rows gone over: 135000 out of 847.237\n",
      "Number of rows gone over: 136000 out of 847.237\n",
      "Number of rows gone over: 137000 out of 847.237\n",
      "Number of rows gone over: 138000 out of 847.237\n",
      "Number of rows gone over: 139000 out of 847.237\n",
      "Number of rows gone over: 140000 out of 847.237\n",
      "Number of rows gone over: 141000 out of 847.237\n",
      "Number of rows gone over: 142000 out of 847.237\n",
      "Number of rows gone over: 143000 out of 847.237\n",
      "Number of rows gone over: 144000 out of 847.237\n",
      "Number of rows gone over: 145000 out of 847.237\n",
      "Number of rows gone over: 146000 out of 847.237\n",
      "Number of rows gone over: 147000 out of 847.237\n",
      "Number of rows gone over: 148000 out of 847.237\n",
      "Number of rows gone over: 149000 out of 847.237\n",
      "Number of rows gone over: 150000 out of 847.237\n",
      "Number of rows gone over: 151000 out of 847.237\n",
      "Number of rows gone over: 152000 out of 847.237\n",
      "Number of rows gone over: 153000 out of 847.237\n",
      "Number of rows gone over: 154000 out of 847.237\n",
      "Number of rows gone over: 155000 out of 847.237\n",
      "Number of rows gone over: 156000 out of 847.237\n",
      "Number of rows gone over: 157000 out of 847.237\n",
      "Number of rows gone over: 158000 out of 847.237\n",
      "Number of rows gone over: 159000 out of 847.237\n",
      "Number of rows gone over: 160000 out of 847.237\n",
      "Number of rows gone over: 161000 out of 847.237\n",
      "Number of rows gone over: 162000 out of 847.237\n",
      "Number of rows gone over: 163000 out of 847.237\n",
      "Number of rows gone over: 164000 out of 847.237\n",
      "Number of rows gone over: 165000 out of 847.237\n",
      "Number of rows gone over: 166000 out of 847.237\n",
      "Number of rows gone over: 167000 out of 847.237\n",
      "Number of rows gone over: 168000 out of 847.237\n",
      "Number of rows gone over: 169000 out of 847.237\n",
      "Number of rows gone over: 170000 out of 847.237\n",
      "Number of rows gone over: 171000 out of 847.237\n",
      "Number of rows gone over: 172000 out of 847.237\n",
      "Number of rows gone over: 173000 out of 847.237\n",
      "Number of rows gone over: 174000 out of 847.237\n",
      "Number of rows gone over: 175000 out of 847.237\n",
      "Number of rows gone over: 176000 out of 847.237\n",
      "Number of rows gone over: 177000 out of 847.237\n",
      "Number of rows gone over: 178000 out of 847.237\n",
      "Number of rows gone over: 179000 out of 847.237\n",
      "Number of rows gone over: 180000 out of 847.237\n",
      "Number of rows gone over: 181000 out of 847.237\n",
      "Number of rows gone over: 182000 out of 847.237\n",
      "Number of rows gone over: 183000 out of 847.237\n",
      "Number of rows gone over: 184000 out of 847.237\n",
      "Number of rows gone over: 185000 out of 847.237\n",
      "Number of rows gone over: 186000 out of 847.237\n",
      "Number of rows gone over: 187000 out of 847.237\n",
      "Number of rows gone over: 188000 out of 847.237\n",
      "Number of rows gone over: 189000 out of 847.237\n",
      "Number of rows gone over: 190000 out of 847.237\n",
      "Number of rows gone over: 191000 out of 847.237\n",
      "Number of rows gone over: 192000 out of 847.237\n",
      "Number of rows gone over: 193000 out of 847.237\n",
      "Number of rows gone over: 194000 out of 847.237\n",
      "Number of rows gone over: 195000 out of 847.237\n",
      "Number of rows gone over: 196000 out of 847.237\n",
      "Number of rows gone over: 197000 out of 847.237\n",
      "Number of rows gone over: 198000 out of 847.237\n",
      "Number of rows gone over: 199000 out of 847.237\n",
      "Number of rows gone over: 200000 out of 847.237\n",
      "Number of rows gone over: 201000 out of 847.237\n",
      "Number of rows gone over: 202000 out of 847.237\n",
      "Number of rows gone over: 203000 out of 847.237\n",
      "Number of rows gone over: 204000 out of 847.237\n",
      "Number of rows gone over: 205000 out of 847.237\n",
      "Number of rows gone over: 206000 out of 847.237\n",
      "Number of rows gone over: 207000 out of 847.237\n",
      "Number of rows gone over: 208000 out of 847.237\n",
      "Number of rows gone over: 209000 out of 847.237\n",
      "Number of rows gone over: 210000 out of 847.237\n",
      "Number of rows gone over: 211000 out of 847.237\n",
      "Number of rows gone over: 212000 out of 847.237\n",
      "Number of rows gone over: 213000 out of 847.237\n",
      "Number of rows gone over: 214000 out of 847.237\n",
      "Number of rows gone over: 215000 out of 847.237\n",
      "Number of rows gone over: 216000 out of 847.237\n",
      "Number of rows gone over: 217000 out of 847.237\n",
      "Number of rows gone over: 218000 out of 847.237\n",
      "Number of rows gone over: 219000 out of 847.237\n",
      "Number of rows gone over: 220000 out of 847.237\n",
      "Number of rows gone over: 221000 out of 847.237\n",
      "Number of rows gone over: 222000 out of 847.237\n",
      "Number of rows gone over: 223000 out of 847.237\n",
      "Number of rows gone over: 224000 out of 847.237\n",
      "Number of rows gone over: 225000 out of 847.237\n",
      "Number of rows gone over: 226000 out of 847.237\n",
      "Number of rows gone over: 227000 out of 847.237\n",
      "Number of rows gone over: 228000 out of 847.237\n",
      "Number of rows gone over: 229000 out of 847.237\n",
      "Number of rows gone over: 230000 out of 847.237\n",
      "Number of rows gone over: 231000 out of 847.237\n",
      "Number of rows gone over: 232000 out of 847.237\n",
      "Number of rows gone over: 233000 out of 847.237\n",
      "Number of rows gone over: 234000 out of 847.237\n",
      "Number of rows gone over: 235000 out of 847.237\n",
      "Number of rows gone over: 236000 out of 847.237\n",
      "Number of rows gone over: 237000 out of 847.237\n",
      "Number of rows gone over: 238000 out of 847.237\n",
      "Number of rows gone over: 239000 out of 847.237\n",
      "Number of rows gone over: 240000 out of 847.237\n",
      "Number of rows gone over: 241000 out of 847.237\n",
      "Number of rows gone over: 242000 out of 847.237\n",
      "Number of rows gone over: 243000 out of 847.237\n",
      "Number of rows gone over: 244000 out of 847.237\n",
      "Number of rows gone over: 245000 out of 847.237\n",
      "Number of rows gone over: 246000 out of 847.237\n",
      "Number of rows gone over: 247000 out of 847.237\n",
      "Number of rows gone over: 248000 out of 847.237\n",
      "Number of rows gone over: 249000 out of 847.237\n",
      "Number of rows gone over: 250000 out of 847.237\n",
      "Number of rows gone over: 251000 out of 847.237\n",
      "Number of rows gone over: 252000 out of 847.237\n",
      "Number of rows gone over: 253000 out of 847.237\n",
      "Number of rows gone over: 254000 out of 847.237\n",
      "Number of rows gone over: 255000 out of 847.237\n",
      "Number of rows gone over: 256000 out of 847.237\n",
      "Number of rows gone over: 257000 out of 847.237\n",
      "Number of rows gone over: 258000 out of 847.237\n",
      "Number of rows gone over: 259000 out of 847.237\n",
      "Number of rows gone over: 260000 out of 847.237\n",
      "Number of rows gone over: 261000 out of 847.237\n",
      "Number of rows gone over: 262000 out of 847.237\n",
      "Number of rows gone over: 263000 out of 847.237\n",
      "Number of rows gone over: 264000 out of 847.237\n",
      "Number of rows gone over: 265000 out of 847.237\n",
      "Number of rows gone over: 266000 out of 847.237\n",
      "Number of rows gone over: 267000 out of 847.237\n",
      "Number of rows gone over: 268000 out of 847.237\n",
      "Number of rows gone over: 269000 out of 847.237\n",
      "Number of rows gone over: 270000 out of 847.237\n",
      "Number of rows gone over: 271000 out of 847.237\n",
      "Number of rows gone over: 272000 out of 847.237\n",
      "Number of rows gone over: 273000 out of 847.237\n",
      "Number of rows gone over: 274000 out of 847.237\n",
      "Number of rows gone over: 275000 out of 847.237\n",
      "Number of rows gone over: 276000 out of 847.237\n",
      "Number of rows gone over: 277000 out of 847.237\n",
      "Number of rows gone over: 278000 out of 847.237\n",
      "Number of rows gone over: 279000 out of 847.237\n",
      "Number of rows gone over: 280000 out of 847.237\n",
      "Number of rows gone over: 281000 out of 847.237\n",
      "Number of rows gone over: 282000 out of 847.237\n",
      "Number of rows gone over: 283000 out of 847.237\n",
      "Number of rows gone over: 284000 out of 847.237\n",
      "Number of rows gone over: 285000 out of 847.237\n",
      "Number of rows gone over: 286000 out of 847.237\n",
      "Number of rows gone over: 287000 out of 847.237\n",
      "Number of rows gone over: 288000 out of 847.237\n",
      "Number of rows gone over: 289000 out of 847.237\n",
      "Number of rows gone over: 290000 out of 847.237\n",
      "Number of rows gone over: 291000 out of 847.237\n",
      "Number of rows gone over: 292000 out of 847.237\n",
      "Number of rows gone over: 293000 out of 847.237\n",
      "Number of rows gone over: 294000 out of 847.237\n",
      "Number of rows gone over: 295000 out of 847.237\n",
      "Number of rows gone over: 296000 out of 847.237\n",
      "Number of rows gone over: 297000 out of 847.237\n",
      "Number of rows gone over: 298000 out of 847.237\n",
      "Number of rows gone over: 299000 out of 847.237\n",
      "Number of rows gone over: 300000 out of 847.237\n",
      "Number of rows gone over: 301000 out of 847.237\n",
      "Number of rows gone over: 302000 out of 847.237\n",
      "Number of rows gone over: 303000 out of 847.237\n",
      "Number of rows gone over: 304000 out of 847.237\n",
      "Number of rows gone over: 305000 out of 847.237\n",
      "Number of rows gone over: 306000 out of 847.237\n",
      "Number of rows gone over: 307000 out of 847.237\n",
      "Number of rows gone over: 308000 out of 847.237\n",
      "Number of rows gone over: 309000 out of 847.237\n",
      "Number of rows gone over: 310000 out of 847.237\n",
      "Number of rows gone over: 311000 out of 847.237\n",
      "Number of rows gone over: 312000 out of 847.237\n",
      "Number of rows gone over: 313000 out of 847.237\n",
      "Number of rows gone over: 314000 out of 847.237\n",
      "Number of rows gone over: 315000 out of 847.237\n",
      "Number of rows gone over: 316000 out of 847.237\n",
      "Number of rows gone over: 317000 out of 847.237\n",
      "Number of rows gone over: 318000 out of 847.237\n",
      "Number of rows gone over: 319000 out of 847.237\n",
      "Number of rows gone over: 320000 out of 847.237\n",
      "Number of rows gone over: 321000 out of 847.237\n",
      "Number of rows gone over: 322000 out of 847.237\n",
      "Number of rows gone over: 323000 out of 847.237\n",
      "Number of rows gone over: 324000 out of 847.237\n",
      "Number of rows gone over: 325000 out of 847.237\n",
      "Number of rows gone over: 326000 out of 847.237\n",
      "Number of rows gone over: 327000 out of 847.237\n",
      "Number of rows gone over: 328000 out of 847.237\n",
      "Number of rows gone over: 329000 out of 847.237\n",
      "Number of rows gone over: 330000 out of 847.237\n",
      "Number of rows gone over: 331000 out of 847.237\n",
      "Number of rows gone over: 332000 out of 847.237\n",
      "Number of rows gone over: 333000 out of 847.237\n",
      "Number of rows gone over: 334000 out of 847.237\n",
      "Number of rows gone over: 335000 out of 847.237\n",
      "Number of rows gone over: 336000 out of 847.237\n",
      "Number of rows gone over: 337000 out of 847.237\n",
      "Number of rows gone over: 338000 out of 847.237\n",
      "Number of rows gone over: 339000 out of 847.237\n",
      "Number of rows gone over: 340000 out of 847.237\n",
      "Number of rows gone over: 341000 out of 847.237\n",
      "Number of rows gone over: 342000 out of 847.237\n",
      "Number of rows gone over: 343000 out of 847.237\n",
      "Number of rows gone over: 344000 out of 847.237\n",
      "Number of rows gone over: 345000 out of 847.237\n",
      "Number of rows gone over: 346000 out of 847.237\n",
      "Number of rows gone over: 347000 out of 847.237\n",
      "Number of rows gone over: 348000 out of 847.237\n",
      "Number of rows gone over: 349000 out of 847.237\n",
      "Number of rows gone over: 350000 out of 847.237\n",
      "Number of rows gone over: 351000 out of 847.237\n",
      "Number of rows gone over: 352000 out of 847.237\n",
      "Number of rows gone over: 353000 out of 847.237\n",
      "Number of rows gone over: 354000 out of 847.237\n",
      "Number of rows gone over: 355000 out of 847.237\n",
      "Number of rows gone over: 356000 out of 847.237\n",
      "Number of rows gone over: 357000 out of 847.237\n",
      "Number of rows gone over: 358000 out of 847.237\n",
      "Number of rows gone over: 359000 out of 847.237\n",
      "Number of rows gone over: 360000 out of 847.237\n",
      "Number of rows gone over: 361000 out of 847.237\n",
      "Number of rows gone over: 362000 out of 847.237\n",
      "Number of rows gone over: 363000 out of 847.237\n",
      "Number of rows gone over: 364000 out of 847.237\n",
      "Number of rows gone over: 365000 out of 847.237\n",
      "Number of rows gone over: 366000 out of 847.237\n",
      "Number of rows gone over: 367000 out of 847.237\n",
      "Number of rows gone over: 368000 out of 847.237\n",
      "Number of rows gone over: 369000 out of 847.237\n",
      "Number of rows gone over: 370000 out of 847.237\n",
      "Number of rows gone over: 371000 out of 847.237\n",
      "Number of rows gone over: 372000 out of 847.237\n",
      "Number of rows gone over: 373000 out of 847.237\n",
      "Number of rows gone over: 374000 out of 847.237\n",
      "Number of rows gone over: 375000 out of 847.237\n",
      "Number of rows gone over: 376000 out of 847.237\n",
      "Number of rows gone over: 377000 out of 847.237\n",
      "Number of rows gone over: 378000 out of 847.237\n",
      "Number of rows gone over: 379000 out of 847.237\n",
      "Number of rows gone over: 380000 out of 847.237\n",
      "Number of rows gone over: 381000 out of 847.237\n",
      "Number of rows gone over: 382000 out of 847.237\n",
      "Number of rows gone over: 383000 out of 847.237\n",
      "Number of rows gone over: 384000 out of 847.237\n",
      "Number of rows gone over: 385000 out of 847.237\n",
      "Number of rows gone over: 386000 out of 847.237\n",
      "Number of rows gone over: 387000 out of 847.237\n",
      "Number of rows gone over: 388000 out of 847.237\n",
      "Number of rows gone over: 389000 out of 847.237\n",
      "Number of rows gone over: 390000 out of 847.237\n",
      "Number of rows gone over: 391000 out of 847.237\n",
      "Number of rows gone over: 392000 out of 847.237\n",
      "Number of rows gone over: 393000 out of 847.237\n",
      "Number of rows gone over: 394000 out of 847.237\n",
      "Number of rows gone over: 395000 out of 847.237\n",
      "Number of rows gone over: 396000 out of 847.237\n",
      "Number of rows gone over: 397000 out of 847.237\n",
      "Number of rows gone over: 398000 out of 847.237\n",
      "Number of rows gone over: 399000 out of 847.237\n",
      "Number of rows gone over: 400000 out of 847.237\n",
      "Number of rows gone over: 401000 out of 847.237\n",
      "Number of rows gone over: 402000 out of 847.237\n",
      "Number of rows gone over: 403000 out of 847.237\n",
      "Number of rows gone over: 404000 out of 847.237\n",
      "Number of rows gone over: 405000 out of 847.237\n",
      "Number of rows gone over: 406000 out of 847.237\n",
      "Number of rows gone over: 407000 out of 847.237\n",
      "Number of rows gone over: 408000 out of 847.237\n",
      "Number of rows gone over: 409000 out of 847.237\n",
      "Number of rows gone over: 410000 out of 847.237\n",
      "Number of rows gone over: 411000 out of 847.237\n",
      "Number of rows gone over: 412000 out of 847.237\n",
      "Number of rows gone over: 413000 out of 847.237\n",
      "Number of rows gone over: 414000 out of 847.237\n",
      "Number of rows gone over: 415000 out of 847.237\n",
      "Number of rows gone over: 416000 out of 847.237\n",
      "Number of rows gone over: 417000 out of 847.237\n",
      "Number of rows gone over: 418000 out of 847.237\n",
      "Number of rows gone over: 419000 out of 847.237\n",
      "Number of rows gone over: 420000 out of 847.237\n",
      "Number of rows gone over: 421000 out of 847.237\n",
      "Number of rows gone over: 422000 out of 847.237\n",
      "Number of rows gone over: 423000 out of 847.237\n",
      "Number of rows gone over: 424000 out of 847.237\n",
      "Number of rows gone over: 425000 out of 847.237\n",
      "Number of rows gone over: 426000 out of 847.237\n",
      "Number of rows gone over: 427000 out of 847.237\n",
      "Number of rows gone over: 428000 out of 847.237\n",
      "Number of rows gone over: 429000 out of 847.237\n",
      "Number of rows gone over: 430000 out of 847.237\n",
      "Number of rows gone over: 431000 out of 847.237\n",
      "Number of rows gone over: 432000 out of 847.237\n",
      "Number of rows gone over: 433000 out of 847.237\n",
      "Number of rows gone over: 434000 out of 847.237\n",
      "Number of rows gone over: 435000 out of 847.237\n",
      "Number of rows gone over: 436000 out of 847.237\n",
      "Number of rows gone over: 437000 out of 847.237\n",
      "Number of rows gone over: 438000 out of 847.237\n",
      "Number of rows gone over: 439000 out of 847.237\n",
      "Number of rows gone over: 440000 out of 847.237\n",
      "Number of rows gone over: 441000 out of 847.237\n",
      "Number of rows gone over: 442000 out of 847.237\n",
      "Number of rows gone over: 443000 out of 847.237\n",
      "Number of rows gone over: 444000 out of 847.237\n",
      "Number of rows gone over: 445000 out of 847.237\n",
      "Number of rows gone over: 446000 out of 847.237\n",
      "Number of rows gone over: 447000 out of 847.237\n",
      "Number of rows gone over: 448000 out of 847.237\n",
      "Number of rows gone over: 449000 out of 847.237\n",
      "Number of rows gone over: 450000 out of 847.237\n",
      "Number of rows gone over: 451000 out of 847.237\n",
      "Number of rows gone over: 452000 out of 847.237\n",
      "Number of rows gone over: 453000 out of 847.237\n",
      "Number of rows gone over: 454000 out of 847.237\n",
      "Number of rows gone over: 455000 out of 847.237\n",
      "Number of rows gone over: 456000 out of 847.237\n",
      "Number of rows gone over: 457000 out of 847.237\n",
      "Number of rows gone over: 458000 out of 847.237\n",
      "Number of rows gone over: 459000 out of 847.237\n",
      "Number of rows gone over: 460000 out of 847.237\n",
      "Number of rows gone over: 461000 out of 847.237\n",
      "Number of rows gone over: 462000 out of 847.237\n",
      "Number of rows gone over: 463000 out of 847.237\n",
      "Number of rows gone over: 464000 out of 847.237\n",
      "Number of rows gone over: 465000 out of 847.237\n",
      "Number of rows gone over: 466000 out of 847.237\n",
      "Number of rows gone over: 467000 out of 847.237\n",
      "Number of rows gone over: 468000 out of 847.237\n",
      "Number of rows gone over: 469000 out of 847.237\n",
      "Number of rows gone over: 470000 out of 847.237\n",
      "Number of rows gone over: 471000 out of 847.237\n",
      "Number of rows gone over: 472000 out of 847.237\n",
      "Number of rows gone over: 473000 out of 847.237\n",
      "Number of rows gone over: 474000 out of 847.237\n",
      "Number of rows gone over: 475000 out of 847.237\n",
      "Number of rows gone over: 476000 out of 847.237\n",
      "Number of rows gone over: 477000 out of 847.237\n",
      "Number of rows gone over: 478000 out of 847.237\n",
      "Number of rows gone over: 479000 out of 847.237\n",
      "Number of rows gone over: 480000 out of 847.237\n",
      "Number of rows gone over: 481000 out of 847.237\n",
      "Number of rows gone over: 482000 out of 847.237\n",
      "Number of rows gone over: 483000 out of 847.237\n",
      "Number of rows gone over: 484000 out of 847.237\n",
      "Number of rows gone over: 485000 out of 847.237\n",
      "Number of rows gone over: 486000 out of 847.237\n",
      "Number of rows gone over: 487000 out of 847.237\n",
      "Number of rows gone over: 488000 out of 847.237\n",
      "Number of rows gone over: 489000 out of 847.237\n",
      "Number of rows gone over: 490000 out of 847.237\n",
      "Number of rows gone over: 491000 out of 847.237\n",
      "Number of rows gone over: 492000 out of 847.237\n",
      "Number of rows gone over: 493000 out of 847.237\n",
      "Number of rows gone over: 494000 out of 847.237\n",
      "Number of rows gone over: 495000 out of 847.237\n",
      "Number of rows gone over: 496000 out of 847.237\n",
      "Number of rows gone over: 497000 out of 847.237\n",
      "Number of rows gone over: 498000 out of 847.237\n",
      "Number of rows gone over: 499000 out of 847.237\n",
      "Number of rows gone over: 500000 out of 847.237\n",
      "Number of rows gone over: 501000 out of 847.237\n",
      "Number of rows gone over: 502000 out of 847.237\n",
      "Number of rows gone over: 503000 out of 847.237\n",
      "Number of rows gone over: 504000 out of 847.237\n",
      "Number of rows gone over: 505000 out of 847.237\n",
      "Number of rows gone over: 506000 out of 847.237\n",
      "Number of rows gone over: 507000 out of 847.237\n",
      "Number of rows gone over: 508000 out of 847.237\n",
      "Number of rows gone over: 509000 out of 847.237\n",
      "Number of rows gone over: 510000 out of 847.237\n",
      "Number of rows gone over: 511000 out of 847.237\n",
      "Number of rows gone over: 512000 out of 847.237\n",
      "Number of rows gone over: 513000 out of 847.237\n",
      "Number of rows gone over: 514000 out of 847.237\n",
      "Number of rows gone over: 515000 out of 847.237\n",
      "Number of rows gone over: 516000 out of 847.237\n",
      "Number of rows gone over: 517000 out of 847.237\n",
      "Number of rows gone over: 518000 out of 847.237\n",
      "Number of rows gone over: 519000 out of 847.237\n",
      "Number of rows gone over: 520000 out of 847.237\n",
      "Number of rows gone over: 521000 out of 847.237\n",
      "Number of rows gone over: 522000 out of 847.237\n",
      "Number of rows gone over: 523000 out of 847.237\n",
      "Number of rows gone over: 524000 out of 847.237\n",
      "Number of rows gone over: 525000 out of 847.237\n",
      "Number of rows gone over: 526000 out of 847.237\n",
      "Number of rows gone over: 527000 out of 847.237\n",
      "Number of rows gone over: 528000 out of 847.237\n",
      "Number of rows gone over: 529000 out of 847.237\n",
      "Number of rows gone over: 530000 out of 847.237\n",
      "Number of rows gone over: 531000 out of 847.237\n",
      "Number of rows gone over: 532000 out of 847.237\n",
      "Number of rows gone over: 533000 out of 847.237\n",
      "Number of rows gone over: 534000 out of 847.237\n",
      "Number of rows gone over: 535000 out of 847.237\n",
      "Number of rows gone over: 536000 out of 847.237\n",
      "Number of rows gone over: 537000 out of 847.237\n",
      "Number of rows gone over: 538000 out of 847.237\n",
      "Number of rows gone over: 539000 out of 847.237\n",
      "Number of rows gone over: 540000 out of 847.237\n",
      "Number of rows gone over: 541000 out of 847.237\n",
      "Number of rows gone over: 542000 out of 847.237\n",
      "Number of rows gone over: 543000 out of 847.237\n",
      "Number of rows gone over: 544000 out of 847.237\n",
      "Number of rows gone over: 545000 out of 847.237\n",
      "Number of rows gone over: 546000 out of 847.237\n",
      "Number of rows gone over: 547000 out of 847.237\n",
      "Number of rows gone over: 548000 out of 847.237\n",
      "Number of rows gone over: 549000 out of 847.237\n",
      "Number of rows gone over: 550000 out of 847.237\n",
      "Number of rows gone over: 551000 out of 847.237\n",
      "Number of rows gone over: 552000 out of 847.237\n",
      "Number of rows gone over: 553000 out of 847.237\n",
      "Number of rows gone over: 554000 out of 847.237\n",
      "Number of rows gone over: 555000 out of 847.237\n",
      "Number of rows gone over: 556000 out of 847.237\n",
      "Number of rows gone over: 557000 out of 847.237\n",
      "Number of rows gone over: 558000 out of 847.237\n",
      "Number of rows gone over: 559000 out of 847.237\n",
      "Number of rows gone over: 560000 out of 847.237\n",
      "Number of rows gone over: 561000 out of 847.237\n",
      "Number of rows gone over: 562000 out of 847.237\n",
      "Number of rows gone over: 563000 out of 847.237\n",
      "Number of rows gone over: 564000 out of 847.237\n",
      "Number of rows gone over: 565000 out of 847.237\n",
      "Number of rows gone over: 566000 out of 847.237\n",
      "Number of rows gone over: 567000 out of 847.237\n",
      "Number of rows gone over: 568000 out of 847.237\n",
      "Number of rows gone over: 569000 out of 847.237\n",
      "Number of rows gone over: 570000 out of 847.237\n",
      "Number of rows gone over: 571000 out of 847.237\n",
      "Number of rows gone over: 572000 out of 847.237\n",
      "Number of rows gone over: 573000 out of 847.237\n",
      "Number of rows gone over: 574000 out of 847.237\n",
      "Number of rows gone over: 575000 out of 847.237\n",
      "Number of rows gone over: 576000 out of 847.237\n",
      "Number of rows gone over: 577000 out of 847.237\n",
      "Number of rows gone over: 578000 out of 847.237\n",
      "Number of rows gone over: 579000 out of 847.237\n",
      "Number of rows gone over: 580000 out of 847.237\n",
      "Number of rows gone over: 581000 out of 847.237\n",
      "Number of rows gone over: 582000 out of 847.237\n",
      "Number of rows gone over: 583000 out of 847.237\n",
      "Number of rows gone over: 584000 out of 847.237\n",
      "Number of rows gone over: 585000 out of 847.237\n",
      "Number of rows gone over: 586000 out of 847.237\n",
      "Number of rows gone over: 587000 out of 847.237\n",
      "Number of rows gone over: 588000 out of 847.237\n",
      "Number of rows gone over: 589000 out of 847.237\n",
      "Number of rows gone over: 590000 out of 847.237\n",
      "Number of rows gone over: 591000 out of 847.237\n",
      "Number of rows gone over: 592000 out of 847.237\n",
      "Number of rows gone over: 593000 out of 847.237\n",
      "Number of rows gone over: 594000 out of 847.237\n",
      "Number of rows gone over: 595000 out of 847.237\n",
      "Number of rows gone over: 596000 out of 847.237\n",
      "Number of rows gone over: 597000 out of 847.237\n",
      "Number of rows gone over: 598000 out of 847.237\n",
      "Number of rows gone over: 599000 out of 847.237\n",
      "Number of rows gone over: 600000 out of 847.237\n",
      "Number of rows gone over: 601000 out of 847.237\n",
      "Number of rows gone over: 602000 out of 847.237\n",
      "Number of rows gone over: 603000 out of 847.237\n",
      "Number of rows gone over: 604000 out of 847.237\n",
      "Number of rows gone over: 605000 out of 847.237\n",
      "Number of rows gone over: 606000 out of 847.237\n",
      "Number of rows gone over: 607000 out of 847.237\n",
      "Number of rows gone over: 608000 out of 847.237\n",
      "Number of rows gone over: 609000 out of 847.237\n",
      "Number of rows gone over: 610000 out of 847.237\n",
      "Number of rows gone over: 611000 out of 847.237\n",
      "Number of rows gone over: 612000 out of 847.237\n",
      "Number of rows gone over: 613000 out of 847.237\n",
      "Number of rows gone over: 614000 out of 847.237\n",
      "Number of rows gone over: 615000 out of 847.237\n",
      "Number of rows gone over: 616000 out of 847.237\n",
      "Number of rows gone over: 617000 out of 847.237\n",
      "Number of rows gone over: 618000 out of 847.237\n",
      "Number of rows gone over: 619000 out of 847.237\n",
      "Number of rows gone over: 620000 out of 847.237\n",
      "Number of rows gone over: 621000 out of 847.237\n",
      "Number of rows gone over: 622000 out of 847.237\n",
      "Number of rows gone over: 623000 out of 847.237\n",
      "Number of rows gone over: 624000 out of 847.237\n",
      "Number of rows gone over: 625000 out of 847.237\n",
      "Number of rows gone over: 626000 out of 847.237\n",
      "Number of rows gone over: 627000 out of 847.237\n",
      "Number of rows gone over: 628000 out of 847.237\n",
      "Number of rows gone over: 629000 out of 847.237\n",
      "Number of rows gone over: 630000 out of 847.237\n",
      "Number of rows gone over: 631000 out of 847.237\n",
      "Number of rows gone over: 632000 out of 847.237\n",
      "Number of rows gone over: 633000 out of 847.237\n",
      "Number of rows gone over: 634000 out of 847.237\n",
      "Number of rows gone over: 635000 out of 847.237\n",
      "Number of rows gone over: 636000 out of 847.237\n",
      "Number of rows gone over: 637000 out of 847.237\n",
      "Number of rows gone over: 638000 out of 847.237\n",
      "Number of rows gone over: 639000 out of 847.237\n",
      "Number of rows gone over: 640000 out of 847.237\n",
      "Number of rows gone over: 641000 out of 847.237\n",
      "Number of rows gone over: 642000 out of 847.237\n",
      "Number of rows gone over: 643000 out of 847.237\n",
      "Number of rows gone over: 644000 out of 847.237\n",
      "Number of rows gone over: 645000 out of 847.237\n",
      "Number of rows gone over: 646000 out of 847.237\n",
      "Number of rows gone over: 647000 out of 847.237\n",
      "Number of rows gone over: 648000 out of 847.237\n",
      "Number of rows gone over: 649000 out of 847.237\n",
      "Number of rows gone over: 650000 out of 847.237\n",
      "Number of rows gone over: 651000 out of 847.237\n",
      "Number of rows gone over: 652000 out of 847.237\n",
      "Number of rows gone over: 653000 out of 847.237\n",
      "Number of rows gone over: 654000 out of 847.237\n",
      "Number of rows gone over: 655000 out of 847.237\n",
      "Number of rows gone over: 656000 out of 847.237\n",
      "Number of rows gone over: 657000 out of 847.237\n",
      "Number of rows gone over: 658000 out of 847.237\n",
      "Number of rows gone over: 659000 out of 847.237\n",
      "Number of rows gone over: 660000 out of 847.237\n",
      "Number of rows gone over: 661000 out of 847.237\n",
      "Number of rows gone over: 662000 out of 847.237\n",
      "Number of rows gone over: 663000 out of 847.237\n",
      "Number of rows gone over: 664000 out of 847.237\n",
      "Number of rows gone over: 665000 out of 847.237\n",
      "Number of rows gone over: 666000 out of 847.237\n",
      "Number of rows gone over: 667000 out of 847.237\n",
      "Number of rows gone over: 668000 out of 847.237\n",
      "Number of rows gone over: 669000 out of 847.237\n",
      "Number of rows gone over: 670000 out of 847.237\n",
      "Number of rows gone over: 671000 out of 847.237\n",
      "Number of rows gone over: 672000 out of 847.237\n",
      "Number of rows gone over: 673000 out of 847.237\n",
      "Number of rows gone over: 674000 out of 847.237\n",
      "Number of rows gone over: 675000 out of 847.237\n",
      "Number of rows gone over: 676000 out of 847.237\n",
      "Number of rows gone over: 677000 out of 847.237\n",
      "Number of rows gone over: 678000 out of 847.237\n",
      "Number of rows gone over: 679000 out of 847.237\n",
      "Number of rows gone over: 680000 out of 847.237\n",
      "Number of rows gone over: 681000 out of 847.237\n",
      "Number of rows gone over: 682000 out of 847.237\n",
      "Number of rows gone over: 683000 out of 847.237\n",
      "Number of rows gone over: 684000 out of 847.237\n",
      "Number of rows gone over: 685000 out of 847.237\n",
      "Number of rows gone over: 686000 out of 847.237\n",
      "Number of rows gone over: 687000 out of 847.237\n",
      "Number of rows gone over: 688000 out of 847.237\n",
      "Number of rows gone over: 689000 out of 847.237\n",
      "Number of rows gone over: 690000 out of 847.237\n",
      "Number of rows gone over: 691000 out of 847.237\n",
      "Number of rows gone over: 692000 out of 847.237\n",
      "Number of rows gone over: 693000 out of 847.237\n",
      "Number of rows gone over: 694000 out of 847.237\n",
      "Number of rows gone over: 695000 out of 847.237\n",
      "Number of rows gone over: 696000 out of 847.237\n",
      "Number of rows gone over: 697000 out of 847.237\n",
      "Number of rows gone over: 698000 out of 847.237\n",
      "Number of rows gone over: 699000 out of 847.237\n",
      "Number of rows gone over: 700000 out of 847.237\n",
      "Number of rows gone over: 701000 out of 847.237\n",
      "Number of rows gone over: 702000 out of 847.237\n",
      "Number of rows gone over: 703000 out of 847.237\n",
      "Number of rows gone over: 704000 out of 847.237\n",
      "Number of rows gone over: 705000 out of 847.237\n",
      "Number of rows gone over: 706000 out of 847.237\n",
      "Number of rows gone over: 707000 out of 847.237\n",
      "Number of rows gone over: 708000 out of 847.237\n",
      "Number of rows gone over: 709000 out of 847.237\n",
      "Number of rows gone over: 710000 out of 847.237\n",
      "Number of rows gone over: 711000 out of 847.237\n",
      "Number of rows gone over: 712000 out of 847.237\n",
      "Number of rows gone over: 713000 out of 847.237\n",
      "Number of rows gone over: 714000 out of 847.237\n",
      "Number of rows gone over: 715000 out of 847.237\n",
      "Number of rows gone over: 716000 out of 847.237\n",
      "Number of rows gone over: 717000 out of 847.237\n",
      "Number of rows gone over: 718000 out of 847.237\n",
      "Number of rows gone over: 719000 out of 847.237\n",
      "Number of rows gone over: 720000 out of 847.237\n",
      "Number of rows gone over: 721000 out of 847.237\n",
      "Number of rows gone over: 722000 out of 847.237\n",
      "Number of rows gone over: 723000 out of 847.237\n",
      "Number of rows gone over: 724000 out of 847.237\n",
      "Number of rows gone over: 725000 out of 847.237\n",
      "Number of rows gone over: 726000 out of 847.237\n",
      "Number of rows gone over: 727000 out of 847.237\n",
      "Number of rows gone over: 728000 out of 847.237\n",
      "Number of rows gone over: 729000 out of 847.237\n",
      "Number of rows gone over: 730000 out of 847.237\n",
      "Number of rows gone over: 731000 out of 847.237\n",
      "Number of rows gone over: 732000 out of 847.237\n",
      "Number of rows gone over: 733000 out of 847.237\n",
      "Number of rows gone over: 734000 out of 847.237\n",
      "Number of rows gone over: 735000 out of 847.237\n",
      "Number of rows gone over: 736000 out of 847.237\n",
      "Number of rows gone over: 737000 out of 847.237\n",
      "Number of rows gone over: 738000 out of 847.237\n",
      "Number of rows gone over: 739000 out of 847.237\n",
      "Number of rows gone over: 740000 out of 847.237\n",
      "Number of rows gone over: 741000 out of 847.237\n",
      "Number of rows gone over: 742000 out of 847.237\n",
      "Number of rows gone over: 743000 out of 847.237\n",
      "Number of rows gone over: 744000 out of 847.237\n",
      "Number of rows gone over: 745000 out of 847.237\n",
      "Number of rows gone over: 746000 out of 847.237\n",
      "Number of rows gone over: 747000 out of 847.237\n",
      "Number of rows gone over: 748000 out of 847.237\n",
      "Number of rows gone over: 749000 out of 847.237\n",
      "Number of rows gone over: 750000 out of 847.237\n",
      "Number of rows gone over: 751000 out of 847.237\n",
      "Number of rows gone over: 752000 out of 847.237\n",
      "Number of rows gone over: 753000 out of 847.237\n",
      "Number of rows gone over: 754000 out of 847.237\n",
      "Number of rows gone over: 755000 out of 847.237\n",
      "Number of rows gone over: 756000 out of 847.237\n",
      "Number of rows gone over: 757000 out of 847.237\n",
      "Number of rows gone over: 758000 out of 847.237\n",
      "Number of rows gone over: 759000 out of 847.237\n",
      "Number of rows gone over: 760000 out of 847.237\n",
      "Number of rows gone over: 761000 out of 847.237\n",
      "Number of rows gone over: 762000 out of 847.237\n",
      "Number of rows gone over: 763000 out of 847.237\n",
      "Number of rows gone over: 764000 out of 847.237\n",
      "Number of rows gone over: 765000 out of 847.237\n",
      "Number of rows gone over: 766000 out of 847.237\n",
      "Number of rows gone over: 767000 out of 847.237\n",
      "Number of rows gone over: 768000 out of 847.237\n",
      "Number of rows gone over: 769000 out of 847.237\n",
      "Number of rows gone over: 770000 out of 847.237\n",
      "Number of rows gone over: 771000 out of 847.237\n",
      "Number of rows gone over: 772000 out of 847.237\n",
      "Number of rows gone over: 773000 out of 847.237\n",
      "Number of rows gone over: 774000 out of 847.237\n",
      "Number of rows gone over: 775000 out of 847.237\n",
      "Number of rows gone over: 776000 out of 847.237\n",
      "Number of rows gone over: 777000 out of 847.237\n",
      "Number of rows gone over: 778000 out of 847.237\n",
      "Number of rows gone over: 779000 out of 847.237\n",
      "Number of rows gone over: 780000 out of 847.237\n",
      "Number of rows gone over: 781000 out of 847.237\n",
      "Number of rows gone over: 782000 out of 847.237\n",
      "Number of rows gone over: 783000 out of 847.237\n",
      "Number of rows gone over: 784000 out of 847.237\n",
      "Number of rows gone over: 785000 out of 847.237\n",
      "Number of rows gone over: 786000 out of 847.237\n",
      "Number of rows gone over: 787000 out of 847.237\n",
      "Number of rows gone over: 788000 out of 847.237\n",
      "Number of rows gone over: 789000 out of 847.237\n",
      "Number of rows gone over: 790000 out of 847.237\n",
      "Number of rows gone over: 791000 out of 847.237\n",
      "Number of rows gone over: 792000 out of 847.237\n",
      "Number of rows gone over: 793000 out of 847.237\n",
      "Number of rows gone over: 794000 out of 847.237\n",
      "Number of rows gone over: 795000 out of 847.237\n",
      "Number of rows gone over: 796000 out of 847.237\n",
      "Number of rows gone over: 797000 out of 847.237\n",
      "Number of rows gone over: 798000 out of 847.237\n",
      "Number of rows gone over: 799000 out of 847.237\n",
      "Number of rows gone over: 800000 out of 847.237\n",
      "Number of rows gone over: 801000 out of 847.237\n",
      "Number of rows gone over: 802000 out of 847.237\n",
      "Number of rows gone over: 803000 out of 847.237\n",
      "Number of rows gone over: 804000 out of 847.237\n",
      "Number of rows gone over: 805000 out of 847.237\n",
      "Number of rows gone over: 806000 out of 847.237\n",
      "Number of rows gone over: 807000 out of 847.237\n",
      "Number of rows gone over: 808000 out of 847.237\n",
      "Number of rows gone over: 809000 out of 847.237\n",
      "Number of rows gone over: 810000 out of 847.237\n",
      "Number of rows gone over: 811000 out of 847.237\n",
      "Number of rows gone over: 812000 out of 847.237\n",
      "Number of rows gone over: 813000 out of 847.237\n",
      "Number of rows gone over: 814000 out of 847.237\n",
      "Number of rows gone over: 815000 out of 847.237\n",
      "Number of rows gone over: 816000 out of 847.237\n",
      "Number of rows gone over: 817000 out of 847.237\n",
      "Number of rows gone over: 818000 out of 847.237\n",
      "Number of rows gone over: 819000 out of 847.237\n",
      "Number of rows gone over: 820000 out of 847.237\n",
      "Number of rows gone over: 821000 out of 847.237\n",
      "Number of rows gone over: 822000 out of 847.237\n",
      "Number of rows gone over: 823000 out of 847.237\n",
      "Number of rows gone over: 824000 out of 847.237\n",
      "Number of rows gone over: 825000 out of 847.237\n",
      "Number of rows gone over: 826000 out of 847.237\n",
      "Number of rows gone over: 827000 out of 847.237\n",
      "Number of rows gone over: 828000 out of 847.237\n",
      "Number of rows gone over: 829000 out of 847.237\n",
      "Number of rows gone over: 830000 out of 847.237\n",
      "Number of rows gone over: 831000 out of 847.237\n",
      "Number of rows gone over: 832000 out of 847.237\n",
      "Number of rows gone over: 833000 out of 847.237\n",
      "Number of rows gone over: 834000 out of 847.237\n",
      "Number of rows gone over: 835000 out of 847.237\n",
      "Number of rows gone over: 836000 out of 847.237\n",
      "Number of rows gone over: 837000 out of 847.237\n",
      "Number of rows gone over: 838000 out of 847.237\n",
      "Number of rows gone over: 839000 out of 847.237\n",
      "Number of rows gone over: 840000 out of 847.237\n",
      "Number of rows gone over: 841000 out of 847.237\n",
      "Number of rows gone over: 842000 out of 847.237\n",
      "Number of rows gone over: 843000 out of 847.237\n",
      "Number of rows gone over: 844000 out of 847.237\n",
      "Number of rows gone over: 845000 out of 847.237\n",
      "Number of rows gone over: 846000 out of 847.237\n",
      "Number of rows gone over: 847000 out of 847.237\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for index, row in data_salesdata[~data_salesdata['Relevant_Estates_ads_for_transaction'].isna()].iterrows():\n",
    "\n",
    "    # the counter \n",
    "    counter +=1 \n",
    "    if counter % 1000 == 0:\n",
    "        print(f'Number of rows gone over: {counter} out of 847.237')\n",
    "\n",
    "    NEWESTAd_askingPrice_lastAd = None\n",
    "    NEWESTAd_daysForSale = None\n",
    "    NEWESTAd_lastSeen_Date = None\n",
    "    OLDESTAd_askingPrice_firstAd = None\n",
    "    OLDESTAd_daysForSale = None\n",
    "    OLDESTAd_lastSeen_Date = None\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # get key variables\n",
    "    # ----------------------------------------------------------\n",
    "    relevant_estates_dict = row['Relevant_Estates_ads_for_transaction']\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # find the dictionary with the NEWEST date \n",
    "    # ----------------------------------------------------------\n",
    "    newest_dictionary_estate = max(relevant_estates_dict, key=lambda x: x['lastSeen'])\n",
    "\n",
    "    # ------------ Get Values : \n",
    "\n",
    "    # get value for : NEWESTAd_askingPrice_lastAd\n",
    "    NEWESTAd_askingPrice_lastAd = newest_dictionary_estate['salesPrice']\n",
    "    # get value for : NEWESTAd_daysForSale\n",
    "    NEWESTAd_daysForSale = newest_dictionary_estate['daysForSale']\n",
    "    # get value for : NEWESTAd_lastSeen_Date   \n",
    "    NEWESTAd_lastSeen_Date = newest_dictionary_estate['lastSeen']\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # find the dictionary with the OLDEST date \n",
    "    # ----------------------------------------------------------\n",
    "    oldest_dictionary_estate = min(relevant_estates_dict, key=lambda x: x['lastSeen'])\n",
    "\n",
    "    # ------------ Get Values : \n",
    "\n",
    "    # get value for : OLDESTAd_askingPrice_firstAd\n",
    "    OLDESTAd_askingPrice_firstAd = oldest_dictionary_estate['salesPrice']\n",
    "    # get value for : OLDESTAd_daysForSale\n",
    "    OLDESTAd_daysForSale = oldest_dictionary_estate['daysForSale']\n",
    "    # get value for : OLDESTAd_lastSeen_Date\n",
    "    OLDESTAd_lastSeen_Date = oldest_dictionary_estate['lastSeen']\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    #  APPEND RESULT TO DATAFRAME\n",
    "    # ----------------------------------------------------------\n",
    "    data_salesdata.at[index, 'Estate_Info_NEWEST_Ad_askingPrice_lastAd'] = NEWESTAd_askingPrice_lastAd\n",
    "    data_salesdata.at[index, 'Estate_Info_NEWEST_Ad_daysForSale'] = NEWESTAd_daysForSale\n",
    "    data_salesdata.at[index, 'Estate_Info_NEWEST_Ad_lastSeen_Date'] = NEWESTAd_lastSeen_Date\n",
    "    data_salesdata.at[index, 'Estate_Info_OLDEST_Ad_askingPrice_firstAd'] = OLDESTAd_askingPrice_firstAd\n",
    "    data_salesdata.at[index, 'Estate_Info_OLDEST_Ad_daysForSale'] = OLDESTAd_daysForSale\n",
    "    data_salesdata.at[index, 'Estate_Info_OLDEST_Ad_lastSeen_Date'] = OLDESTAd_lastSeen_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estateId': 1931979,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 52,\n",
       "  'salesPrice': 3248000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1931/1931979.jpg',\n",
       "  'lastSeen': '2022-11-08 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1857402,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 242,\n",
       "  'salesPrice': 3348000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1857/1857402.jpg',\n",
       "  'lastSeen': '2022-09-14 00:00:00',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['Relevant_Estates_ads_for_transaction'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowID_MAIN_boliga_ROW_ID_unitID                                 9133416f-191b-496e-88bb-62b3a46a370a\n",
       "salesInfo_isSalesValid                                                                          True\n",
       "salesInfo_handoverCode                                                                           1.0\n",
       "salesInfo_handoverName                                                                Alm. frit salg\n",
       "salesInfo_deedIssueDate                                                                   2023-01-18\n",
       "salesInfo_price                                                                            3050000.0\n",
       "salesInfo_recalculationDate                                                               2023-11-08\n",
       "salesInfo_rebuildYear                                                                         2008.0\n",
       "unique_sales_ID                                                                                    2\n",
       "salesInfo_year_of_sale                                                                          2023\n",
       "EvaluationInfo_evaluationYear                                                                 2022.0\n",
       "EvaluationInfo_lastChange                                                                 2022-10-01\n",
       "EvaluationInfo_propertyValue                                                               2250000.0\n",
       "EvaluationInfo_landValue                                                                    375000.0\n",
       "EvaluationInfo_deductionSum                                                                 161300.0\n",
       "EvaluationInfo_usage                                                                Beboelsesejendom\n",
       "EvaluationInfo_residentialUnits                                                                  1.0\n",
       "EvaluationInfo_propertyValueArea                                                           2250000.0\n",
       "EvaluationInfo_rebuildYear                                                                    2008.0\n",
       "EvaluationInfo_areaSize                                                                        562.0\n",
       "RAW_dictionary_previousEstates                     [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "salesInfo_ALL_sales_dates_by_main_ID               ['2007-09-12', '2023-01-18', '2017-12-11', '20...\n",
       "salesInfo_OTHER_sales_dates_by_main_ID                    ['2007-09-12', '2017-12-11', '2007-09-27']\n",
       "salesInfo_OLDER_sales_dates_by_main_ID                    ['2007-09-12', '2017-12-11', '2007-09-27']\n",
       "Relevant_Estates_ads_for_transaction               [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "Estate_info_Number_of_estates_Ads                                                                  2\n",
       "Estate_info_Number_of_dayes_between_ads                                                          294\n",
       "Estate_Info_NEWEST_Ad_askingPrice_lastAd                                                   3248000.0\n",
       "Estate_Info_NEWEST_Ad_daysForSale                                                               52.0\n",
       "Estate_Info_NEWEST_Ad_lastSeen_Date                                              2022-11-08 00:00:00\n",
       "Estate_Info_OLDEST_Ad_askingPrice_firstAd                                                  3348000.0\n",
       "Estate_Info_OLDEST_Ad_daysForSale                                                              242.0\n",
       "Estate_Info_OLDEST_Ad_lastSeen_Date                                              2022-09-14 00:00:00\n",
       "Estate_Info_Day_Difference_OLDEST_and_NEWEST_AD                                                 55.0\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =======================> creating : Number_of_days_between_ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['Estate_Info_NEWEST_Ad_lastSeen_Date'] = pd.to_datetime(data_salesdata['Estate_Info_NEWEST_Ad_lastSeen_Date'])\n",
    "data_salesdata['Estate_Info_OLDEST_Ad_lastSeen_Date'] = pd.to_datetime(data_salesdata['Estate_Info_OLDEST_Ad_lastSeen_Date'])\n",
    "\n",
    "# Create a new column 'Day_Difference'\n",
    "data_salesdata['Estate_Info_Day_Difference_OLDEST_and_NEWEST_AD'] = (data_salesdata['Estate_Info_NEWEST_Ad_lastSeen_Date'] - data_salesdata['Estate_Info_OLDEST_Ad_lastSeen_Date']).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2623340 entries, 0 to 2623339\n",
      "Data columns (total 34 columns):\n",
      " #   Column                                           Non-Null Count    Dtype         \n",
      "---  ------                                           --------------    -----         \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID                  2623340 non-null  object        \n",
      " 1   salesInfo_isSalesValid                           2623340 non-null  bool          \n",
      " 2   salesInfo_handoverCode                           2623340 non-null  float64       \n",
      " 3   salesInfo_handoverName                           2623340 non-null  object        \n",
      " 4   salesInfo_deedIssueDate                          2623340 non-null  object        \n",
      " 5   salesInfo_price                                  2623340 non-null  float64       \n",
      " 6   salesInfo_recalculationDate                      2623340 non-null  object        \n",
      " 7   salesInfo_rebuildYear                            2623340 non-null  float64       \n",
      " 8   unique_sales_ID                                  2623340 non-null  int64         \n",
      " 9   salesInfo_year_of_sale                           2623340 non-null  int64         \n",
      " 10  EvaluationInfo_evaluationYear                    1364441 non-null  float64       \n",
      " 11  EvaluationInfo_lastChange                        1364441 non-null  object        \n",
      " 12  EvaluationInfo_propertyValue                     1364441 non-null  float64       \n",
      " 13  EvaluationInfo_landValue                         1364441 non-null  float64       \n",
      " 14  EvaluationInfo_deductionSum                      1364441 non-null  float64       \n",
      " 15  EvaluationInfo_usage                             1364441 non-null  object        \n",
      " 16  EvaluationInfo_residentialUnits                  1364441 non-null  float64       \n",
      " 17  EvaluationInfo_propertyValueArea                 1364441 non-null  float64       \n",
      " 18  EvaluationInfo_rebuildYear                       1364441 non-null  float64       \n",
      " 19  EvaluationInfo_areaSize                          1364441 non-null  float64       \n",
      " 20  RAW_dictionary_previousEstates                   1790826 non-null  object        \n",
      " 21  salesInfo_ALL_sales_dates_by_main_ID             2623340 non-null  object        \n",
      " 22  salesInfo_OTHER_sales_dates_by_main_ID           2623340 non-null  object        \n",
      " 23  salesInfo_OLDER_sales_dates_by_main_ID           2623340 non-null  object        \n",
      " 24  Relevant_Estates_ads_for_transaction             847237 non-null   object        \n",
      " 25  Estate_info_Number_of_estates_Ads                2623340 non-null  int64         \n",
      " 26  Estate_info_Number_of_dayes_between_ads          2623340 non-null  int64         \n",
      " 27  Estate_Info_NEWEST_Ad_askingPrice_lastAd         847237 non-null   float64       \n",
      " 28  Estate_Info_NEWEST_Ad_daysForSale                847237 non-null   float64       \n",
      " 29  Estate_Info_NEWEST_Ad_lastSeen_Date              847237 non-null   datetime64[ns]\n",
      " 30  Estate_Info_OLDEST_Ad_askingPrice_firstAd        847237 non-null   float64       \n",
      " 31  Estate_Info_OLDEST_Ad_daysForSale                847237 non-null   float64       \n",
      " 32  Estate_Info_OLDEST_Ad_lastSeen_Date              847237 non-null   datetime64[ns]\n",
      " 33  Estate_Info_Day_Difference_OLDEST_and_NEWEST_AD  847237 non-null   float64       \n",
      "dtypes: bool(1), datetime64[ns](2), float64(16), int64(4), object(11)\n",
      "memory usage: 663.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data_salesdata.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------- save RESULT !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_merge\\step_2_mrgin_newSales_with_Estate_ads\\Boliga_salesData_SalesTransactions_with_evaluation_and_estate_info_34col_2623340rows.csv'\n",
    "data_salesdata.to_csv(path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del oldest_dictionary_estate, newest_dictionary_estate, NEWESTAd_askingPrice_lastAd, NEWESTAd_askingPrice_lastAd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note: need to convert RAW_dictionary_previousEstate again to a dictionary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['RAW_dictionary_previousEstates'] = data_salesdata['RAW_dictionary_previousEstates'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) and x!='[]' and x!='' and x is not None else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also need to convert salesInfo_OLDER_sales_dates_by_main_ID  to a list  (now its a string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  []\n",
       "1          ['2007-09-12', '2017-12-11', '2007-09-27']\n",
       "2                        ['2007-09-12', '2007-09-27']\n",
       "3                                      ['2007-09-12']\n",
       "4                                                  []\n",
       "                              ...                    \n",
       "2623335                                ['1899-12-30']\n",
       "2623336                                            []\n",
       "2623337                                ['1899-12-30']\n",
       "2623338                                ['1899-12-30']\n",
       "2623339                                            []\n",
       "Name: salesInfo_OLDER_sales_dates_by_main_ID, Length: 2623340, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['salesInfo_OLDER_sales_dates_by_main_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['salesInfo_OLDER_sales_dates_by_main_ID'] = data_salesdata['salesInfo_OLDER_sales_dates_by_main_ID'].apply(lambda x: ast.literal_eval(x) if isinstance(x,str) and x!='' and x is not None else x) #and x!='[]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2007-09-12', '2017-12-11', '2007-09-27']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['salesInfo_OLDER_sales_dates_by_main_ID'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __ convert Salesinfo_DeedIssueDate to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['salesInfo_deedIssueDate'] = pd.to_datetime(data_salesdata['salesInfo_deedIssueDate'])#, format=\"%Y-%m-%d\")#.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2007-09-12 00:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['salesInfo_deedIssueDate'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8. nov. 2022'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['RAW_dictionary_previousEstates'][0][0]['lastSeen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(data_salesdata['RAW_dictionary_previousEstates'][0][0]['lastSeen']) > data_salesdata['salesInfo_deedIssueDate'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---- Replace '[]' with None in column RAW_dictionary_previousEstates          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['RAW_dictionary_previousEstates'] = data_salesdata['RAW_dictionary_previousEstates'].replace('[]',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "1          [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "2          [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "3          [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "4          [{'estateId': 1988849, 'estateAddress': 'Ibsgå...\n",
       "                                 ...                        \n",
       "2623335                                                 None\n",
       "2623336                                                 None\n",
       "2623337                                                 None\n",
       "2623338                                                 None\n",
       "2623339                                                 None\n",
       "Name: RAW_dictionary_previousEstates, Length: 2623340, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['RAW_dictionary_previousEstates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- convert \"lastSeen\" in dictionaries as datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---- TESTing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                 None\n",
       "1    [{'housetype': 'bingo', 'lastSeen': '2022-01-0...\n",
       "2    [{'lastSeen': '2021-12-10', 'status': 'expired...\n",
       "3                                                 None\n",
       "4    [{'housetype': 'bingo', 'lastSeen': '2021-11-2...\n",
       "Name: RAW_dictionary_previousEstates, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample DataFrame with a column of dictionaries\n",
    "data = {'RAW_dictionary_previousEstates': [\n",
    "    None,\n",
    "    [{'housetype':'bingo','lastSeen': '2022-01-01', 'status': 'active'}, {'lastSeen': '2022-02-15', 'status': 'inactive'}],\n",
    "    [{'lastSeen': '2021-12-10', 'status': 'expired'}, {'lastSeen': '2022-03-05', 'status': 'active'}],\n",
    "    None,\n",
    "    [{'housetype':'bingo', 'lastSeen': '2021-11-20', 'status': 'inactive'}],\n",
    "]}\n",
    "\n",
    "test = pd.DataFrame(data)\n",
    "test['RAW_dictionary_previousEstates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['RAW_dictionary_previousEstates'] = test['RAW_dictionary_previousEstates'].apply(lambda x: None if x is None else [{k: pd.to_datetime(v) if k == 'lastSeen' else v for k, v in d.items()} for d in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAW_dictionary_previousEstates\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test['RAW_dictionary_previousEstates'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estateId': 1931979,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 52,\n",
       "  'salesPrice': 3248000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1931/1931979.jpg',\n",
       "  'lastSeen': '8. nov. 2022',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1857402,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 242,\n",
       "  'salesPrice': 3348000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1857/1857402.jpg',\n",
       "  'lastSeen': '14. sep. 2022',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1352628,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 26,\n",
       "  'salesPrice': 2975000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1352/1352628.jpg',\n",
       "  'lastSeen': '31. aug. 2017',\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['RAW_dictionary_previousEstates'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- main : change lastSeen  to a  datetime object in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['RAW_dictionary_previousEstates'] = data_salesdata['RAW_dictionary_previousEstates'].apply(lambda x: None if x is None or x == '[]' or x =='' else [{k: pd.to_datetime(v) if k == 'lastSeen' else v for k, v in d.items()} for d in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estateId': 1136274,\n",
       "  'estateAddress': 'Dronningensgade 3B',\n",
       "  'daysForSale': 291,\n",
       "  'salesPrice': 6150000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1136/1136274.jpg',\n",
       "  'lastSeen': Timestamp('2016-06-29 00:00:00'),\n",
       "  'zipCode': 1420,\n",
       "  'city': 'København K'},\n",
       " {'estateId': 1006630,\n",
       "  'estateAddress': 'Dronningensgade 3B, 1.',\n",
       "  'daysForSale': 403,\n",
       "  'salesPrice': 6395000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1006/1006630.jpg',\n",
       "  'lastSeen': Timestamp('2015-08-31 00:00:00'),\n",
       "  'zipCode': 1420,\n",
       "  'city': 'København K'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['RAW_dictionary_previousEstates'][1565161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2012-02-01 00:00:00')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata['salesInfo_deedIssueDate'][654]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before running the code to create Relevant_Estates_ads_for_transaction I will first drop all unnecessary columns that I will later merge with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "'salesInfo_ALL_sales_dates_by_main_ID'    \n",
    "]\n",
    "\n",
    "data_salesdata.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2623340 entries, 0 to 2623339\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                  Dtype         \n",
      "---  ------                                  -----         \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID         object        \n",
      " 1   salesInfo_deedIssueDate                 datetime64[ns]\n",
      " 2   salesInfo_recalculationDate             object        \n",
      " 3   unique_sales_ID                         int64         \n",
      " 4   RAW_dictionary_previousEstates          object        \n",
      " 5   salesInfo_OTHER_sales_dates_by_main_ID  object        \n",
      " 6   salesInfo_OLDER_sales_dates_by_main_ID  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 140.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_salesdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- create the column  \"Relevant_Estates_ads_for_transaction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m relevant_estates\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Apply the function using apply and axis=1\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m data_salesdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelevant_Estates_ads_for_transaction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_salesdata\u001b[38;5;241m.\u001b[39mapply(filter_relevant_estates, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(v)\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[32], line 52\u001b[0m, in \u001b[0;36mfilter_relevant_estates\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_seen_date \u001b[38;5;241m<\u001b[39m deed_issue_date:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m older_sales_dates \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m older_sales_dates \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(older_sales_dates, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m---> 52\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39marray([last_seen_date \u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(date) \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m older_sales_dates \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mto_datetime(date, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mNaT])):\n\u001b[0;32m     53\u001b[0m             relevant_estates\u001b[38;5;241m.\u001b[39mappend(estate_dict)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[32], line 52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_seen_date \u001b[38;5;241m<\u001b[39m deed_issue_date:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m older_sales_dates \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m older_sales_dates \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(older_sales_dates, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m---> 52\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39marray([last_seen_date \u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(date) \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m older_sales_dates \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mto_datetime(date, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mNaT])):\n\u001b[0;32m     53\u001b[0m             relevant_estates\u001b[38;5;241m.\u001b[39mappend(estate_dict)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1084\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1082\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1084\u001b[0m     result \u001b[38;5;241m=\u001b[39m convert_listlike(np\u001b[38;5;241m.\u001b[39marray([arg]), \u001b[38;5;28mformat\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mbool_):\n\u001b[0;32m   1086\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(result)  \u001b[38;5;66;03m# TODO: avoid this kludge.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:453\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m    455\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    456\u001b[0m     arg,\n\u001b[0;32m    457\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:488\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n\u001b[1;32m--> 488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _box_as_indexlike(result, utc\u001b[38;5;241m=\u001b[39mutc, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:287\u001b[0m, in \u001b[0;36m_box_as_indexlike\u001b[1;34m(dt_array, utc, name)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_datetime64_dtype(dt_array):\n\u001b[0;32m    286\u001b[0m     tz \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m utc \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DatetimeIndex(dt_array, tz\u001b[38;5;241m=\u001b[39mtz, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Index(dt_array, name\u001b[38;5;241m=\u001b[39mname, dtype\u001b[38;5;241m=\u001b[39mdt_array\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:339\u001b[0m, in \u001b[0;36mDatetimeIndex.__new__\u001b[1;34m(cls, data, freq, tz, normalize, closed, ambiguous, dayfirst, yearfirst, dtype, copy, name)\u001b[0m\n\u001b[0;32m    336\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_simple_new(data, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m--> 339\u001b[0m dtarr \u001b[38;5;241m=\u001b[39m DatetimeArray\u001b[38;5;241m.\u001b[39m_from_sequence_not_strict(\n\u001b[0;32m    340\u001b[0m     data,\n\u001b[0;32m    341\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    342\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    343\u001b[0m     tz\u001b[38;5;241m=\u001b[39mtz,\n\u001b[0;32m    344\u001b[0m     freq\u001b[38;5;241m=\u001b[39mfreq,\n\u001b[0;32m    345\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m    346\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m    347\u001b[0m     ambiguous\u001b[38;5;241m=\u001b[39mambiguous,\n\u001b[0;32m    348\u001b[0m )\n\u001b[0;32m    349\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (Index, ABCSeries)):\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:333\u001b[0m, in \u001b[0;36mDatetimeArray._from_sequence_not_strict\u001b[1;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;66;03m# DatetimeTZDtype\u001b[39;00m\n\u001b[0;32m    331\u001b[0m         unit \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39munit\n\u001b[1;32m--> 333\u001b[0m subarr, tz, inferred_freq \u001b[38;5;241m=\u001b[39m _sequence_to_dt64ns(\n\u001b[0;32m    334\u001b[0m     data,\n\u001b[0;32m    335\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    336\u001b[0m     tz\u001b[38;5;241m=\u001b[39mtz,\n\u001b[0;32m    337\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m    338\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m    339\u001b[0m     ambiguous\u001b[38;5;241m=\u001b[39mambiguous,\n\u001b[0;32m    340\u001b[0m     out_unit\u001b[38;5;241m=\u001b[39munit,\n\u001b[0;32m    341\u001b[0m )\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# We have to call this again after possibly inferring a tz above\u001b[39;00m\n\u001b[0;32m    343\u001b[0m _validate_tz_from_dtype(dtype, tz, explicit_tz_none)\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2041\u001b[0m, in \u001b[0;36m_sequence_to_dt64ns\u001b[1;34m(data, copy, tz, dayfirst, yearfirst, ambiguous, out_unit)\u001b[0m\n\u001b[0;32m   2036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_unit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2037\u001b[0m     out_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM8[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_unit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2040\u001b[0m     is_object_dtype(data_dtype)\n\u001b[1;32m-> 2041\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_string_dtype(data_dtype)\n\u001b[0;32m   2042\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_sparse(data_dtype)\n\u001b[0;32m   2043\u001b[0m ):\n\u001b[0;32m   2044\u001b[0m     \u001b[38;5;66;03m# TODO: We do not have tests specific to string-dtypes,\u001b[39;00m\n\u001b[0;32m   2045\u001b[0m     \u001b[38;5;66;03m#  also complex or categorical or other extension\u001b[39;00m\n\u001b[0;32m   2046\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2047\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39minfer_dtype(data, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ABC\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\common.py:537\u001b[0m, in \u001b[0;36mis_string_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_string_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m    Check whether the provided array or dtype is of the string dtype.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m get_dtype(arr_or_dtype)\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m is_all_strings(arr_or_dtype)\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcondition\u001b[39m(dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# def vectorized_filter_relevant_estates(deed_issue_date, older_sales_dates, estates_list):\n",
    "#     relevant_estates = []\n",
    "\n",
    "#     # Check if 'RAW_dictionary_previousEstates' is a list\n",
    "#     if isinstance(estates_list, list):\n",
    "#         # Iterate over each dictionary in the list using NumPy vectorized operations\n",
    "#         for estate_dict in estates_list:\n",
    "#             # Extract 'lastSeen' date from the dictionary\n",
    "#             last_seen_date = pd.to_datetime(estate_dict.get('lastSeen', ''))\n",
    "            \n",
    "#             # Check conditions for relevant estate\n",
    "#             if last_seen_date < deed_issue_date:\n",
    "#                 if older_sales_dates != '[]' and older_sales_dates !='' and isinstance(older_sales_dates,list):\n",
    "#                     if np.all(np.array([last_seen_date > pd.to_datetime(date) for date in older_sales_dates])):\n",
    "#                         relevant_estates.append(estate_dict)\n",
    "#                 else:\n",
    "#                     relevant_estates.append(estate_dict)\n",
    "                    \n",
    "    \n",
    "#     return relevant_estates\n",
    "\n",
    "# # Apply the vectorized function to create the new column\n",
    "# data_salesdata['Relevant_Estates_ads_for_transaction'] = np.vectorize(vectorized_filter_relevant_estates)(\n",
    "#     data_salesdata['salesInfo_deedIssueDate'],\n",
    "#     data_salesdata['salesInfo_OLDER_sales_dates_by_main_ID'],\n",
    "#     data_salesdata['RAW_dictionary_previousEstates']\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def filter_relevant_estates(row):\n",
    "    deed_issue_date = row['salesInfo_deedIssueDate']\n",
    "    older_sales_dates = row['salesInfo_OLDER_sales_dates_by_main_ID']\n",
    "    estates_list = row['RAW_dictionary_previousEstates']\n",
    "\n",
    "    relevant_estates = []\n",
    "\n",
    "    # Check if 'RAW_dictionary_previousEstates' is a list\n",
    "    if isinstance(estates_list, list):\n",
    "        # Iterate over each dictionary in the list\n",
    "        for estate_dict in estates_list:\n",
    "            # Extract 'lastSeen' date from the dictionary\n",
    "            last_seen_date = pd.to_datetime(estate_dict.get('lastSeen', ''))\n",
    "            \n",
    "            # Check conditions for relevant estate\n",
    "            if last_seen_date < deed_issue_date:\n",
    "                if older_sales_dates != '[]' and older_sales_dates != '' and isinstance(older_sales_dates, list):\n",
    "                    if np.all(np.array([last_seen_date > pd.to_datetime(date) for date in older_sales_dates if pd.to_datetime(date, errors='coerce') is not pd.NaT])):\n",
    "                        relevant_estates.append(estate_dict)\n",
    "                else:\n",
    "                    relevant_estates.append(estate_dict)\n",
    "\n",
    "    return relevant_estates\n",
    "\n",
    "# Apply the function using apply and axis=1\n",
    "data_salesdata['Relevant_Estates_ads_for_transaction'] = data_salesdata.apply(filter_relevant_estates, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(data_salesdata['Relevant_Estates_ads_for_transaction'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929180"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = data_salesdata[data_salesdata['Relevant_Estates_ads_for_transaction'].apply(len) > 0]\n",
    "len(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE RESULT !!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_merge\\step_2_mrgin_newSales_with_Estate_ads\\setup\\setup_Relevant_Estates_ads_for_transaction_step_2.csv'\n",
    "data_salesdata.to_csv(path,encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2623340 entries, 0 to 2623339\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                  Non-Null Count    Dtype         \n",
      "---  ------                                  --------------    -----         \n",
      " 0   RowID_MAIN_boliga_ROW_ID_unitID         2623340 non-null  object        \n",
      " 1   salesInfo_deedIssueDate                 2623340 non-null  datetime64[ns]\n",
      " 2   salesInfo_recalculationDate             2623340 non-null  object        \n",
      " 3   unique_sales_ID                         2623340 non-null  int64         \n",
      " 4   RAW_dictionary_previousEstates          1790826 non-null  object        \n",
      " 5   salesInfo_OTHER_sales_dates_by_main_ID  2623340 non-null  object        \n",
      " 6   salesInfo_OLDER_sales_dates_by_main_ID  2623340 non-null  object        \n",
      " 7   Relevant_Estates_ads_for_transaction    2623340 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(6)\n",
      "memory usage: 160.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_salesdata.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --------------------------- check result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['Relevant_Estates_ads_for_transaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "1    [{'estateId': 1931979, 'estateAddress': 'Rønne...\n",
       "2    [{'estateId': 1352628, 'estateAddress': 'Rønne...\n",
       "3                                                   []\n",
       "Name: Relevant_Estates_ads_for_transaction, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['Relevant_Estates_ads_for_transaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estateId': 1931979,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 52,\n",
       "  'salesPrice': 3248000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1931/1931979.jpg',\n",
       "  'lastSeen': Timestamp('2022-11-08 00:00:00'),\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1857402,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 242,\n",
       "  'salesPrice': 3348000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1857/1857402.jpg',\n",
       "  'lastSeen': Timestamp('2022-09-14 00:00:00'),\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'},\n",
       " {'estateId': 1352628,\n",
       "  'estateAddress': 'Rønnevangen 1',\n",
       "  'daysForSale': 26,\n",
       "  'salesPrice': 2975000,\n",
       "  'imageUrl': 'https://i.boliga.org/dk/550x/1352/1352628.jpg',\n",
       "  'lastSeen': Timestamp('2017-08-31 00:00:00'),\n",
       "  'zipCode': 8471,\n",
       "  'city': 'Sabro'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['Relevant_Estates_ads_for_transaction'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2007-09-12\n",
       "1   2023-01-18\n",
       "2   2017-12-11\n",
       "3   2007-09-27\n",
       "Name: salesInfo_deedIssueDate, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_deedIssueDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            []\n",
       "1    ['2007-09-12', '2017-12-11', '2007-09-27']\n",
       "2                  ['2007-09-12', '2007-09-27']\n",
       "3                                ['2007-09-12']\n",
       "Name: salesInfo_OLDER_sales_dates_by_main_ID, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_OLDER_sales_dates_by_main_ID']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_OLDER_sales_dates_by_main_ID'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('2017-12-11') > pd.to_datetime('2017-08-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_salesdata.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_current_date(row):\n",
    "    current_date = row['current_date']\n",
    "    dates_list = row['dates_list']\n",
    "    \n",
    "    if current_date in dates_list:\n",
    "        dates_list.remove(current_date)\n",
    "    \n",
    "    return dates_list\n",
    "\n",
    "# Apply the function to each row\n",
    "data_salesdata['salesInfo_OTHER_sales_dates_by_main_ID'] = data_salesdata.apply(remove_current_date, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named 'df' with columns 'current_date' and 'dates_list'\n",
    "data = {'current_date': ['2022-01-02', '2022-01-05', '2022-01-01'],\n",
    "        'dates_list': [['2022-01-01', '2022-01-02', '2022-01-03'], ['2022-01-04', '2022-01-05', '2022-01-06'], ['2022-01-01', '2022-01-02']]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to remove 'current_date' from 'dates_list' if it exists\n",
    "def remove_current_date(row):\n",
    "    current_date = row['current_date']\n",
    "    dates_list = row['dates_list']\n",
    "    \n",
    "    if current_date in dates_list:\n",
    "        dates_list.remove(current_date)\n",
    "    \n",
    "    return dates_list\n",
    "\n",
    "# Apply the function to each row\n",
    "df['dates_list'] = df.apply(remove_current_date, axis=1)\n",
    "\n",
    "# Display the result\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'ID': [1, 2, 1, 3, 2, 3],\n",
    "        'date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06']}\n",
    "original_df = pd.DataFrame(data)\n",
    "\n",
    "# Group by 'ID' and aggregate dates into a list\n",
    "grouped_df = original_df.groupby('ID')['date'].agg(list).reset_index()\n",
    "\n",
    "# Rename columns if needed\n",
    "grouped_df.columns = ['ID', 'date_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata.groupby('RowID_MAIN_boliga_ROW_ID_unitID')['salesInfo_deedIssueDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'list_of_dates' containing a list of dates for each ID\n",
    "data_salesdata['Property_Older_transactions_dates'] = data_salesdata.groupby('RowID_MAIN_boliga_ROW_ID_unitID')['salesInfo_deedIssueDate'].transform(lambda x: x.tolist())\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['Property_Older_transactions_dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the date equal to the row date from the list\n",
    "data_salesdata['Property_Older_transactions_dates'] = data_salesdata.apply(lambda row: [d for d in row['Property_Older_transactions_dates'] if d != row['salesInfo_deedIssueDate']], axis=1)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove dates that are newer than the row date\n",
    "data_salesdata['Property_Older_transactions_dates'] = data_salesdata.apply(lambda row: [d for d in row['list_of_dates'] if d <= row['salesInfo_deedIssueDate']], axis=1)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by property ID and date\n",
    "data_salesdata.sort_values(by=['RowID_MAIN_boliga_ROW_ID_unitID', 'salesInfo_deedIssueDate'], inplace=True)\n",
    "\n",
    "# Create a new column to store lists of older dates\n",
    "data_salesdata['Property_Older_transactions_dates'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# # Iterate through each row\n",
    "# for index, row in data_salesdata.iterrows():\n",
    "#     counter+=1\n",
    "#     print(counter)\n",
    "#     current_id = row['RowID_MAIN_boliga_ROW_ID_unitID']\n",
    "#     current_date = row['salesInfo_deedIssueDate']\n",
    "    \n",
    "#     # Filter rows with the same ID and older dates\n",
    "#     older_dates = data_salesdata[(data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID'] == current_id) &\n",
    "#                                  (data_salesdata['salesInfo_deedIssueDate'] < current_date)]['salesInfo_deedIssueDate'].tolist()\n",
    "    \n",
    "#     # Update the 'older_dates' column with the list of older dates\n",
    "#     data_salesdata.at[index, 'Property_Older_transactions_dates'] = older_dates\n",
    "\n",
    "# # If needed, you can sort the DataFrame back to its original order\n",
    "# data_salesdata.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "################################################## USING ProcessPoolExecutor...... NOT GOOD \n",
    "\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# counter = 0\n",
    "\n",
    "# def process_row(index, row, data_salesdata):\n",
    "#     global counter\n",
    "#     counter += 1\n",
    "#     logging.info(f\"Processing row {counter}\")\n",
    "\n",
    "#     current_id = row['RowID_MAIN_boliga_ROW_ID_unitID']\n",
    "#     current_date = row['salesInfo_deedIssueDate']\n",
    "    \n",
    "#     # Filter rows with the same ID and older dates\n",
    "#     older_dates = data_salesdata[(data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID'] == current_id) &\n",
    "#                                  (data_salesdata['salesInfo_deedIssueDate'] < current_date)]['salesInfo_deedIssueDate'].tolist()\n",
    "    \n",
    "#     # Update the 'older_dates' column with the list of older dates\n",
    "#     data_salesdata.at[index, 'older_dates'] = older_dates\n",
    "\n",
    "\n",
    "\n",
    "# Use ProcessPoolExecutor for parallel processing\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for index, row in data_salesdata.iterrows():\n",
    "        future = executor.submit(process_row, index, row, data_salesdata)\n",
    "        futures.append(future)\n",
    "\n",
    "    # Wait for all futures to complete\n",
    "    for future in futures:\n",
    "        future.result()\n",
    "\n",
    "# If needed, you can sort the DataFrame back to its original order\n",
    "data_salesdata.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################## USING THREADPOOL...... NOT GOOD \n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# import threading\n",
    "\n",
    "\n",
    "# counter=0\n",
    "# counter_lock = threading.Lock()\n",
    "\n",
    "# def process_row(index, row, data_salesdata):\n",
    "#     global counter\n",
    "#     with counter_lock:\n",
    "#         counter += 1\n",
    "#         print(f\"Processing row {counter}\")\n",
    "\n",
    "\n",
    "#     current_id = row['RowID_MAIN_boliga_ROW_ID_unitID']\n",
    "#     current_date = row['salesInfo_deedIssueDate']\n",
    "    \n",
    "#     # Filter rows with the same ID and older dates\n",
    "#     older_dates = data_salesdata[(data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID'] == current_id) &\n",
    "#                                  (data_salesdata['salesInfo_deedIssueDate'] < current_date)]['salesInfo_deedIssueDate'].tolist()\n",
    "    \n",
    "#     # Update the 'older_dates' column with the list of older dates\n",
    "#     data_salesdata.at[index, 'older_dates'] = older_dates\n",
    "\n",
    "# # Use ThreadPoolExecutor for parallel processing\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     futures = []\n",
    "#     for index, row in data_salesdata.iterrows():\n",
    "#         future = executor.submit(process_row, index, row, data_salesdata)\n",
    "#         futures.append(future)\n",
    "\n",
    "#     # Wait for all futures to complete\n",
    "#     for future in futures:\n",
    "#         future.result()\n",
    "\n",
    "# # If needed, you can sort the DataFrame back to its original order\n",
    "# data_salesdata.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "316 2,3min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "\n",
    "if test: \n",
    "    print('okj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# If not, replace df with the actual DataFrame name\n",
    "\n",
    "\n",
    "# Create an empty list to store the relevant estates for each row\n",
    "relevant_estates_list = []\n",
    "\n",
    "\n",
    "counter = 0\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in data_salesdata.iterrows():\n",
    "    counter +=1\n",
    "    # if counter%1000==0:\n",
    "    #     print(f'--------> row nr. {counter} out of 2623340')\n",
    "    print(f'--------> row nr. {counter} out of 2623340')\n",
    "\n",
    "    current_id = row['RowID_MAIN_boliga_ROW_ID_unitID']\n",
    "    current_date = row['salesInfo_deedIssueDate']\n",
    "    current_advertisements = row['RAW_dictionary_previousEstates']\n",
    "\n",
    "    print('CURRNET DATE:',current_date)\n",
    "    display(current_advertisements)\n",
    "\n",
    "    if not current_advertisements:\n",
    "        relevant_estates_list.append([])\n",
    "    else:\n",
    "        # Filter relevant advertisements based on the criteria\n",
    "        relevant_advertisements = [\n",
    "            ad for ad in current_advertisements\n",
    "            if 'lastSeen' in ad and pd.to_datetime(ad['lastSeen'].replace('okt', 'oct').replace('maj', 'may')) < current_date\n",
    "        ]\n",
    "\n",
    "        # Check if the relevant advertisements are newer than others for the same property\n",
    "        if relevant_advertisements:\n",
    "            previous_transactions = data_salesdata[\n",
    "                (data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID'] == current_id) &\n",
    "                (data_salesdata['salesInfo_deedIssueDate'] < current_date)\n",
    "            ]\n",
    "\n",
    "            # Check if previous_transactions is not empty before finding the maximum date\n",
    "            if not previous_transactions.empty:\n",
    "                if not any(pd.to_datetime(ad['lastSeen'].replace('okt', 'oct').replace('maj', 'may')) > previous_transactions['salesInfo_deedIssueDate'] for ad in relevant_advertisements):\n",
    "                    relevant_estates_list.append(relevant_advertisements)\n",
    "                    print('RELEVANT ADS')\n",
    "                    display(relevant_advertisements)\n",
    "                else:\n",
    "                    relevant_estates_list.append([])\n",
    "            else:\n",
    "                relevant_estates_list.append([])\n",
    "        else:\n",
    "            relevant_estates_list.append([])\n",
    "\n",
    "# Add the new list to the DataFrame\n",
    "data_salesdata['Relevant_estates_to_transaction_list'] = relevant_estates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- cahnge month names so datetime can convert it correctly\n",
    "data_previousEstate['PreviousEstate_lastSeen'] = data_previousEstate['PreviousEstate_lastSeen'].str.replace('okt', 'oct')\n",
    "data_previousEstate['PreviousEstate_lastSeen'] = data_previousEstate['PreviousEstate_lastSeen'].str.replace('maj', 'may')\n",
    "\n",
    "# convert column to date object\n",
    "data_previousEstate['PreviousEstate_lastSeen'] = pd.to_datetime(data_previousEstate['PreviousEstate_lastSeen'], format=\"%d. %b. %Y\")#.dt.date\n",
    "\n",
    "type(data_previousEstate['PreviousEstate_lastSeen'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _______________ read in the NEW SALES data (Sales+evaluation)______________________________________ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_sales = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_merge\\step_1_mergin_Sales_transactions_with_evaluation_data\\Boliga_salesData_SalesTransactions_with_evaluation_2623340rows_20columns.csv'\n",
    "data_salesdata = pd.read_csv(path_sales, encoding = 'utf-8', low_memory=False) #,nrows=1000)\n",
    "data_salesdata.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_salesdata['unique_sales_ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- -CREATE UNIQUE ID column for the sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['unique_sales_ID'] = range(1, len(data_salesdata) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- convert salesInfo_deedIssueDate to date object with only day,month and year  \n",
    "\n",
    "\n",
    "### NOTE !!!!!!!!!!!!!!!! THE SEEMS TO BE AN ERROR IN THE YEAR OF THE DATA YEARS WITH 2000 AND 1999 SEEM TO GET THE YEAR 1899 IN THE salesInfo_deedIssueDate - BETTER TO GET THE YEAR FROM RECALCULATIONdATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['salesInfo_deedIssueDate'] = pd.to_datetime(data_salesdata['salesInfo_deedIssueDate'], format=\"%Y-%m-%d\")#.dt.date\n",
    "type(data_salesdata['salesInfo_deedIssueDate'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------- convert salesInfo_recalculationDate to date object as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['salesInfo_recalculationDate'] = pd.to_datetime(data_salesdata['salesInfo_recalculationDate'], format=\"%Y-%m-%d\",errors='coerce')#.dt.date\n",
    "type(data_salesdata['salesInfo_recalculationDate'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------- REMOVE NON VALID SALES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['salesInfo_isSalesValid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_salesInfo = data_salesInfo[data_salesInfo['salesInfo_isSalesValid']==True]\n",
    "# data_salesInfo = data_salesInfo.reset_index(dropbbb=True)\n",
    "# data_salesInfo.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _______________ read in the Previous Evaluation data (with the asking price)______________________________________ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ESTATE=r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_split\\14_PreviousEstate\\Ready\\Boliga_propertySales_previousEstate_READY.csv'\n",
    "data_previousEstate = pd.read_csv(path_ESTATE, encoding = 'utf-8', low_memory=False) #,nrows=1000)\n",
    "data_previousEstate.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---- convert column \"PreviousEstate_lastSeen\" as date object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- cahnge month names so datetime can convert it correctly\n",
    "data_previousEstate['PreviousEstate_lastSeen'] = data_previousEstate['PreviousEstate_lastSeen'].str.replace('okt', 'oct')\n",
    "data_previousEstate['PreviousEstate_lastSeen'] = data_previousEstate['PreviousEstate_lastSeen'].str.replace('maj', 'may')\n",
    "\n",
    "# convert column to date object\n",
    "data_previousEstate['PreviousEstate_lastSeen'] = pd.to_datetime(data_previousEstate['PreviousEstate_lastSeen'], format=\"%d. %b. %Y\")#.dt.date\n",
    "\n",
    "type(data_previousEstate['PreviousEstate_lastSeen'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show result\n",
    "data_previousEstate['PreviousEstate_lastSeen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ______________________________________________________ The PLAN: \n",
    "\n",
    "## ---- First: there are some properties which have maybe 2 or more ads/estates which technicall belongs to the same final transaction sale. e.g. property A is put on market in Jan then in mars they take it of and in august they put in on again and finally gets sold in December.... therefore I need to account for this - also this can overlap over 2 years instead of happening within a single year \n",
    "\n",
    "\n",
    "# the plan is as follows: \n",
    "* Create following columns in dataframe: data_salesdata\n",
    "    * Number_of_estates_ads\n",
    "    * Number_of_days_between_ads\n",
    "    * Total_daysForSale\n",
    "    * LastAd_askingPrice_lastAd\n",
    "    * FirstAd_askingPrice_firstAd\n",
    "    * LastAd_daysForSale\n",
    "    * FirstAd_daysForSale\n",
    "    * LastAd_lastSeen_Date\n",
    "    * FirstAd_lastSeen_Date\n",
    "\n",
    "* LOOP over each row in data_salesdata\n",
    "    * check if Main ID exists in the main ID in data_previousEstate dataframe\n",
    "    * if yes then:\n",
    "        * get all rows in data_previousEstate that match the main ID \n",
    "        * also get the dates of all sales in data_salesdata\n",
    "        * LOOP OVER each filtered row: \n",
    "            * make sure that the date of sale is newer then all the other dates of Estate \n",
    "            * then make sure that the date of the Estate is NEWER than all the previous Sales\n",
    "            * if that works then:\n",
    "                * add values to columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_columns = [\n",
    "#     'PreviousEstate_Number_of_estates_ads', \n",
    "#     'PreviousEstate_Number_of_days_between_ads', \n",
    "#     'PreviousEstate_Total_daysForSale', \n",
    "#     'PreviousEstate_LastAd_askingPrice_lastAd', \n",
    "#     'PreviousEstate_FirstAd_askingPrice_firstAd', \n",
    "#     'PreviousEstate_LastAd_daysForSale', \n",
    "#     'PreviousEstate_FirstAd_daysForSale', \n",
    "#     'PreviousEstate_LastAd_lastSeen_Date', \n",
    "#     'PreviousEstate_FirstAd_lastSeen_Date', \n",
    "# ]\n",
    "\n",
    "# data_salesdata.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Create new columns : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata['PreviousEstate_Number_of_estates_ads'] = None\n",
    "data_salesdata['PreviousEstate_Number_of_days_between_ads'] = None\n",
    "data_salesdata['PreviousEstate_Total_daysForSale'] = None\n",
    "data_salesdata['PreviousEstate_NEWEST_Ad_askingPrice_lastAd'] = None\n",
    "data_salesdata['PreviousEstate_OLDEST_Ad_askingPrice_firstAd'] = None\n",
    "data_salesdata['PreviousEstate_NEWEST_Ad_daysForSale'] = None\n",
    "data_salesdata['PreviousEstate_OLDEST_Ad_daysForSale'] = None\n",
    "data_salesdata['PreviousEstate_NEWEST_Ad_lastSeen_Date'] = None\n",
    "data_salesdata['PreviousEstate_OLDEST_Ad_lastSeen_Date'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique IDs from DataFrame B\n",
    "unique_ids_b = data_previousEstate['RowID_MAIN_boliga_ROW_ID_unitID'].unique()\n",
    "\n",
    "# Use isin to filter DataFrame A based on IDs in DataFrame B\n",
    "filtered_data_salesdata = data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID'].isin(unique_ids_b)]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "filtered_data_salesdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- trying to make the code more efficient with tuples and apply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_Estates(subset_data_previousEstate):\n",
    "    Total_daysForSale = 0\n",
    "    Number_of_estates_ads = 0\n",
    "    estate_dataframe_index_list_that_belong_to_sale = []\n",
    "\n",
    "     for index_B, row_B in subset_data_previousEstate.iterrows():\n",
    "        row_estate_date = row_B['PreviousEstate_lastSeen']\n",
    "\n",
    "        # Check if the condition is fulfilled\n",
    "        \n",
    "        if (row_estate_date < row_sale_date) and all(row_estate_date > date for date in dates_from_salesdata):\n",
    "            # print('BINGO')\n",
    "            Number_of_estates_ads+=1\n",
    "            Total_daysForSale += row_B['PreviousEstate_daysForSale']\n",
    "\n",
    "            # create tuple with date (lastSeen) and date and asking price\n",
    "            estate_dataframe_index_list_that_belong_to_sale.append(index_B)\n",
    "\n",
    "\n",
    "def start(tuple_item_sales, list_of_tuples_ESTATE, list_of_tuples_SALES):\n",
    "    global Sales_index_counter\n",
    "\n",
    "    # keep track of things\n",
    "    Sales_index_counter +=1 \n",
    "    if Sales_index_counter%10==0:\n",
    "        print(f'-----------------> Nr. rows done: {Sales_index_counter} out of 2.623.340')\n",
    "\n",
    "    # get 2 key variables of the row\n",
    "    id_code = tuple_item[]\n",
    "    row_sale_date = tuple_item[4] \n",
    "    unique_sales_ID_row = tuple_item[8]\n",
    "\n",
    "    ## Get subset of DataFrame B for the current ID in Sales data as list of tuples\n",
    "    subset_data_previousEstate = [tpl for tpl in list_of_tuples_ESTATE if tpl[0] == id_code]\n",
    "\n",
    "\n",
    "    # Create a list of all sales dates from DataFrame data_salesdata with the same ID excluding the current date\n",
    "    dates_from_salesdata_tuples = [\n",
    "    tpl[4] for tpl in list_of_tuples_SALES if tpl[0] == id_code and tpl[4] < row_sale_date\n",
    "    ]\n",
    "    # Remove tuples with dates newer than row_sale_date\n",
    "    # dates_from_salesdata_tuples = [tpl for tpl in dates_from_salesdata_tuples if tpl[4] <= row_sale_date]\n",
    "\n",
    "    # create variables to add to dataframe\n",
    "    # Number_of_estates_ads = 0\n",
    "    # Total_daysForSale = 0\n",
    "    NEWEST_Ad_askingPrice_lastAd = 0\n",
    "    OLDEST_Ad_askingPrice_firstAd = 0\n",
    "    NEWEST_Ad_daysForSale = 0\n",
    "    OLDEST_Ad_daysForSale = 0\n",
    "    NEWEST_Ad_lastSeen_Date = 0\n",
    "    OLDEST_Ad_lastSeen_Date = 0\n",
    "    # estate_dataframe_index_list_that_belong_to_sale = []\n",
    "\n",
    "\n",
    "    # GO OVER ALL THE ESTATES OF THE PROPERTY AND CHECK IF Salesprice matches any of the Estates\n",
    "    Number_of_estates_ads,Total_daysForSale, estate_dataframe_index_list_that_belong_to_sale =  get_Estates(subset_data_previousEstate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# main function : \n",
    "list_of_tuples_ESTATE =  list(data_previousEstate.to_records(index=False))\n",
    "\n",
    "list_of_tuples_SALES =  list(filtered_data_salesdata.to_records(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tuples[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----- run the program  --- BASIC FOR-LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "Sales_index_counter = 0 \n",
    "# Loop over each row in Salesdata\n",
    "for index_data_salesdata, row_data_salesdata in data_salesdata.iterrows():\n",
    "    Sales_index_counter +=1 \n",
    "    if Sales_index_counter%10==0:\n",
    "        print(f'-----------------> Nr. rows done: {Sales_index_counter} out of 2.623.340')\n",
    "     \n",
    "    # get key variables:\n",
    "    id_code = row_data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']\n",
    "    row_sale_date = row_data_salesdata['salesInfo_deedIssueDate'] # i think its already a date variable before hand \n",
    "\n",
    "    # if the ID exists in Estate dataframe then carry ON: \n",
    "    if row_data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID'] in data_previousEstate['RowID_MAIN_boliga_ROW_ID_unitID'].values:\n",
    "        # print('############################ PRINTING: Row for Sales data')\n",
    "        # print(row_data_salesdata)\n",
    "        # print()\n",
    "        # print()\n",
    "        # print('=================== PRINTING salesInfo_deedIssueDate of ROW:')\n",
    "        # print(row_sale_date)\n",
    "        # print()\n",
    "\n",
    "        # Get subset of DataFrame B for the current ID in A\n",
    "        subset_data_previousEstate = data_previousEstate[data_previousEstate['RowID_MAIN_boliga_ROW_ID_unitID'] == id_code]\n",
    "        # print('############################ PRINTING: Estate Subset by ID')\n",
    "        # display(subset_data_previousEstate)\n",
    "        # print()\n",
    "\n",
    "        # Create a list of all sales dates from DataFrame data_salesdata with the same ID excluding the current date\n",
    "        dates_from_salesdata = data_salesdata[(data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID'] == id_code) & (data_salesdata['salesInfo_deedIssueDate'] != row_sale_date)]['salesInfo_deedIssueDate'].tolist()\n",
    "        # Remove dates that are newer than row_sale_date i.e. main date of interest at the moment\n",
    "        dates_from_salesdata = [date for date in dates_from_salesdata if date <= row_sale_date]\n",
    "\n",
    "\n",
    "        # print('############################ PRINTING: All dates IN dates_from_salesdata WITH SAME ID')\n",
    "        # display(dates_from_salesdata)\n",
    "        # print()\n",
    "\n",
    "        # create variables to add to dataframe\n",
    "        Number_of_estates_ads = 0\n",
    "        Number_of_days_between_ads = 0 #<--------------- between oldest and newest AD\n",
    "        Total_daysForSale = 0\n",
    "        NEWEST_Ad_askingPrice_lastAd = 0\n",
    "        OLDEST_Ad_askingPrice_firstAd = 0\n",
    "        NEWEST_Ad_daysForSale = 0\n",
    "        OLDEST_Ad_daysForSale = 0\n",
    "        NEWEST_Ad_lastSeen_Date = 0\n",
    "        OLDEST_Ad_lastSeen_Date = 0\n",
    "        estate_dataframe_index_list_that_belong_to_sale = []\n",
    "\n",
    "        # Loop over each row in the subset of DataFrame B : data_previousEstate\n",
    "        # print('-----> for-loop estate subset data')\n",
    "        for index_B, row_B in subset_data_previousEstate.iterrows():\n",
    "            row_estate_date = row_B['PreviousEstate_lastSeen']\n",
    "\n",
    "            # Check if the condition is fulfilled\n",
    "            \n",
    "            if (row_estate_date < row_sale_date) and all(row_estate_date > date for date in dates_from_salesdata):\n",
    "                # print('BINGO')\n",
    "                Number_of_estates_ads+=1\n",
    "                Total_daysForSale += row_B['PreviousEstate_daysForSale']\n",
    "\n",
    "                # create tuple with date (lastSeen) and date and asking price\n",
    "                estate_dataframe_index_list_that_belong_to_sale.append(index_B)\n",
    "            \n",
    "        # Finally filter the Estate subset to only rows wich belong to the Sale row ! \n",
    "        # Create a subset based on the specified row indices\n",
    "        subset_estate_forSale = subset_data_previousEstate.loc[estate_dataframe_index_list_that_belong_to_sale]\n",
    "        # convert Lastseen column to datetime\n",
    "        # subset_estate_forSale['PreviousEstate_lastSeen'] = pd.to_datetime(subset_estate_forSale['PreviousEstate_lastSeen']).dt.date\n",
    "        # print(subset_estate_forSale.dtypes)\n",
    "\n",
    "        # Find the row with the Newest date\n",
    "        newest_row = subset_estate_forSale.nlargest(1, 'PreviousEstate_lastSeen')\n",
    "\n",
    "        # Find the row with the oldest date\n",
    "        oldest_row = subset_estate_forSale.nsmallest(1, 'PreviousEstate_lastSeen')\n",
    "\n",
    "\n",
    "        # -------------------------------------\n",
    "        # CREATE THE  REST OF THE VARIABLES\n",
    "        # -------------------------------------\n",
    "        if Number_of_estates_ads > 1:\n",
    "            # ==============> Number_of_days_between_ads\n",
    "            # print()\n",
    "            # print(newest_row['PreviousEstate_lastSeen'])\n",
    "            # print(oldest_row['PreviousEstate_lastSeen'])\n",
    "\n",
    "            time_diff = oldest_row['PreviousEstate_lastSeen'] - newest_row['PreviousEstate_lastSeen']\n",
    "            \n",
    "            # print('time_diff', time_diff.dt.days.iloc[0])\n",
    "            \n",
    "            Number_of_days_between_ads = time_diff.dt.days.iloc[0]\n",
    "\n",
    "            # ==============> NEWEST_Ad_askingPrice_lastAd\n",
    "            NEWEST_Ad_askingPrice_lastAd = newest_row['PreviousEstate_salesPrice'].iloc[0]\n",
    "            # ==============> OLDEST_Ad_askingPrice_firstAd\n",
    "            OLDEST_Ad_askingPrice_firstAd = oldest_row['PreviousEstate_salesPrice'].iloc[0]\n",
    "            # ===============> NEWEST_Ad_daysForSale\n",
    "            NEWEST_Ad_daysForSale = newest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "            # ===============> OLDEST_Ad_daysForSale\n",
    "            OLDEST_Ad_daysForSale = oldest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "            # ===============> NEWEST_Ad_lastSeen_Date\n",
    "            NEWEST_Ad_lastSeen_Date = newest_row['PreviousEstate_lastSeen'].iloc[0]\n",
    "            # ===============> OLDEST_Ad_lastSeen_Date\n",
    "            OLDEST_Ad_lastSeen_Date = oldest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "\n",
    "        elif Number_of_estates_ads == 1:\n",
    "            \n",
    "            # ==============> NEWEST_Ad_askingPrice_lastAd\n",
    "            NEWEST_Ad_askingPrice_lastAd = newest_row['PreviousEstate_salesPrice'].iloc[0]\n",
    "            # ===============> NEWEST_Ad_daysForSale\n",
    "            NEWEST_Ad_daysForSale = newest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "            # ===============> NEWEST_Ad_lastSeen_Date\n",
    "            NEWEST_Ad_lastSeen_Date = newest_row['PreviousEstate_lastSeen'].iloc[0]\n",
    "        \n",
    "        # elif Number_of_estates_ads == 0:\n",
    "        #     print('################################################')\n",
    "        #     print('----------------- NO ESTATE/ NO AD MATCHES THIS SALE')\n",
    "        #     print('################################################')\n",
    "\n",
    "        # print()\n",
    "        # print('----> RESULT')\n",
    "        # print('----------------------')\n",
    "        # print(f'Number_of_estates_ads = {Number_of_estates_ads}')\n",
    "        # print(f'Number_of_days_between_ads = {Number_of_days_between_ads}')\n",
    "        # print(f'Total_daysForSale = {Total_daysForSale}')\n",
    "        # print(f'NEWEST_Ad_askingPrice_lastAd = {NEWEST_Ad_askingPrice_lastAd}')\n",
    "        # print(f'OLDEST_Ad_askingPrice_firstAd = {OLDEST_Ad_askingPrice_firstAd}')\n",
    "        # print(f'NEWEST_Ad_daysForSale = {NEWEST_Ad_daysForSale}')\n",
    "        # print(f'OLDEST_Ad_daysForSale = {OLDEST_Ad_daysForSale}')\n",
    "        # print(f'NEWEST_Ad_lastSeen_Date = {NEWEST_Ad_lastSeen_Date}')\n",
    "        # print(f'OLDEST_Ad_lastSeen_Date = {OLDEST_Ad_lastSeen_Date}')\n",
    "        \n",
    "\n",
    "        # ==================================\n",
    "        #  ADD RESULT TO DATAFRAME\n",
    "        # ==================================\n",
    "        data_salesdata.at[index_data_salesdata,'PreviousEstate_Number_of_estates_ads'] = Number_of_estates_ads\n",
    "        data_salesdata.at[index_data_salesdata,'PreviousEstate_Number_of_days_between_ads'] = Number_of_days_between_ads\n",
    "        data_salesdata.at[index_data_salesdata,'PreviousEstate_Total_daysForSale'] = Total_daysForSale\n",
    "        data_salesdata.at[index_data_salesdata,'PreviousEstate_NEWEST_Ad_askingPrice_lastAd'] = NEWEST_Ad_askingPrice_lastAd\n",
    "        data_salesdata.at[index_data_salesdata,'PreviousEstate_OLDEST_Ad_askingPrice_firstAd'] = OLDEST_Ad_askingPrice_firstAd\n",
    "        data_salesdata.at[index_data_salesdata,'PreviousEstate_NEWEST_Ad_daysForSale'] = NEWEST_Ad_daysForSale\n",
    "        data_salesdata.at[index_data_salesdata,'PreviousEstate_OLDEST_Ad_daysForSale'] = OLDEST_Ad_daysForSale\n",
    "        data_salesdata.at[index_data_salesdata,'PreviousEstate_NEWEST_Ad_lastSeen_Date'] = NEWEST_Ad_lastSeen_Date\n",
    "        data_salesdata.at[index_data_salesdata,'PreviousEstate_OLDEST_Ad_lastSeen_Date'] = OLDEST_Ad_lastSeen_Date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----- concurrent futures test version : new VERSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(index_data_salesdata):\n",
    "    global Sales_index_counter\n",
    "    global data_salesdata\n",
    "    global data_previousEstate\n",
    "\n",
    "    try: \n",
    "        with lock:\n",
    "            id_code = data_salesdata.at[index_data_salesdata,'RowID_MAIN_boliga_ROW_ID_unitID']\n",
    "            row_sale_date = data_salesdata.at[index_data_salesdata,'salesInfo_deedIssueDate']\n",
    "\n",
    "            Sales_index_counter += 1\n",
    "\n",
    "            if Sales_index_counter % 1000 == 0:\n",
    "                print(f'-----------------> Nr. rows done: {Sales_index_counter} out of 2.623.340')\n",
    "\n",
    "            # if the ID exists in Estate dataframe then carry ON: \n",
    "            if id_code in data_previousEstate['RowID_MAIN_boliga_ROW_ID_unitID'].values:\n",
    "                # Get subset of DataFrame B for the current ID in A\n",
    "                subset_data_previousEstate = data_previousEstate[data_previousEstate['RowID_MAIN_boliga_ROW_ID_unitID'] == id_code]\n",
    "\n",
    "                # Create a list of all sales dates from DataFrame data_salesdata with the same ID excluding the current date\n",
    "                dates_from_salesdata = data_salesdata[(data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID'] == id_code) & (data_salesdata['salesInfo_deedIssueDate'] != row_sale_date)]['salesInfo_deedIssueDate'].tolist()\n",
    "                # Remove dates that are newer than row_sale_date i.e. main date of interest at the moment\n",
    "                dates_from_salesdata = [date for date in dates_from_salesdata if date <= row_sale_date]\n",
    "\n",
    "\n",
    "                # create variables to add to dataframe\n",
    "                Number_of_estates_ads = 0\n",
    "                Number_of_days_between_ads = 0 #<--------------- between oldest and newest AD\n",
    "                Total_daysForSale = 0\n",
    "                NEWEST_Ad_askingPrice_lastAd = 0\n",
    "                OLDEST_Ad_askingPrice_firstAd = 0\n",
    "                NEWEST_Ad_daysForSale = 0\n",
    "                OLDEST_Ad_daysForSale = 0\n",
    "                NEWEST_Ad_lastSeen_Date = 0\n",
    "                OLDEST_Ad_lastSeen_Date = 0\n",
    "                estate_dataframe_index_list_that_belong_to_sale = []\n",
    "\n",
    "                # Loop over each row in the subset of DataFrame B : data_previousEstate\n",
    "                # print('-----> for-loop estate subset data')\n",
    "                for index_B, row_B in subset_data_previousEstate.iterrows():\n",
    "                    row_estate_date = row_B['PreviousEstate_lastSeen']\n",
    "\n",
    "                    # Check if the condition is fulfilled\n",
    "                    \n",
    "                    if (row_estate_date < row_sale_date) and all(row_estate_date > date for date in dates_from_salesdata):\n",
    "                        # print('BINGO')\n",
    "                        Number_of_estates_ads+=1\n",
    "                        Total_daysForSale += row_B['PreviousEstate_daysForSale']\n",
    "\n",
    "                        # create tuple with date (lastSeen) and date and asking price\n",
    "                        estate_dataframe_index_list_that_belong_to_sale.append(index_B)\n",
    "                    \n",
    "                # Finally filter the Estate subset to only rows wich belong to the Sale row ! \n",
    "                # Create a subset based on the specified row indices\n",
    "                subset_estate_forSale = subset_data_previousEstate.loc[estate_dataframe_index_list_that_belong_to_sale]\n",
    "\n",
    "                # Find the row with the Newest date\n",
    "                newest_row = subset_estate_forSale.nlargest(1, 'PreviousEstate_lastSeen')\n",
    "\n",
    "                # Find the row with the oldest date\n",
    "                oldest_row = subset_estate_forSale.nsmallest(1, 'PreviousEstate_lastSeen')\n",
    "\n",
    "\n",
    "                # -------------------------------------\n",
    "                # CREATE THE  REST OF THE VARIABLES\n",
    "                # -------------------------------------\n",
    "                if Number_of_estates_ads > 1:\n",
    "\n",
    "                    time_diff = oldest_row['PreviousEstate_lastSeen'] - newest_row['PreviousEstate_lastSeen']\n",
    "                    \n",
    "                    # print('time_diff', time_diff.dt.days.iloc[0])\n",
    "                    \n",
    "                    Number_of_days_between_ads = time_diff.dt.days.iloc[0]\n",
    "\n",
    "                    # ==============> NEWEST_Ad_askingPrice_lastAd\n",
    "                    NEWEST_Ad_askingPrice_lastAd = newest_row['PreviousEstate_salesPrice'].iloc[0]\n",
    "                    # ==============> OLDEST_Ad_askingPrice_firstAd\n",
    "                    OLDEST_Ad_askingPrice_firstAd = oldest_row['PreviousEstate_salesPrice'].iloc[0]\n",
    "                    # ===============> NEWEST_Ad_daysForSale\n",
    "                    NEWEST_Ad_daysForSale = newest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "                    # ===============> OLDEST_Ad_daysForSale\n",
    "                    OLDEST_Ad_daysForSale = oldest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "                    # ===============> NEWEST_Ad_lastSeen_Date\n",
    "                    NEWEST_Ad_lastSeen_Date = newest_row['PreviousEstate_lastSeen'].iloc[0]\n",
    "                    # ===============> OLDEST_Ad_lastSeen_Date\n",
    "                    OLDEST_Ad_lastSeen_Date = oldest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "\n",
    "                elif Number_of_estates_ads == 1:\n",
    "                    \n",
    "                    # ==============> NEWEST_Ad_askingPrice_lastAd\n",
    "                    NEWEST_Ad_askingPrice_lastAd = newest_row['PreviousEstate_salesPrice'].iloc[0]\n",
    "                    # ===============> NEWEST_Ad_daysForSale\n",
    "                    NEWEST_Ad_daysForSale = newest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "                    # ===============> NEWEST_Ad_lastSeen_Date\n",
    "                    NEWEST_Ad_lastSeen_Date = newest_row['PreviousEstate_lastSeen'].iloc[0]\n",
    "\n",
    "                print()\n",
    "                print('----> RESULT')\n",
    "                print('----------------------')\n",
    "                print(f'Number_of_estates_ads = {Number_of_estates_ads}')\n",
    "                print(f'Number_of_days_between_ads = {Number_of_days_between_ads}')\n",
    "                print(f'Total_daysForSale = {Total_daysForSale}')\n",
    "                print(f'NEWEST_Ad_askingPrice_lastAd = {NEWEST_Ad_askingPrice_lastAd}')\n",
    "                print(f'OLDEST_Ad_askingPrice_firstAd = {OLDEST_Ad_askingPrice_firstAd}')\n",
    "                print(f'NEWEST_Ad_daysForSale = {NEWEST_Ad_daysForSale}')\n",
    "                print(f'OLDEST_Ad_daysForSale = {OLDEST_Ad_daysForSale}')\n",
    "                print(f'NEWEST_Ad_lastSeen_Date = {NEWEST_Ad_lastSeen_Date}')\n",
    "                print(f'OLDEST_Ad_lastSeen_Date = {OLDEST_Ad_lastSeen_Date}')\n",
    "                    \n",
    "\n",
    "                # ==================================\n",
    "                #  ADD RESULT TO DATAFRAME\n",
    "                # ==================================\n",
    "                data_salesdata.at[index_data_salesdata,'PreviousEstate_Number_of_estates_ads'] = Number_of_estates_ads\n",
    "                data_salesdata.at[index_data_salesdata,'PreviousEstate_Number_of_days_between_ads'] = Number_of_days_between_ads\n",
    "                data_salesdata.at[index_data_salesdata,'PreviousEstate_Total_daysForSale'] = Total_daysForSale\n",
    "                data_salesdata.at[index_data_salesdata,'PreviousEstate_NEWEST_Ad_askingPrice_lastAd'] = NEWEST_Ad_askingPrice_lastAd\n",
    "                data_salesdata.at[index_data_salesdata,'PreviousEstate_OLDEST_Ad_askingPrice_firstAd'] = OLDEST_Ad_askingPrice_firstAd\n",
    "                data_salesdata.at[index_data_salesdata,'PreviousEstate_NEWEST_Ad_daysForSale'] = NEWEST_Ad_daysForSale\n",
    "                data_salesdata.at[index_data_salesdata,'PreviousEstate_OLDEST_Ad_daysForSale'] = OLDEST_Ad_daysForSale\n",
    "                data_salesdata.at[index_data_salesdata,'PreviousEstate_NEWEST_Ad_lastSeen_Date'] = NEWEST_Ad_lastSeen_Date\n",
    "                data_salesdata.at[index_data_salesdata,'PreviousEstate_OLDEST_Ad_lastSeen_Date'] = OLDEST_Ad_lastSeen_Date\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Catch any exception that occurs within the task\n",
    "        print('------------------------------ SHIIIIIIIIIIIIIIIIIIIIIIIIIIIITTTTTTTTT ----------------------')\n",
    "        print(f\"Error processing row {index_data_salesdata}: {e}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from multiprocessing import Lock\n",
    "\n",
    "# Define a lock\n",
    "lock = Lock()\n",
    "\n",
    "# Create a list with all index numbers of the DataFrame\n",
    "index_list = list(data_salesdata.index)\n",
    "\n",
    "# run the concurrency \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor: \n",
    "        # run script\n",
    "        executor.map(process_row,index_list)\n",
    "\n",
    "# for row in index_list:\n",
    "#     process_row(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----- concurrent futures test version : OLD VERSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def process_row(index_data_salesdata, row_data_salesdata, data_salesdata, data_previousEstate):\n",
    "    global Sales_index_counter\n",
    "    try: \n",
    "        id_code = row_data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']\n",
    "        row_sale_date = row_data_salesdata['salesInfo_deedIssueDate']\n",
    "\n",
    "        Sales_index_counter += 1\n",
    "\n",
    "        if Sales_index_counter % 1000 == 0:\n",
    "            print(f'-----------------> Nr. rows done: {Sales_index_counter} out of 2.623.340')\n",
    "\n",
    "        # if the ID exists in Estate dataframe then carry ON: \n",
    "        if row_data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID'] in data_previousEstate['RowID_MAIN_boliga_ROW_ID_unitID'].values:\n",
    "            # Get subset of DataFrame B for the current ID in A\n",
    "            subset_data_previousEstate = data_previousEstate[data_previousEstate['RowID_MAIN_boliga_ROW_ID_unitID'] == id_code]\n",
    "\n",
    "            # Create a list of all sales dates from DataFrame data_salesdata with the same ID excluding the current date\n",
    "            dates_from_salesdata = data_salesdata[(data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID'] == id_code) & (data_salesdata['salesInfo_deedIssueDate'] != row_sale_date)]['salesInfo_deedIssueDate'].tolist()\n",
    "            # Remove dates that are newer than row_sale_date i.e. main date of interest at the moment\n",
    "            dates_from_salesdata = [date for date in dates_from_salesdata if date <= row_sale_date]\n",
    "\n",
    "\n",
    "            # create variables to add to dataframe\n",
    "            Number_of_estates_ads = 0\n",
    "            Number_of_days_between_ads = 0 #<--------------- between oldest and newest AD\n",
    "            Total_daysForSale = 0\n",
    "            NEWEST_Ad_askingPrice_lastAd = 0\n",
    "            OLDEST_Ad_askingPrice_firstAd = 0\n",
    "            NEWEST_Ad_daysForSale = 0\n",
    "            OLDEST_Ad_daysForSale = 0\n",
    "            NEWEST_Ad_lastSeen_Date = 0\n",
    "            OLDEST_Ad_lastSeen_Date = 0\n",
    "            estate_dataframe_index_list_that_belong_to_sale = []\n",
    "\n",
    "            # Loop over each row in the subset of DataFrame B : data_previousEstate\n",
    "            # print('-----> for-loop estate subset data')\n",
    "            for index_B, row_B in subset_data_previousEstate.iterrows():\n",
    "                row_estate_date = row_B['PreviousEstate_lastSeen']\n",
    "\n",
    "                # Check if the condition is fulfilled\n",
    "                \n",
    "                if (row_estate_date < row_sale_date) and all(row_estate_date > date for date in dates_from_salesdata):\n",
    "                    # print('BINGO')\n",
    "                    Number_of_estates_ads+=1\n",
    "                    Total_daysForSale += row_B['PreviousEstate_daysForSale']\n",
    "\n",
    "                    # create tuple with date (lastSeen) and date and asking price\n",
    "                    estate_dataframe_index_list_that_belong_to_sale.append(index_B)\n",
    "                \n",
    "            # Finally filter the Estate subset to only rows wich belong to the Sale row ! \n",
    "            # Create a subset based on the specified row indices\n",
    "            subset_estate_forSale = subset_data_previousEstate.loc[estate_dataframe_index_list_that_belong_to_sale]\n",
    "\n",
    "            # Find the row with the Newest date\n",
    "            newest_row = subset_estate_forSale.nlargest(1, 'PreviousEstate_lastSeen')\n",
    "\n",
    "            # Find the row with the oldest date\n",
    "            oldest_row = subset_estate_forSale.nsmallest(1, 'PreviousEstate_lastSeen')\n",
    "\n",
    "\n",
    "            # -------------------------------------\n",
    "            # CREATE THE  REST OF THE VARIABLES\n",
    "            # -------------------------------------\n",
    "            if Number_of_estates_ads > 1:\n",
    "\n",
    "                time_diff = oldest_row['PreviousEstate_lastSeen'] - newest_row['PreviousEstate_lastSeen']\n",
    "                \n",
    "                # print('time_diff', time_diff.dt.days.iloc[0])\n",
    "                \n",
    "                Number_of_days_between_ads = time_diff.dt.days.iloc[0]\n",
    "\n",
    "                # ==============> NEWEST_Ad_askingPrice_lastAd\n",
    "                NEWEST_Ad_askingPrice_lastAd = newest_row['PreviousEstate_salesPrice'].iloc[0]\n",
    "                # ==============> OLDEST_Ad_askingPrice_firstAd\n",
    "                OLDEST_Ad_askingPrice_firstAd = oldest_row['PreviousEstate_salesPrice'].iloc[0]\n",
    "                # ===============> NEWEST_Ad_daysForSale\n",
    "                NEWEST_Ad_daysForSale = newest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "                # ===============> OLDEST_Ad_daysForSale\n",
    "                OLDEST_Ad_daysForSale = oldest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "                # ===============> NEWEST_Ad_lastSeen_Date\n",
    "                NEWEST_Ad_lastSeen_Date = newest_row['PreviousEstate_lastSeen'].iloc[0]\n",
    "                # ===============> OLDEST_Ad_lastSeen_Date\n",
    "                OLDEST_Ad_lastSeen_Date = oldest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "\n",
    "            elif Number_of_estates_ads == 1:\n",
    "                \n",
    "                # ==============> NEWEST_Ad_askingPrice_lastAd\n",
    "                NEWEST_Ad_askingPrice_lastAd = newest_row['PreviousEstate_salesPrice'].iloc[0]\n",
    "                # ===============> NEWEST_Ad_daysForSale\n",
    "                NEWEST_Ad_daysForSale = newest_row['PreviousEstate_daysForSale'].iloc[0]\n",
    "                # ===============> NEWEST_Ad_lastSeen_Date\n",
    "                NEWEST_Ad_lastSeen_Date = newest_row['PreviousEstate_lastSeen'].iloc[0]\n",
    "                \n",
    "\n",
    "            # ==================================\n",
    "            #  ADD RESULT TO DATAFRAME\n",
    "            # ==================================\n",
    "            data_salesdata.at[index_data_salesdata,'PreviousEstate_Number_of_estates_ads'] = Number_of_estates_ads\n",
    "            data_salesdata.at[index_data_salesdata,'PreviousEstate_Number_of_days_between_ads'] = Number_of_days_between_ads\n",
    "            data_salesdata.at[index_data_salesdata,'PreviousEstate_Total_daysForSale'] = Total_daysForSale\n",
    "            data_salesdata.at[index_data_salesdata,'PreviousEstate_NEWEST_Ad_askingPrice_lastAd'] = NEWEST_Ad_askingPrice_lastAd\n",
    "            data_salesdata.at[index_data_salesdata,'PreviousEstate_OLDEST_Ad_askingPrice_firstAd'] = OLDEST_Ad_askingPrice_firstAd\n",
    "            data_salesdata.at[index_data_salesdata,'PreviousEstate_NEWEST_Ad_daysForSale'] = NEWEST_Ad_daysForSale\n",
    "            data_salesdata.at[index_data_salesdata,'PreviousEstate_OLDEST_Ad_daysForSale'] = OLDEST_Ad_daysForSale\n",
    "            data_salesdata.at[index_data_salesdata,'PreviousEstate_NEWEST_Ad_lastSeen_Date'] = NEWEST_Ad_lastSeen_Date\n",
    "            data_salesdata.at[index_data_salesdata,'PreviousEstate_OLDEST_Ad_lastSeen_Date'] = OLDEST_Ad_lastSeen_Date\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Catch any exception that occurs within the task\n",
    "        print(f\"Error processing row {index_data_salesdata}: {e}\")\n",
    "\n",
    "\n",
    "Sales_index_counter = 0 \n",
    "\n",
    "# Using ThreadPoolExecutor for concurrent processing\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    \n",
    "    for index_data_salesdata, row_data_salesdata in data_salesdata.iterrows():\n",
    "        futures.append(executor.submit(process_row, index_data_salesdata, row_data_salesdata, data_salesdata, data_previousEstate))\n",
    "        \n",
    "\n",
    " # Wait for all futures to complete with a timeout\n",
    "concurrent.futures.wait(futures, timeout=120)  # Adjust the timeout as needed (e.g., 3600 seconds or 1 hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10,2 210000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generating example data\n",
    "oldest_row = pd.DataFrame({'PreviousEstate_lastSeen': [pd.to_datetime('2022-09-14')]})\n",
    "newest_row = pd.DataFrame({'PreviousEstate_lastSeen': [pd.to_datetime('2022-11-08')]})\n",
    "\n",
    "# Check for NaT before subtraction\n",
    "if pd.notna(oldest_row['PreviousEstate_lastSeen'].iloc[0]) and pd.notna(newest_row['PreviousEstate_lastSeen'].iloc[0]):\n",
    "    # Calculate time difference\n",
    "    time_diff = newest_row['PreviousEstate_lastSeen'] - oldest_row['PreviousEstate_lastSeen']\n",
    "\n",
    "    # Extract number of days\n",
    "    Number_of_days_between_ads = time_diff.dt.days.iloc[0]\n",
    "    \n",
    "    # Print results\n",
    "    print(f'oldest_row: {oldest_row[\"PreviousEstate_lastSeen\"].iloc[0]}')\n",
    "    print(f'newest_row: {newest_row[\"PreviousEstate_lastSeen\"].iloc[0]}')\n",
    "    print(f'Number of days between the two dates: {Number_of_days_between_ads}')\n",
    "else:\n",
    "    print('One or both of the dates are NaT.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesdata[data_salesdata['RowID_MAIN_boliga_ROW_ID_unitID']== '9133416f-191b-496e-88bb-62b3a46a370a']['salesInfo_recalculationDate'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_previousEstate[data_previousEstate['RowID_MAIN_boliga_ROW_ID_unitID']=='9133416f-191b-496e-88bb-62b3a46a370a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample DataFrames\n",
    "data_A = {'ID': [1, 2, 1, 3, 2],\n",
    "          'SalePrice': [100000, 150000, 120000, 200000, 180000],\n",
    "          'Date': ['2022-01-01', '2022-02-01', '2022-03-01', '2022-04-01', '2022-05-01']}\n",
    "df_A = pd.DataFrame(data_A)\n",
    "display(df_A)\n",
    "\n",
    "data_B = {'ID': [1, 2, 1, 3, 2],\n",
    "          'Date': ['2022-01-05', '2022-02-15', '2022-03-10', '2022-04-20', '2022-05-05'],\n",
    "          'DaysOnMarket': [5, 10, 7, 15, 8]}\n",
    "df_B = pd.DataFrame(data_B)\n",
    "display(df_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each row in DataFrame A\n",
    "for index_A, row_A in df_A.iterrows():\n",
    "    id_code = row_A['ID']\n",
    "    sale_date_A = pd.to_datetime(row_A['Date'])\n",
    "\n",
    "    # Get subset of DataFrame B for the current ID in A\n",
    "    subset_B = df_B[df_B['ID'] == id_code]\n",
    "\n",
    "    total_days_on_market = 0\n",
    "\n",
    "    # Create a list of dates from DataFrame A excluding the current date\n",
    "    dates_from_A = df_A[(df_A['ID'] == id_code) & (df_A['Date'] != row_A['Date'])]['Date'].tolist()\n",
    "\n",
    "    # Loop over each row in the subset of DataFrame B\n",
    "    for index_B, row_B in subset_B.iterrows():\n",
    "        sale_date_B = pd.to_datetime(row_B['Date'])\n",
    "\n",
    "        # Check if the condition is fulfilled\n",
    "        if (sale_date_B < sale_date_A) and all(sale_date_B > pd.to_datetime(date) for date in dates_from_A):\n",
    "            total_days_on_market += row_B['DaysOnMarket']\n",
    "\n",
    "    # Update the 'total_DaysOnMarket' column in DataFrame A\n",
    "    df_A.at[index_A, 'total_DaysOnMarket'] = total_days_on_market\n",
    "\n",
    "# Display the updated DataFrame A\n",
    "print(df_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- Create the MERGING by year \n",
    "## SO will will merge sales data with the last years evalutaion !  so I will create salesInfo_sale_year_before_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesInfo['salesInfo_year_of_sale']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year and add it to a new column 'Year'\n",
    "data_salesInfo['salesInfo_sale_year_before_merge'] = data_salesInfo['salesInfo_year_of_sale']-1 #minus 1 year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---- FILTER SALES DATA: take Only Sales between years 2006-2023, drop the rest \n",
    "## (no - i will do this once I have merged everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_salesInfo = data_salesInfo[data_salesInfo['salesInfo_year_of_sale']>=2006]\n",
    "# data_salesInfo = data_salesInfo.reset_index(drop=True)\n",
    "# data_salesInfo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---- Create new columns in Salesinfos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_salesInfo['evaluationInfo_evaluationYear'] = None\n",
    "# data_salesInfo['evaluationInfo_lastChange'] = None\n",
    "# data_salesInfo['evaluationInfo_propertyValue'] = None\n",
    "# data_salesInfo['evaluationInfo_landValue'] = None\n",
    "# data_salesInfo['evaluationInfo_deductionSum'] = None\n",
    "# data_salesInfo['evaluationInfo_usage'] = None\n",
    "# data_salesInfo['evaluationInfo_residentialUnits'] = None\n",
    "# data_salesInfo['evaluationInfo_propertyValueArea'] = None\n",
    "# data_salesInfo['evaluationInfo_rebuildYear'] = None\n",
    "# data_salesInfo['evaluationInfo_areaSize'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesInfo.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ RUN THE PROGRAM  AS WHOLE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your path to the evaluation CSV file\n",
    "path_evaluation = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_split\\12_evalutationInfos\\Ready\\Boliga_propertySales_evaluationInfo_Ready.csv'\n",
    "\n",
    "# Initialize an empty DataFrame to store the merged data\n",
    "merged_data_list = []\n",
    "\n",
    "# Read the evaluation data in chunks\n",
    "evaluation_WHOLE = pd.read_csv(path_evaluation, low_memory=False )#, chunksize=chunk_size)\n",
    "\n",
    "chunk_counter = 0\n",
    "\n",
    "# Convert the 'lastChange' column to datetime and sort the DataFrame\n",
    "evaluation_WHOLE['lastChange'] = pd.to_datetime(evaluation_WHOLE['lastChange'], format=\"%Y-%m-%dT%H:%M:%S\").dt.date\n",
    "evaluation_WHOLE = evaluation_WHOLE.sort_values(by='lastChange', ascending=False)\n",
    "\n",
    "# Merge the two DataFrames based on the common column 'RowID_MAIN_boliga_ROW_ID_unitID'\n",
    "merged_chunk = pd.merge(data_salesInfo, evaluation_WHOLE, left_on=['RowID_MAIN_boliga_ROW_ID_unitID','salesInfo_sale_year_before_merge'], right_on=['RowID_MAIN_boliga_ROW_ID_unitID', 'evaluationYear'], how='left')\n",
    "\n",
    "del evaluation_WHOLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_chunk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_chunk[merged_chunk.duplicated(subset='unique_sales_ID', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DataFrame by 'lastChange' in descending order\n",
    "merged_chunk = merged_chunk.sort_values(by=['unique_sales_ID', 'lastChange'], ascending=[True, False])\n",
    "\n",
    "# Keep only the first occurrence (latest date) for each 'unique_sales_ID'\n",
    "merged_chunk_latest = merged_chunk.drop_duplicates(subset='unique_sales_ID', keep='first')\n",
    "merged_chunk_latest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _________________ RENAME COLUMS _____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_column_names = {\n",
    "    'evaluationYear': 'EvaluationInfo_evaluationYear',\n",
    "    'lastChange': 'EvaluationInfo_lastChange', \n",
    "    'propertyValue': 'EvaluationInfo_propertyValue',\n",
    "    'landValue': 'EvaluationInfo_landValue',\n",
    "    'deductionSum': 'EvaluationInfo_deductionSum',\n",
    "    'usage': 'EvaluationInfo_usage', \n",
    "    'residentialUnits': 'EvaluationInfo_residentialUnits',\n",
    "    'propertyValueArea': 'EvaluationInfo_propertyValueArea',\n",
    "    'rebuildYear': 'EvaluationInfo_rebuildYear',\n",
    "    'areaSize': 'EvaluationInfo_areaSize',\n",
    "}\n",
    "\n",
    "merged_chunk_latest = merged_chunk_latest.rename(columns=change_column_names)\n",
    "merged_chunk_latest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_chunk_latest.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ______________________________ SAVE RESULT _______________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_columns = [\n",
    "    'RowID_MAIN_boliga_ROW_ID_unitID',\n",
    "    'salesInfo_isSalesValid',\n",
    "    'salesInfo_handoverCode',\n",
    "    'salesInfo_handoverName',\n",
    "    'salesInfo_deedIssueDate',\n",
    "    'salesInfo_price',\n",
    "    'salesInfo_recalculationDate',\n",
    "    'salesInfo_rebuildYear',\n",
    "    'unique_sales_ID',\n",
    "    'salesInfo_year_of_sale',\n",
    "    'EvaluationInfo_evaluationYear',\n",
    "    'EvaluationInfo_lastChange',\n",
    "    'EvaluationInfo_propertyValue',\n",
    "    'EvaluationInfo_landValue',\n",
    "    'EvaluationInfo_deductionSum',\n",
    "    'EvaluationInfo_usage',\n",
    "    'EvaluationInfo_residentialUnits',\n",
    "    'EvaluationInfo_propertyValueArea',\n",
    "    'EvaluationInfo_rebuildYear',\n",
    "    'EvaluationInfo_areaSize',\n",
    "]\n",
    "\n",
    "path=r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_merge\\step_1_mergin_Sales_transactions_with_evaluation_data\\Boliga_salesData_SalesTransactions_with_evaluation_2623340rows_20columns.csv'\n",
    "\n",
    "merged_chunk_latest[sub_columns].to_csv(path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ RUN THE PROGRAM  CHUNKS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your path to the evaluation CSV file\n",
    "path_evaluation = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_split\\12_evalutationInfos\\Ready\\Boliga_propertySales_evaluationInfo_Ready.csv'\n",
    "\n",
    "# Define chunk size based on your available memory for DataFrame B\n",
    "chunk_size = 1000000\n",
    "\n",
    "# Initialize an empty DataFrame to store the merged data\n",
    "merged_data_list = []\n",
    "\n",
    "# Read the evaluation data in chunks\n",
    "evaluation_chunks = pd.read_csv(path_evaluation, chunksize=chunk_size)\n",
    "\n",
    "chunk_counter = 0\n",
    "# Loop through evaluation chunks\n",
    "for evaluation_chunk in evaluation_chunks:\n",
    "    chunk_counter+=1\n",
    "    print(f'-----> chunk nr.{chunk_counter}')\n",
    "    print(f'chunk lenght: {len(evaluation_chunk)}')\n",
    "    # Convert the 'lastChange' column to datetime and sort the DataFrame\n",
    "    evaluation_chunk['lastChange'] = pd.to_datetime(evaluation_chunk['lastChange'], format=\"%Y-%m-%dT%H:%M:%S\").dt.date\n",
    "    evaluation_chunk = evaluation_chunk.sort_values(by='lastChange', ascending=False)\n",
    "\n",
    "    # Merge the two DataFrames based on the common column 'RowID_MAIN_boliga_ROW_ID_unitID'\n",
    "    merged_chunk = pd.merge(data_salesInfo, evaluation_chunk, left_on=['RowID_MAIN_boliga_ROW_ID_unitID'], right_on=['RowID_MAIN_boliga_ROW_ID_unitID'], how='left')\n",
    "    print(f'lenght of merged: {len(merged_chunk)}')\n",
    "\n",
    "    \n",
    "\n",
    "    # Filter rows where sales_date is greater than evaluation_date\n",
    "    # condition = merged_chunk['salesInfo_deedIssueDate'] > merged_chunk['lastChange']\n",
    "    # merged_chunk = merged_chunk[condition]\n",
    "\n",
    "    # display(merged_chunk.info())\n",
    "\n",
    "    # # Append the filtered chunk to the merged data\n",
    "    # merged_data = pd.concat([merged_data, merged_chunk])\n",
    "    merged_data_list.append(merged_chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- concatenate the list of results \n",
    "result_df = pd.concat(merged_data_list, ignore_index=True)\n",
    "del merged_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where sales_date is greater than evaluation_date\n",
    "condition = result_df['salesInfo_deedIssueDate'] >= result_df['lastChange']\n",
    "result_df = result_df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "a.extend([1,2])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ----- get Unique rows that dont have missing evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicated IDs with empty propertyValue and landValue\n",
    "duplicated_ids_empty_validSale = result_df[result_df.duplicated(subset='RowID_MAIN_boliga_ROW_ID_unitID', keep=False) & result_df['propertyValue'].isna() & result_df['landValue'].isna()]['RowID_MAIN_boliga_ROW_ID_unitID'].unique()\n",
    "duplicated_ids_empty_validSale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove rows with duplicated IDs and empty validSale\n",
    "df_result_clean = result_df[~((result_df['unique_sales_ID'].isin(duplicated_ids_empty_validSale)) & (result_df['propertyValue'].isna()) & (result_df['landValue'].isna()) )]\n",
    "\n",
    "df_result_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Now get the unique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_clean[df_result_clean['propertyValue'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_clean_simple = result_df.drop_duplicates(subset=['unique_sales_ID'], keep='first')\n",
    "df_result_clean_simple.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_clean_simple[df_result_clean_simple['unique_sales_ID']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_result_clean_simple[df_result_clean_simple['propertyValue'].isna()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_clean_simple[df_result_clean_simple['propertyValue'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df['unique_sales_ID']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df.duplicated(subset=['unique_sales_ID'],keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_salesInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_data_nodobble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_nodobble.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_nodobble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "# Example DataFrame A\n",
    "data_a = {\n",
    "    'ID': [1, 2, 3, 1, 4],\n",
    "    'Date_A': [datetime(2022, 1, 1), datetime(2022, 2, 1), datetime(2022, 3, 1), datetime(2022, 4, 1), datetime(2022, 5, 1)],\n",
    "    'Value_A': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "df_a = pd.DataFrame(data_a)\n",
    "\n",
    "# Example DataFrame B\n",
    "data_b = {\n",
    "    'ID': [1, 2, 3, 1, 4] * 4,  # Repeated IDs\n",
    "    'Date_B': [datetime(2021, 12, 1), datetime(2022, 1, 1), datetime(2022, 2, 1), datetime(2022, 3, 1), datetime(2022, 4, 1)] * 4,  # Repeated Dates\n",
    "    'Value_B': np.arange(1, 21)\n",
    "}\n",
    "\n",
    "df_b = pd.DataFrame(data_b)\n",
    "\n",
    "# Convert Date columns to date format\n",
    "df_a['Date_A'] = df_a['Date_A'].dt.date\n",
    "df_b['Date_B'] = df_b['Date_B'].dt.date\n",
    "\n",
    "# Filter DataFrame B based on the condition\n",
    "filtered_df_b = df_b[df_b['Date_B'] > df_a['Date_A']]\n",
    "\n",
    "# Merge DataFrames based on ID\n",
    "merged_df = pd.merge(df_a, filtered_df_b, how='left', on='ID')\n",
    "\n",
    "# Display the result\n",
    "print(\"DataFrame A:\")\n",
    "print(df_a)\n",
    "print(\"\\nDataFrame B:\")\n",
    "print(df_b)\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- OLD SHIT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_evaluation = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_split\\12_evalutationInfos\\Ready\\Boliga_propertySales_evaluationInfo_Ready.csv'\n",
    "\n",
    "# Define chunk size based on your available memory for DataFrame B\n",
    "chunk_size = 10000\n",
    "\n",
    "# Read DataFrame evaluation as chunks\n",
    "evaluation_chunks = pd.read_csv(path_evaluation, chunksize=chunk_size)\n",
    "\n",
    "row_counter = 0\n",
    "for index, row in data_salesInfo.iterrows():\n",
    "    row_counter+=1\n",
    "    print(f'----- row nr. {row_counter} out of 2.623.800')\n",
    "\n",
    "    # -- get values \n",
    "    sales_ID = row['RowID_MAIN_boliga_ROW_ID_unitID']\n",
    "    sales_date = row['salesInfo_deedIssueDate']\n",
    "\n",
    "    # trigger to go next row if conditions are met\n",
    "    new_sales_line = False\n",
    "\n",
    "\n",
    "    for evaluation_chunk in evaluation_chunks:\n",
    "        \n",
    "        # convert the date to day, month and year \n",
    "        evaluation_chunk['lastChange'] = pd.to_datetime(evaluation_chunk['lastChange'], format=\"%Y-%m-%dT%H:%M:%S\").dt.date\n",
    "\n",
    "        # short chunk by \"lastChange\"\n",
    "        evaluation_chunk = evaluation_chunk.sort_values(by='lastChange', ascending=False)\n",
    "\n",
    "\n",
    "        for index_evaluation, row_evaluation in evaluation_chunk.iterrows():\n",
    "            # -- get values \n",
    "            evaluation_ID = row_evaluation['RowID_MAIN_boliga_ROW_ID_unitID']\n",
    "            evaluation_date = row_evaluation['lastChange']\n",
    "\n",
    "            if sales_ID == evaluation_ID:\n",
    "                # print(type(sales_date))\n",
    "                # print(type(evaluation_date))\n",
    "                if sales_date>evaluation_date:\n",
    "                    data_salesInfo.at[index,'evaluationInfo_evaluationYear'] = row_evaluation['evaluationYear']\n",
    "                    data_salesInfo.at[index,'evaluationInfo_lastChange'] = row_evaluation['lastChange']\n",
    "                    data_salesInfo.at[index,'evaluationInfo_propertyValue'] = row_evaluation['propertyValue']\n",
    "                    data_salesInfo.at[index,'evaluationInfo_landValue'] = row_evaluation['landValue']\n",
    "                    data_salesInfo.at[index,'evaluationInfo_deductionSum'] = row_evaluation['deductionSum']\n",
    "                    data_salesInfo.at[index,'evaluationInfo_usage'] = row_evaluation['usage']\n",
    "                    data_salesInfo.at[index,'evaluationInfo_residentialUnits'] = row_evaluation['residentialUnits']\n",
    "                    data_salesInfo.at[index,'evaluationInfo_propertyValueArea'] = row_evaluation['propertyValueArea']\n",
    "                    data_salesInfo.at[index,'evaluationInfo_rebuildYear'] = row_evaluation['rebuildYear']\n",
    "                    data_salesInfo.at[index,'evaluationInfo_areaSize'] = row_evaluation['areaSize']\n",
    "                    new_sales_line = True\n",
    "                    break\n",
    "        \n",
    "        # if we got the values the move to the next sales row!\n",
    "        if new_sales_line:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesInfo['RowID_MAIN_boliga_ROW_ID_unitID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salesInfo['salesInfo_deedIssueDate'] = pd.to_datetime(data_salesInfo['salesInfo_deedIssueDate'], format=\"%Y-%m-%dT%H:%M:%S\").dt.date\n",
    "data_salesInfo['salesInfo_deedIssueDate'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_evaluation = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_split\\12_evalutationInfos\\Ready\\Boliga_propertySales_evaluationInfo_Ready.csv'\n",
    "\n",
    "# Define chunk size based on your available memory for DataFrame B\n",
    "chunk_size = 10000\n",
    "\n",
    "# Define the columns to be used for merging\n",
    "merge_columns = [\"RowID_MAIN_boliga_ROW_ID_unitID\"]\n",
    "\n",
    "# Read DataFrame B in chunks\n",
    "date_evaluation_chunks = pd.read_csv(path_evaluation, chunksize=chunk_size)\n",
    "\n",
    "# Iterate through DataFrame B chunks\n",
    "for date_evaluation in date_evaluation_chunks:\n",
    "    \n",
    "    date_evaluation[\"lastChange\"] = pd.to_datetime(date_evaluation[\"lastChange\"], format=\"%Y-%m-%dT%H:%M:%S\").dt.date\n",
    "\n",
    "    # Merge based on ID column\n",
    "    merged_chunk = pd.merge(data_salesInfo, date_evaluation, on=merge_columns, how=\"left\", suffixes=('_a', '_b'))\n",
    "\n",
    "    # Filter based on the date condition\n",
    "    filtered_chunk = merged_chunk[(merged_chunk[\"salesInfo_deedIssueDate\"] >= merged_chunk[\"lastChange\"]) | merged_chunk[\"lastChange\"].isnull()]\n",
    "\n",
    "    # Drop unnecessary columns from DataFrame A\n",
    "    drop_columns = [col for col in filtered_chunk.columns if col.endswith('_b')]\n",
    "    filtered_chunk = filtered_chunk.drop(columns=drop_columns)\n",
    "\n",
    "    # Update DataFrame A with the new values\n",
    "    data_salesInfo.update(filtered_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_chunk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_evaluation = r'D:\\Thesis\\Properties\\Denmark\\RE_due_scraping_properties\\Boliga_dk\\Creating_main_dataset_for_sales_data\\Data_split\\12_evalutationInfos\\Ready\\Boliga_propertySales_evaluationInfo_Ready.csv'\n",
    "# Specify the number of rows you want to read (in this case, 100)\n",
    "num_rows_to_read = 100\n",
    "\n",
    "# Replace \"your_file.csv\" with the actual file path of your CSV file\n",
    "date_evaluation = pd.read_csv(path_evaluation, nrows=num_rows_to_read)\n",
    "\n",
    "display(date_evaluation.info())\n",
    "\n",
    "\n",
    "display(date_evaluation[''])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_evaluation[\"lastChange\"] = pd.to_datetime(date_evaluation[\"lastChange\"], format=\"%Y-%m-%dT%H:%M:%S\").dt.date\n",
    "date_evaluation[\"lastChange\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if date_evaluation[\"lastChange\"][0] > data_salesInfo['salesInfo_deedIssueDate'][0]:\n",
    "    print(\"bingo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
